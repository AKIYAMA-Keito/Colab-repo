{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKIYAMA-Keito/Colab-repo/blob/main/AWP_nondef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d1Z8uIInOldG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKEv8KiMOldH"
      },
      "source": [
        "Step1 Tensorflowチュートリアル4から引用"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "version2\n"
      ],
      "metadata": {
        "id": "Yk9ofpRIRw2k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVrpxk0rOldI"
      },
      "source": [
        "データセットを読み込んで正規化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QobaZNJyOldJ"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "random_index_train = np.array(range(len(x_train)))\n",
        "np.random.shuffle(random_index_train)\n",
        "x_train = x_train[random_index_train][:1000]\n",
        "y_train = y_train[random_index_train][:1000]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test/255.0\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNcHvWE9OldJ"
      },
      "source": [
        "データセットをシャッフルしてバッチ化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wg2lQwV_OldJ"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)\n",
        ").batch(1000)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_test, y_test)\n",
        ").batch(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQHK9sMOldK"
      },
      "source": [
        "CNNモデルを定義しインスタンスを取り出す．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1-UIMbDyOldK"
      },
      "outputs": [],
      "source": [
        "class CNNModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32, 3, activation = \"relu\")\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation = \"relu\")\n",
        "        self.d2 = Dense(10)\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return x\n",
        "\n",
        "model = CNNModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R46fxEjOOldK"
      },
      "source": [
        "損失関数とoptmizerを選択する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9pzC_gytOldL"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph_DSqV9OldL"
      },
      "source": [
        "損失関数とoptimizerの尺度評価のための関数を導入する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MipedjyLOldL"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD6sZQRdOldL"
      },
      "source": [
        "モデルを訓練するための関数train_stepを定義する．\n",
        "予測値と正解ラベルの間の損失関数の勾配を最適化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KCmbB-cnOldL"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training = True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdL3GJY2OldM"
      },
      "source": [
        "モデルをテストするための関数test_stepを定義する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IsRpIQFEOldM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images, training = False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    \n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D-PUsW-OldM"
      },
      "source": [
        "学習を実行してテストし，結果を出力する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJEwX2bUOldM",
        "outputId": "d093a2df-2cae-46c7-8887-9f4a0517be13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.3100950717926025, Accuracy: 9.700000762939453, Test Loss: 1.9859158992767334, Test Accuracy: 45.869998931884766\n",
            "Epoch 2, Loss: 1.9550176858901978, Accuracy: 52.79999923706055, Test Loss: 1.5647445917129517, Test Accuracy: 70.6500015258789\n",
            "Epoch 3, Loss: 1.5052270889282227, Accuracy: 75.0999984741211, Test Loss: 1.1999425888061523, Test Accuracy: 78.44999694824219\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "    \n",
        "    for train_images, train_labels in train_ds:\n",
        "        train_step(train_images, train_labels)\n",
        "    \n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Loss: {train_loss.result()}, '\n",
        "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTaFZYwFOldM"
      },
      "source": [
        "AWPのアルゴリズムを記述する．\n",
        "まず，学習済みのmodelから重みを取り出してvを加えて再設定する．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()\n",
        "ordinary_weights = weights\n",
        "v_array = []\n",
        "for w in weights:\n",
        "  v = 0.02 * np.random.rand() - 0.01\n",
        "  v_array.append(tf.fill(w.shape, v))"
      ],
      "metadata": {
        "id": "XRSISCKw7GT9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKvxUYsOldM"
      },
      "source": [
        "Step2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "    weights = model.get_weights()\n",
        "    new_weights = []\n",
        "    for w, v in zip(weights, additive_weights):\n",
        "      new_weights.append(w + v)\n",
        "    model.set_weights(new_weights)\n",
        "\n",
        "    adversarial_image_list = []\n",
        "    # eps1 = 1\n",
        "    # eta1 = 0.1\n",
        "    for (images, labels) in dataset:\n",
        "      for (image, label) in zip(images, labels):\n",
        "        image = tf.Variable([image])\n",
        "\n",
        "        initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        image_dashed = tf.add(image, initial_noise)\n",
        "\n",
        "        # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "        # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "        # image_dashed_list = []\n",
        "        # for image_0 in image:\n",
        "        #   for image_h in image_0:\n",
        "        #     for image_v in image_h:\n",
        "        #       for image_pixel in image_v:\n",
        "        #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "        # image_dashed_list.append(image_pixel_dashed)\n",
        "        # # image_dashed = np.array(image_dashed_list)\n",
        "        # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "        # print(image_dashed.numpy())\n",
        "\n",
        "        for j in range(5):\n",
        "          with tf.GradientTape() as tape:\n",
        "            tape.watch(image_dashed)\n",
        "            prediction = model(image_dashed, training = True)\n",
        "            loss = loss_object(label, prediction)\n",
        "          gradients = tape.gradient(loss, image_dashed)\n",
        "          image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "          difference = tf.subtract(image_med, image)\n",
        "          if tf.norm(difference) <= eps1:\n",
        "            image_dashed = image_med \n",
        "          else:\n",
        "            image_dashed = difference\n",
        "            image_dashed = tf.multiply(image_dashed, eps1)\n",
        "            image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "            image_dashed = tf.add(image_dashed, image)\n",
        "        adversarial_image_list.append(image_dashed[0])\n",
        "        adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "    return adversarial_image"
      ],
      "metadata": {
        "id": "V3j-1XQM1lMS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "# weights = model.get_weights()\n",
        "# new_weights = []\n",
        "# for w, v in zip(weights, v_array):\n",
        "#   new_weights.append(w + v)\n",
        "# model.set_weights(new_weights)\n",
        "\n",
        "# adversarial_image_list = []\n",
        "# eps1 = 1\n",
        "# eta1 = 0.1\n",
        "# for (images, labels) in train_ds:\n",
        "#   for (image, label) in zip(images, labels):\n",
        "#     image = tf.Variable([image])\n",
        "\n",
        "#     initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     image_dashed = tf.add(image, initial_noise)\n",
        "#     # print(image)\n",
        "#     # print(image_dashed)\n",
        "\n",
        "#     # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "#     # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "#     # image_dashed_list = []\n",
        "#     # for image_0 in image:\n",
        "#     #   for image_h in image_0:\n",
        "#     #     for image_v in image_h:\n",
        "#     #       for image_pixel in image_v:\n",
        "#     #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "#     # image_dashed_list.append(image_pixel_dashed)\n",
        "#     # # image_dashed = np.array(image_dashed_list)\n",
        "#     # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "#     # print(image_dashed.numpy())\n",
        "\n",
        "#     for j in range(1):\n",
        "#       with tf.GradientTape() as tape:\n",
        "#         tape.watch(image_dashed)\n",
        "#         prediction = model(image_dashed, training = False)\n",
        "#         # print(prediction)\n",
        "#         loss = loss_object(label, prediction)\n",
        "#       gradients = tape.gradient(loss, image_dashed)\n",
        "#       image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "#       difference = tf.subtract(image_med, image)\n",
        "#       if tf.norm(difference) <= eps1:\n",
        "#         image_dashed = image_med \n",
        "#       else:\n",
        "#         image_dashed = difference\n",
        "#         image_dashed = tf.multiply(image_dashed, eps1)\n",
        "#         image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "#         image_dashed = tf.add(image_dashed, image)\n",
        "#     adversarial_image_list.append(image_dashed[0])\n",
        "#     adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "# print(adversarial_image[0] - x_train[0])\n",
        "\n",
        "# # print(adversarial_image)"
      ],
      "metadata": {
        "id": "2HGcWwIkljvE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adversarial = adversary(train_ds, v_array)"
      ],
      "metadata": {
        "id": "LzKpbHhf5dup"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Mpzb3j_c8kKF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(10):\n",
        "plt.imshow(np.squeeze(x_adversarial[0] - x_train[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "aMZJZZYgA04d",
        "outputId": "5f04cbea-6ce4-4e3a-8e0d-6f972e450287"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.squeeze(x_adversarial[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6uaLXa-goe2o",
        "outputId": "5228bbed-4dcb-4a3d-b0e3-f20b9c651118"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "# for i in range(10):\n",
        "#   plt.imshow(np.squeeze(x_adversarial[i]))\n",
        "#   plt.show()\n",
        "#   print(y_train[i])"
      ],
      "metadata": {
        "id": "8C5mNp328y8q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxll_dsBOldN"
      },
      "source": [
        "Step3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_adversarial, y_train)\n",
        ").batch(100)"
      ],
      "metadata": {
        "id": "Cjf3frQs4Io4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(dataset, batch_size = 100):\n",
        "  batch_size = 100\n",
        "  loss_sum = 0.0\n",
        "  for (images, labels) in adversarial_ds:\n",
        "    predictions = model(images, training = True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "    loss_sum_batch = loss * batch_size\n",
        "    loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "  average_loss = tf.divide(loss_sum, 1000)\n",
        "  return average_loss"
      ],
      "metadata": {
        "id": "ozxGyYUn3KGZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 100\n",
        "# loss_sum = 0.0\n",
        "# for (images, labels) in adversarial_ds:\n",
        "#   predictions = model(images, training = True)\n",
        "#   loss = loss_object(labels, predictions)\n",
        "#   loss_sum_batch = loss * batch_size\n",
        "#   loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "# average_loss = tf.divide(loss_sum, 1000)"
      ],
      "metadata": {
        "id": "rD2V2J5I5E1E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_loss(dataset, batch_size = 100, additive_noise = v_array):\n",
        "#   # batch_size = 100\n",
        "#   loss_sum = 0.0\n",
        "#   for (images, labels) in dataset:\n",
        "#     predictions = model(images, training = True)\n",
        "#     loss = loss_object(labels, predictions)\n",
        "#     loss_sum_batch = loss * batch_size\n",
        "#     loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "#   average_loss = tf.divide(loss_sum, 1000)\n",
        "#   return average_loss"
      ],
      "metadata": {
        "id": "H1C7Lp-g3JzR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZ9Ze5LOldN"
      },
      "source": [
        "Step4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_flat = np.ndarray([])\n",
        "for w in ordinary_weights:\n",
        "  w_reshape = tf.reshape(w, [-1])\n",
        "  print(w_reshape.shape)\n",
        "  w_flat = np.hstack([w_flat, w_reshape])\n",
        "w_fro = np.linalg.norm(w_flat)\n",
        "print(w_fro)\n",
        "  # w_fro = tf.add(w_fro, np.linalg.norm(w_reshape, ord=2))\n",
        "# w_fro = tf.sqrt(w_fro)"
      ],
      "metadata": {
        "id": "BD3YeKDISlsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce84f7e3-4aaa-4350-b5bf-970a9d393225"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288,)\n",
            "(32,)\n",
            "(2768896,)\n",
            "(128,)\n",
            "(1280,)\n",
            "(10,)\n",
            "16.906106672650523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.rcsetup import validate_axisbelow\n",
        "eps2 = 1\n",
        "eta2 = 0.1\n",
        "batch_size = 100\n",
        "\n",
        "v_updated = v_array\n",
        "# vの初期値を，step2で固定したvに設定する．\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  # 重みをw + (現在の)vに設定する　　ここから\n",
        "  current_weights = []\n",
        "  for layer_weights, v in zip(ordinary_weights, v_updated):\n",
        "    current_layer_weight = tf.add(layer_weights, v)\n",
        "    current_weights.append(current_layer_weight)\n",
        "  model.set_weights(current_weights)\n",
        "  # 重みをw + (現在の)vに設定する　　ここまで\n",
        "\n",
        "  # gradientの計算　　ここから\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = calculate_loss(adversarial_ds)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  # print(gradients)\n",
        "  #　計算できているし，悪い値ではない．\n",
        "  # gradientの計算　　ここまで\n",
        "\n",
        "  # gradientのノルムの計算　　ここから\n",
        "  gradients_flat = np.ndarray([])\n",
        "  for g in gradients:\n",
        "    g_reshape = tf.reshape(g, [-1])\n",
        "    gradients_flat = np.hstack([gradients_flat, g_reshape])\n",
        "  gradients_norm = np.linalg.norm(gradients_flat)\n",
        "  print(gradients_flat)\n",
        "  print(gradients_norm)\n",
        "  # ループを経るごとに値が大きくなり過ぎている？\n",
        "  # gradientのノルムの計算　　ここまで\n",
        "\n",
        "  # 勾配降下の実行　　ここから\n",
        "  v_difference = []\n",
        "  for g, v in zip(gradients, v_updated):\n",
        "    g = tf.divide(g, gradients_norm)\n",
        "    g = tf.multiply(g, w_fro)\n",
        "    g = tf.multiply(eta2, g)\n",
        "    v_med = tf.add(v, g)\n",
        "  # 勾配降下の実行　　ここまで\n",
        "\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここから\n",
        "    v_difference.append(v_med)\n",
        "  v_difference_flat = np.ndarray([])\n",
        "  for v_flat in v_difference:\n",
        "    v_flat_reshape = tf.reshape(v_flat, [-1])\n",
        "    # print(g_reshape.shape)\n",
        "    v_difference_flat = np.hstack([v_difference_flat, v_flat_reshape])\n",
        "  v_difference_norm = np.linalg.norm(v_difference_flat)\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここまで\n",
        "\n",
        "  # 射影の実行　　ここから\n",
        "  if v_difference_norm <= eps2:\n",
        "    v_hat = v_med \n",
        "  else:\n",
        "    v_hat = v_difference\n",
        "    for v_hat_med in v_hat:\n",
        "      v_hat_med = tf.multiply(v_hat_med, eps2)\n",
        "      v_hat_med = tf.divide(v_hat_med, v_difference_norm)\n",
        "  v_updated = v_hat\n",
        "  # print(v_updated)　計算できているし，悪い値ではない．\n",
        "  # 射影の実行　　ここまで"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhQbeCasjVRp",
        "outputId": "49dfeaa4-2d06-4571-bc63-cf83a45598b1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.          0.          0.         ... -0.01466845  0.00876029\n",
            "  0.00177864]\n",
            "0.024671979859245265\n",
            "[ 0.          0.          0.         ... -0.0827188   0.06884347\n",
            "  0.00108441]\n",
            "0.17389860564704276\n",
            "[ 0.          0.          0.         ... -0.10503002  0.12445395\n",
            " -0.02888424]\n",
            "0.3229957954817389\n",
            "[ 0.          0.          0.         ... -0.11203143  0.12223837\n",
            " -0.06734335]\n",
            "0.5237436710057816\n",
            "[ 0.          0.          0.         ... -0.11428382  0.01859043\n",
            " -0.089456  ]\n",
            "0.7718595771008931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZjbQBHOldN"
      },
      "source": [
        "Step5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta3 = 1\n",
        "\n",
        "weights_updated = ordinary_weights\n",
        "for i in range(5):\n",
        "\n",
        "  # 重みをw + (step4で決めた)vに設定する　　ここから\n",
        "  current_weights = []\n",
        "  for layer_weights, v in zip(weights_updated, v_updated):\n",
        "    current_layer_weight = tf.add(layer_weights, v)\n",
        "    current_weights.append(current_layer_weight)\n",
        "  model.set_weights(current_weights)\n",
        "  print(current_weights) \n",
        "  # 計算できている．\n",
        "  # 重みをw + (step4で決めた)vに設定する　　ここまで\n",
        "\n",
        "  # gradientの計算　　ここから\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = calculate_loss(adversarial_ds)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  # print(gradients) \n",
        "  # 計算できているが，値が大きい．\n",
        "  # gradientの計算　　ここまで\n",
        "\n",
        "  # 勾配降下の実行　　ここから\n",
        "  w_hat = []\n",
        "  for wu, g in zip(weights_updated, gradients):\n",
        "    g_med = tf.multiply(eta3, g)\n",
        "    wu = tf.subtract(wu, g_med)\n",
        "    w_hat.append(wu)\n",
        "  weights_updated = w_hat\n",
        "  # 勾配降下の実行　　ここまで"
      ],
      "metadata": {
        "id": "_0bd9iyoK9EB",
        "outputId": "9fc5487f-5505-469e-9602-30e5b6bc1f40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.06202856,  0.05014295, -0.13210635, -0.02812419,\n",
            "          -0.06932499,  0.00484942, -0.02333109,  0.09960455,\n",
            "           0.08221591,  0.05807344,  0.09276387,  0.08513191,\n",
            "          -0.07835997, -0.01386511, -0.12508532,  0.03721204,\n",
            "           0.04695119,  0.08166332,  0.03454292,  0.11252072,\n",
            "           0.03706631,  0.10830042,  0.03283131,  0.05252631,\n",
            "          -0.03488038,  0.03010919,  0.13159613, -0.00925291,\n",
            "          -0.01023544,  0.09489118, -0.10082849, -0.14053127]],\n",
            "\n",
            "        [[ 0.00249597, -0.0783968 ,  0.1233348 ,  0.06705999,\n",
            "           0.04455622,  0.06970557, -0.13608931,  0.12992008,\n",
            "          -0.02727869,  0.13120602, -0.06019425,  0.08174113,\n",
            "           0.07721741,  0.05482655, -0.00259487, -0.09592575,\n",
            "           0.06706798, -0.06159519,  0.1392652 ,  0.0987114 ,\n",
            "          -0.01633115, -0.08949215, -0.01266699,  0.13684088,\n",
            "           0.14086436, -0.13885099, -0.05200045,  0.13710865,\n",
            "          -0.13077584, -0.11186041, -0.07764996,  0.10710786]],\n",
            "\n",
            "        [[-0.03069373,  0.00702035, -0.12879436, -0.10537256,\n",
            "          -0.02802309,  0.05892619, -0.12192397,  0.03425682,\n",
            "          -0.12366469,  0.10084802,  0.04794036,  0.05822574,\n",
            "           0.00668348, -0.07263146, -0.08305137, -0.09823068,\n",
            "          -0.05065713,  0.07076769, -0.03317459, -0.02624558,\n",
            "          -0.00258005, -0.01363758, -0.00982865,  0.08919286,\n",
            "           0.10976722,  0.07036143,  0.13991347, -0.13388212,\n",
            "           0.13103156, -0.037078  , -0.10752662, -0.0866694 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.07412991, -0.09595376,  0.04210574, -0.0476921 ,\n",
            "          -0.03610288,  0.03001294, -0.14109747, -0.07817936,\n",
            "          -0.08793124,  0.04588717, -0.08404898,  0.0604384 ,\n",
            "          -0.09408069, -0.00367751,  0.14138883,  0.09411197,\n",
            "          -0.02879274, -0.08985905,  0.0796673 , -0.11078194,\n",
            "          -0.0948124 , -0.06853653,  0.12520373,  0.13625085,\n",
            "          -0.11714021, -0.01037177,  0.13489549,  0.04826215,\n",
            "          -0.03527536, -0.08881437, -0.12745184,  0.09332817]],\n",
            "\n",
            "        [[ 0.11378999, -0.00791644,  0.07322919, -0.09426878,\n",
            "          -0.0334513 , -0.00302515,  0.0700658 , -0.06241706,\n",
            "          -0.0490274 , -0.079239  ,  0.07385737,  0.06505667,\n",
            "           0.00539763, -0.0419738 ,  0.08032528,  0.02251007,\n",
            "           0.12563002,  0.13094811,  0.02967912, -0.12132199,\n",
            "          -0.14012006,  0.09857967,  0.02680316, -0.09036358,\n",
            "          -0.05032411, -0.010203  , -0.07579824,  0.00898009,\n",
            "           0.01308346, -0.06985516,  0.04522499,  0.11637746]],\n",
            "\n",
            "        [[ 0.11213239,  0.00241366, -0.00729572, -0.07177906,\n",
            "           0.11773024,  0.12709284, -0.10576161,  0.05821696,\n",
            "          -0.05235052,  0.01336579,  0.09582432, -0.0530754 ,\n",
            "          -0.10397846, -0.01828397,  0.03170863,  0.08607525,\n",
            "           0.02994699, -0.11480095,  0.08653051, -0.09112059,\n",
            "          -0.05838883, -0.07402168,  0.04332776,  0.0007032 ,\n",
            "           0.07268424, -0.05909398, -0.07649388,  0.09262356,\n",
            "          -0.09645572,  0.13073309,  0.1012977 , -0.04572782]]],\n",
            "\n",
            "\n",
            "       [[[-0.0979704 , -0.08454851, -0.09056082,  0.00423675,\n",
            "          -0.10456272,  0.02287782, -0.12610416,  0.07786541,\n",
            "          -0.00419454,  0.0730189 , -0.08534931, -0.01275937,\n",
            "           0.09062144,  0.04615173, -0.02734124,  0.02106691,\n",
            "          -0.03535959, -0.08256157,  0.12913978,  0.02704783,\n",
            "           0.04879972, -0.01569001, -0.01388762,  0.03570298,\n",
            "          -0.01455456,  0.0197239 ,  0.0830362 ,  0.05966683,\n",
            "           0.07741973, -0.0789151 , -0.105644  , -0.06022153]],\n",
            "\n",
            "        [[ 0.08758924, -0.05517194,  0.05702516,  0.10708377,\n",
            "          -0.11925049, -0.03550239,  0.13866036, -0.077084  ,\n",
            "           0.09195867, -0.0518985 , -0.02180975,  0.02071336,\n",
            "           0.11471535,  0.0963527 ,  0.11030308, -0.12262659,\n",
            "           0.08906279, -0.08450389, -0.14244479,  0.11484022,\n",
            "           0.10688809,  0.03647962, -0.12267335,  0.12980713,\n",
            "          -0.04347834,  0.00548032, -0.12233563, -0.01448329,\n",
            "          -0.07177961, -0.10123114, -0.0144809 ,  0.04654104]],\n",
            "\n",
            "        [[ 0.03782939,  0.1269201 ,  0.08049585,  0.05070779,\n",
            "          -0.04414065,  0.03340891, -0.10825917, -0.12431242,\n",
            "           0.0717251 ,  0.09378184,  0.05687805, -0.02080578,\n",
            "          -0.01133154, -0.07365052, -0.09479876,  0.0411536 ,\n",
            "           0.05902185,  0.12052424,  0.08089989, -0.06529094,\n",
            "          -0.13747199, -0.1350784 , -0.00036737, -0.02964802,\n",
            "          -0.11615554,  0.08652553, -0.14339562,  0.00238161,\n",
            "           0.13349923, -0.07748175,  0.08071343, -0.03476932]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([0.00564745, 0.00575184, 0.00561189, 0.00564333, 0.00557935,\n",
            "       0.00536721, 0.00548672, 0.00575975, 0.00604404, 0.00550545,\n",
            "       0.00569685, 0.00590295, 0.00571191, 0.00568212, 0.00574921,\n",
            "       0.00573382, 0.00559204, 0.00554901, 0.00566101, 0.00570602,\n",
            "       0.00550203, 0.00600863, 0.00543001, 0.00578629, 0.00573254,\n",
            "       0.00560171, 0.00562991, 0.00540037, 0.00557529, 0.00601533,\n",
            "       0.00568759, 0.00557825], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-0.01104863, -0.01569864,  0.00177612, ..., -0.01847203,\n",
            "         0.00310316,  0.00771448],\n",
            "       [-0.00925448, -0.00265528, -0.0087408 , ..., -0.00247854,\n",
            "         0.0007723 , -0.02143149],\n",
            "       [ 0.00774184, -0.02313373, -0.01894658, ..., -0.004254  ,\n",
            "        -0.02058014,  0.00213366],\n",
            "       ...,\n",
            "       [ 0.00313085,  0.00512195, -0.00227743, ..., -0.0040302 ,\n",
            "        -0.00072019, -0.00145574],\n",
            "       [ 0.00160082, -0.0177766 , -0.01249252, ..., -0.00406026,\n",
            "         0.00312158, -0.02011246],\n",
            "       [ 0.00019007, -0.01070052, -0.01990644, ..., -0.00559603,\n",
            "        -0.00999445, -0.00700347]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.00842417, -0.00555125, -0.00325719, -0.00645145, -0.00600843,\n",
            "       -0.00353425, -0.00389545, -0.00574814, -0.00842584, -0.00552653,\n",
            "       -0.00363381, -0.00842575, -0.00603284, -0.00454745, -0.00518222,\n",
            "       -0.0073994 , -0.00346652, -0.00333299, -0.00842554, -0.00363305,\n",
            "       -0.00400056, -0.00744497, -0.00576731, -0.00622624, -0.00382348,\n",
            "       -0.00700141, -0.00398429, -0.00696739, -0.00568952, -0.0071525 ,\n",
            "       -0.00590593, -0.00362756, -0.00581427, -0.0035934 , -0.00615328,\n",
            "       -0.00577438, -0.0063106 , -0.00667454, -0.00593763, -0.00514508,\n",
            "       -0.00590599, -0.00809625, -0.00638245, -0.00351065, -0.00644704,\n",
            "       -0.00913655, -0.00630396, -0.00649505, -0.00376223, -0.00842588,\n",
            "       -0.00842615, -0.00604389, -0.00365584, -0.00593873, -0.00576415,\n",
            "       -0.00484582, -0.00661672, -0.00825501, -0.00612159, -0.00661015,\n",
            "       -0.00331496, -0.00679756, -0.00609577, -0.00341438, -0.00564251,\n",
            "       -0.0080354 , -0.0075368 , -0.00600003, -0.00331273, -0.0035093 ,\n",
            "       -0.00629108, -0.00601081, -0.00362004, -0.00356843, -0.00362582,\n",
            "       -0.00615842, -0.00344443, -0.00842577, -0.00324133, -0.00341243,\n",
            "       -0.00600886, -0.00569651, -0.00370386, -0.00333893, -0.00651092,\n",
            "       -0.00576783, -0.00607937, -0.00803237, -0.00671545, -0.00500785,\n",
            "       -0.00782678, -0.00781939, -0.00573   , -0.00842585, -0.00574003,\n",
            "       -0.00490013, -0.00566727, -0.00568579, -0.00601775, -0.00686955,\n",
            "       -0.00842245, -0.00602241, -0.00619941, -0.00888851, -0.00563707,\n",
            "       -0.0035871 , -0.00643113, -0.00838527, -0.00376128, -0.00569968,\n",
            "       -0.00601837, -0.00396748, -0.00782878, -0.00645805, -0.00338571,\n",
            "       -0.00683478, -0.00327492, -0.00672262, -0.00636292, -0.00403743,\n",
            "       -0.00839901, -0.00739377, -0.00589352, -0.00595199, -0.00404924,\n",
            "       -0.00581757, -0.0041369 , -0.00534613], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[ 0.01920497,  0.05783387, -0.0979767 , ..., -0.1444712 ,\n",
            "         0.18752769, -0.15595494],\n",
            "       [ 0.1855257 , -0.16534883, -0.19107886, ..., -0.04171174,\n",
            "         0.13292825,  0.05250443],\n",
            "       [ 0.17774679,  0.1789255 , -0.07314532, ...,  0.04281954,\n",
            "         0.12669507,  0.04535551],\n",
            "       ...,\n",
            "       [-0.14799179,  0.10000856,  0.03800937, ..., -0.14066488,\n",
            "        -0.00318479, -0.11953481],\n",
            "       [-0.20608117, -0.08037669, -0.1288431 , ..., -0.09889741,\n",
            "        -0.00110024,  0.06943077],\n",
            "       [ 0.16364554, -0.19957103, -0.19758053, ..., -0.04074754,\n",
            "         0.00933902,  0.0485101 ]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-1.5239873 ,  0.15517887,  1.1823833 , -1.1677042 , -1.0648707 ,\n",
            "        5.893493  , -2.4881983 , -2.9765184 ,  2.3450503 , -0.4431223 ],\n",
            "      dtype=float32)>]\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.06202856,  0.05014295, -0.13210635, -0.02812419,\n",
            "          -0.06932499,  0.00484942, -0.02333109,  0.09960455,\n",
            "           0.08221591,  0.05807344,  0.09276387,  0.08513191,\n",
            "          -0.07835997, -0.01386511, -0.12508532,  0.03721204,\n",
            "           0.04695119,  0.08166332,  0.03454292,  0.11252072,\n",
            "           0.03706631,  0.10830042,  0.03283131,  0.05252631,\n",
            "          -0.03488038,  0.03010919,  0.13159613, -0.00925291,\n",
            "          -0.01023544,  0.09489118, -0.10082849, -0.14053127]],\n",
            "\n",
            "        [[ 0.00249597, -0.0783968 ,  0.1233348 ,  0.06705999,\n",
            "           0.04455622,  0.06970557, -0.13608931,  0.12992008,\n",
            "          -0.02727869,  0.13120602, -0.06019425,  0.08174113,\n",
            "           0.07721741,  0.05482655, -0.00259487, -0.09592575,\n",
            "           0.06706798, -0.06159519,  0.1392652 ,  0.0987114 ,\n",
            "          -0.01633115, -0.08949215, -0.01266699,  0.13684088,\n",
            "           0.14086436, -0.13885099, -0.05200045,  0.13710865,\n",
            "          -0.13077584, -0.11186041, -0.07764996,  0.10710786]],\n",
            "\n",
            "        [[-0.03069373,  0.00702035, -0.12879436, -0.10537256,\n",
            "          -0.02802309,  0.05892619, -0.12192397,  0.03425682,\n",
            "          -0.12366469,  0.10084802,  0.04794036,  0.05822574,\n",
            "           0.00668348, -0.07263146, -0.08305137, -0.09823068,\n",
            "          -0.05065713,  0.07076769, -0.03317459, -0.02624558,\n",
            "          -0.00258005, -0.01363758, -0.00982865,  0.08919286,\n",
            "           0.10976722,  0.07036143,  0.13991347, -0.13388212,\n",
            "           0.13103156, -0.037078  , -0.10752662, -0.0866694 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.07412991, -0.09595376,  0.04210574, -0.0476921 ,\n",
            "          -0.03610288,  0.03001294, -0.14109747, -0.07817936,\n",
            "          -0.08793124,  0.04588717, -0.08404898,  0.0604384 ,\n",
            "          -0.09408069, -0.00367751,  0.14138883,  0.09411197,\n",
            "          -0.02879274, -0.08985905,  0.0796673 , -0.11078194,\n",
            "          -0.0948124 , -0.06853653,  0.12520373,  0.13625085,\n",
            "          -0.11714021, -0.01037177,  0.13489549,  0.04826215,\n",
            "          -0.03527536, -0.08881437, -0.12745184,  0.09332817]],\n",
            "\n",
            "        [[ 0.11378999, -0.00791644,  0.07322919, -0.09426878,\n",
            "          -0.0334513 , -0.00302515,  0.0700658 , -0.06241706,\n",
            "          -0.0490274 , -0.079239  ,  0.07385737,  0.06505667,\n",
            "           0.00539763, -0.0419738 ,  0.08032528,  0.02251007,\n",
            "           0.12563002,  0.13094811,  0.02967912, -0.12132199,\n",
            "          -0.14012006,  0.09857967,  0.02680316, -0.09036358,\n",
            "          -0.05032411, -0.010203  , -0.07579824,  0.00898009,\n",
            "           0.01308346, -0.06985516,  0.04522499,  0.11637746]],\n",
            "\n",
            "        [[ 0.11213239,  0.00241366, -0.00729572, -0.07177906,\n",
            "           0.11773024,  0.12709284, -0.10576161,  0.05821696,\n",
            "          -0.05235052,  0.01336579,  0.09582432, -0.0530754 ,\n",
            "          -0.10397846, -0.01828397,  0.03170863,  0.08607525,\n",
            "           0.02994699, -0.11480095,  0.08653051, -0.09112059,\n",
            "          -0.05838883, -0.07402168,  0.04332776,  0.0007032 ,\n",
            "           0.07268424, -0.05909398, -0.07649388,  0.09262356,\n",
            "          -0.09645572,  0.13073309,  0.1012977 , -0.04572782]]],\n",
            "\n",
            "\n",
            "       [[[-0.0979704 , -0.08454851, -0.09056082,  0.00423675,\n",
            "          -0.10456272,  0.02287782, -0.12610416,  0.07786541,\n",
            "          -0.00419454,  0.0730189 , -0.08534931, -0.01275937,\n",
            "           0.09062144,  0.04615173, -0.02734124,  0.02106691,\n",
            "          -0.03535959, -0.08256157,  0.12913978,  0.02704783,\n",
            "           0.04879972, -0.01569001, -0.01388762,  0.03570298,\n",
            "          -0.01455456,  0.0197239 ,  0.0830362 ,  0.05966683,\n",
            "           0.07741973, -0.0789151 , -0.105644  , -0.06022153]],\n",
            "\n",
            "        [[ 0.08758924, -0.05517194,  0.05702516,  0.10708377,\n",
            "          -0.11925049, -0.03550239,  0.13866036, -0.077084  ,\n",
            "           0.09195867, -0.0518985 , -0.02180975,  0.02071336,\n",
            "           0.11471535,  0.0963527 ,  0.11030308, -0.12262659,\n",
            "           0.08906279, -0.08450389, -0.14244479,  0.11484022,\n",
            "           0.10688809,  0.03647962, -0.12267335,  0.12980713,\n",
            "          -0.04347834,  0.00548032, -0.12233563, -0.01448329,\n",
            "          -0.07177961, -0.10123114, -0.0144809 ,  0.04654104]],\n",
            "\n",
            "        [[ 0.03782939,  0.1269201 ,  0.08049585,  0.05070779,\n",
            "          -0.04414065,  0.03340891, -0.10825917, -0.12431242,\n",
            "           0.0717251 ,  0.09378184,  0.05687805, -0.02080578,\n",
            "          -0.01133154, -0.07365052, -0.09479876,  0.0411536 ,\n",
            "           0.05902185,  0.12052424,  0.08089989, -0.06529094,\n",
            "          -0.13747199, -0.1350784 , -0.00036737, -0.02964802,\n",
            "          -0.11615554,  0.08652553, -0.14339562,  0.00238161,\n",
            "           0.13349923, -0.07748175,  0.08071343, -0.03476932]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([0.00564745, 0.00575184, 0.00561189, 0.00564333, 0.00557935,\n",
            "       0.00536721, 0.00548672, 0.00575975, 0.00604404, 0.00550545,\n",
            "       0.00569685, 0.00590295, 0.00571191, 0.00568212, 0.00574921,\n",
            "       0.00573382, 0.00559204, 0.00554901, 0.00566101, 0.00570602,\n",
            "       0.00550203, 0.00600863, 0.00543001, 0.00578629, 0.00573254,\n",
            "       0.00560171, 0.00562991, 0.00540037, 0.00557529, 0.00601533,\n",
            "       0.00568759, 0.00557825], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-0.01104863, -0.01569864,  0.00177612, ..., -0.01847203,\n",
            "         0.00310316,  0.00771448],\n",
            "       [-0.00925448, -0.00265528, -0.0087408 , ..., -0.00247854,\n",
            "         0.0007723 , -0.02143149],\n",
            "       [ 0.00774184, -0.02313373, -0.01894658, ..., -0.004254  ,\n",
            "        -0.02058014,  0.00213366],\n",
            "       ...,\n",
            "       [ 0.00313085,  0.00512195, -0.00227743, ..., -0.0040302 ,\n",
            "        -0.00072019, -0.00145574],\n",
            "       [ 0.00160082, -0.0177766 , -0.01249252, ..., -0.00406026,\n",
            "         0.00312158, -0.02011246],\n",
            "       [ 0.00019007, -0.01070052, -0.01990644, ..., -0.00559603,\n",
            "        -0.00999445, -0.00700347]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.00842417, -0.00555125, -0.00325719, -0.00645145, -0.00600843,\n",
            "       -0.00353425, -0.00389545, -0.00574814, -0.00842584, -0.00552653,\n",
            "       -0.00363381, -0.00842575, -0.00603284, -0.00454745, -0.00518222,\n",
            "       -0.0073994 , -0.00346652, -0.00333299, -0.00842554, -0.00363305,\n",
            "       -0.00400056, -0.00744497, -0.00576731, -0.00622624, -0.00382348,\n",
            "       -0.00700141, -0.00398429, -0.00696739, -0.00568952, -0.0071525 ,\n",
            "       -0.00590593, -0.00362756, -0.00581427, -0.0035934 , -0.00615328,\n",
            "       -0.00577438, -0.0063106 , -0.00667454, -0.00593763, -0.00514508,\n",
            "       -0.00590599, -0.00809625, -0.00638245, -0.00351065, -0.00644704,\n",
            "       -0.00913655, -0.00630396, -0.00649505, -0.00376223, -0.00842588,\n",
            "       -0.00842615, -0.00604389, -0.00365584, -0.00593873, -0.00576415,\n",
            "       -0.00484582, -0.00661672, -0.00825501, -0.00612159, -0.00661015,\n",
            "       -0.00331496, -0.00679756, -0.00609577, -0.00341438, -0.00564251,\n",
            "       -0.0080354 , -0.0075368 , -0.00600003, -0.00331273, -0.0035093 ,\n",
            "       -0.00629108, -0.00601081, -0.00362004, -0.00356843, -0.00362582,\n",
            "       -0.00615842, -0.00344443, -0.00842577, -0.00324133, -0.00341243,\n",
            "       -0.00600886, -0.00569651, -0.00370386, -0.00333893, -0.00651092,\n",
            "       -0.00576783, -0.00607937, -0.00803237, -0.00671545, -0.00500785,\n",
            "       -0.00782678, -0.00781939, -0.00573   , -0.00842585, -0.00574003,\n",
            "       -0.00490013, -0.00566727, -0.00568579, -0.00601775, -0.00686955,\n",
            "       -0.00842245, -0.00602241, -0.00619941, -0.00888851, -0.00563707,\n",
            "       -0.0035871 , -0.00643113, -0.00838527, -0.00376128, -0.00569968,\n",
            "       -0.00601837, -0.00396748, -0.00782878, -0.00645805, -0.00338571,\n",
            "       -0.00683478, -0.00327492, -0.00672262, -0.00636292, -0.00403743,\n",
            "       -0.00839901, -0.00739377, -0.00589352, -0.00595199, -0.00404924,\n",
            "       -0.00581757, -0.0041369 , -0.00534613], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[ 0.01920497,  0.05783387, -0.0979767 , ..., -0.1444712 ,\n",
            "         0.18752769, -0.15595494],\n",
            "       [ 0.1855257 , -0.16534883, -0.19107886, ..., -0.04171174,\n",
            "         0.13292825,  0.05250443],\n",
            "       [ 0.17774679,  0.1789255 , -0.07314532, ...,  0.04281954,\n",
            "         0.12669507,  0.04535551],\n",
            "       ...,\n",
            "       [-0.14799179,  0.10000856,  0.03800937, ..., -0.14066488,\n",
            "        -0.00318479, -0.11953481],\n",
            "       [-0.20608117, -0.08037669, -0.1288431 , ..., -0.09889741,\n",
            "        -0.00110024,  0.06943077],\n",
            "       [ 0.16364554, -0.19957103, -0.19758053, ..., -0.04074754,\n",
            "         0.00933902,  0.0485101 ]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-1.4205618 ,  0.24809894,  1.2667801 , -1.0665246 , -0.9647799 ,\n",
            "        5.0260434 , -2.3774173 , -2.8616526 ,  2.408534  , -0.34681547],\n",
            "      dtype=float32)>]\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.06202856,  0.05014295, -0.13210635, -0.02812419,\n",
            "          -0.06932499,  0.00484942, -0.02333109,  0.09960455,\n",
            "           0.08221591,  0.05807344,  0.09276387,  0.08513191,\n",
            "          -0.07835997, -0.01386511, -0.12508532,  0.03721204,\n",
            "           0.04695119,  0.08166332,  0.03454292,  0.11252072,\n",
            "           0.03706631,  0.10830042,  0.03283131,  0.05252631,\n",
            "          -0.03488038,  0.03010919,  0.13159613, -0.00925291,\n",
            "          -0.01023544,  0.09489118, -0.10082849, -0.14053127]],\n",
            "\n",
            "        [[ 0.00249597, -0.0783968 ,  0.1233348 ,  0.06705999,\n",
            "           0.04455622,  0.06970557, -0.13608931,  0.12992008,\n",
            "          -0.02727869,  0.13120602, -0.06019425,  0.08174113,\n",
            "           0.07721741,  0.05482655, -0.00259487, -0.09592575,\n",
            "           0.06706798, -0.06159519,  0.1392652 ,  0.0987114 ,\n",
            "          -0.01633115, -0.08949215, -0.01266699,  0.13684088,\n",
            "           0.14086436, -0.13885099, -0.05200045,  0.13710865,\n",
            "          -0.13077584, -0.11186041, -0.07764996,  0.10710786]],\n",
            "\n",
            "        [[-0.03069373,  0.00702035, -0.12879436, -0.10537256,\n",
            "          -0.02802309,  0.05892619, -0.12192397,  0.03425682,\n",
            "          -0.12366469,  0.10084802,  0.04794036,  0.05822574,\n",
            "           0.00668348, -0.07263146, -0.08305137, -0.09823068,\n",
            "          -0.05065713,  0.07076769, -0.03317459, -0.02624558,\n",
            "          -0.00258005, -0.01363758, -0.00982865,  0.08919286,\n",
            "           0.10976722,  0.07036143,  0.13991347, -0.13388212,\n",
            "           0.13103156, -0.037078  , -0.10752662, -0.0866694 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.07412991, -0.09595376,  0.04210574, -0.0476921 ,\n",
            "          -0.03610288,  0.03001294, -0.14109747, -0.07817936,\n",
            "          -0.08793124,  0.04588717, -0.08404898,  0.0604384 ,\n",
            "          -0.09408069, -0.00367751,  0.14138883,  0.09411197,\n",
            "          -0.02879274, -0.08985905,  0.0796673 , -0.11078194,\n",
            "          -0.0948124 , -0.06853653,  0.12520373,  0.13625085,\n",
            "          -0.11714021, -0.01037177,  0.13489549,  0.04826215,\n",
            "          -0.03527536, -0.08881437, -0.12745184,  0.09332817]],\n",
            "\n",
            "        [[ 0.11378999, -0.00791644,  0.07322919, -0.09426878,\n",
            "          -0.0334513 , -0.00302515,  0.0700658 , -0.06241706,\n",
            "          -0.0490274 , -0.079239  ,  0.07385737,  0.06505667,\n",
            "           0.00539763, -0.0419738 ,  0.08032528,  0.02251007,\n",
            "           0.12563002,  0.13094811,  0.02967912, -0.12132199,\n",
            "          -0.14012006,  0.09857967,  0.02680316, -0.09036358,\n",
            "          -0.05032411, -0.010203  , -0.07579824,  0.00898009,\n",
            "           0.01308346, -0.06985516,  0.04522499,  0.11637746]],\n",
            "\n",
            "        [[ 0.11213239,  0.00241366, -0.00729572, -0.07177906,\n",
            "           0.11773024,  0.12709284, -0.10576161,  0.05821696,\n",
            "          -0.05235052,  0.01336579,  0.09582432, -0.0530754 ,\n",
            "          -0.10397846, -0.01828397,  0.03170863,  0.08607525,\n",
            "           0.02994699, -0.11480095,  0.08653051, -0.09112059,\n",
            "          -0.05838883, -0.07402168,  0.04332776,  0.0007032 ,\n",
            "           0.07268424, -0.05909398, -0.07649388,  0.09262356,\n",
            "          -0.09645572,  0.13073309,  0.1012977 , -0.04572782]]],\n",
            "\n",
            "\n",
            "       [[[-0.0979704 , -0.08454851, -0.09056082,  0.00423675,\n",
            "          -0.10456272,  0.02287782, -0.12610416,  0.07786541,\n",
            "          -0.00419454,  0.0730189 , -0.08534931, -0.01275937,\n",
            "           0.09062144,  0.04615173, -0.02734124,  0.02106691,\n",
            "          -0.03535959, -0.08256157,  0.12913978,  0.02704783,\n",
            "           0.04879972, -0.01569001, -0.01388762,  0.03570298,\n",
            "          -0.01455456,  0.0197239 ,  0.0830362 ,  0.05966683,\n",
            "           0.07741973, -0.0789151 , -0.105644  , -0.06022153]],\n",
            "\n",
            "        [[ 0.08758924, -0.05517194,  0.05702516,  0.10708377,\n",
            "          -0.11925049, -0.03550239,  0.13866036, -0.077084  ,\n",
            "           0.09195867, -0.0518985 , -0.02180975,  0.02071336,\n",
            "           0.11471535,  0.0963527 ,  0.11030308, -0.12262659,\n",
            "           0.08906279, -0.08450389, -0.14244479,  0.11484022,\n",
            "           0.10688809,  0.03647962, -0.12267335,  0.12980713,\n",
            "          -0.04347834,  0.00548032, -0.12233563, -0.01448329,\n",
            "          -0.07177961, -0.10123114, -0.0144809 ,  0.04654104]],\n",
            "\n",
            "        [[ 0.03782939,  0.1269201 ,  0.08049585,  0.05070779,\n",
            "          -0.04414065,  0.03340891, -0.10825917, -0.12431242,\n",
            "           0.0717251 ,  0.09378184,  0.05687805, -0.02080578,\n",
            "          -0.01133154, -0.07365052, -0.09479876,  0.0411536 ,\n",
            "           0.05902185,  0.12052424,  0.08089989, -0.06529094,\n",
            "          -0.13747199, -0.1350784 , -0.00036737, -0.02964802,\n",
            "          -0.11615554,  0.08652553, -0.14339562,  0.00238161,\n",
            "           0.13349923, -0.07748175,  0.08071343, -0.03476932]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([0.00564745, 0.00575184, 0.00561189, 0.00564333, 0.00557935,\n",
            "       0.00536721, 0.00548672, 0.00575975, 0.00604404, 0.00550545,\n",
            "       0.00569685, 0.00590295, 0.00571191, 0.00568212, 0.00574921,\n",
            "       0.00573382, 0.00559204, 0.00554901, 0.00566101, 0.00570602,\n",
            "       0.00550203, 0.00600863, 0.00543001, 0.00578629, 0.00573254,\n",
            "       0.00560171, 0.00562991, 0.00540037, 0.00557529, 0.00601533,\n",
            "       0.00568759, 0.00557825], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-0.01104863, -0.01569864,  0.00177612, ..., -0.01847203,\n",
            "         0.00310316,  0.00771448],\n",
            "       [-0.00925448, -0.00265528, -0.0087408 , ..., -0.00247854,\n",
            "         0.0007723 , -0.02143149],\n",
            "       [ 0.00774184, -0.02313373, -0.01894658, ..., -0.004254  ,\n",
            "        -0.02058014,  0.00213366],\n",
            "       ...,\n",
            "       [ 0.00313085,  0.00512195, -0.00227743, ..., -0.0040302 ,\n",
            "        -0.00072019, -0.00145574],\n",
            "       [ 0.00160082, -0.0177766 , -0.01249252, ..., -0.00406026,\n",
            "         0.00312158, -0.02011246],\n",
            "       [ 0.00019007, -0.01070052, -0.01990644, ..., -0.00559603,\n",
            "        -0.00999445, -0.00700347]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.00842417, -0.00555125, -0.00325719, -0.00645145, -0.00600843,\n",
            "       -0.00353425, -0.00389545, -0.00574814, -0.00842584, -0.00552653,\n",
            "       -0.00363381, -0.00842575, -0.00603284, -0.00454745, -0.00518222,\n",
            "       -0.0073994 , -0.00346652, -0.00333299, -0.00842554, -0.00363305,\n",
            "       -0.00400056, -0.00744497, -0.00576731, -0.00622624, -0.00382348,\n",
            "       -0.00700141, -0.00398429, -0.00696739, -0.00568952, -0.0071525 ,\n",
            "       -0.00590593, -0.00362756, -0.00581427, -0.0035934 , -0.00615328,\n",
            "       -0.00577438, -0.0063106 , -0.00667454, -0.00593763, -0.00514508,\n",
            "       -0.00590599, -0.00809625, -0.00638245, -0.00351065, -0.00644704,\n",
            "       -0.00913655, -0.00630396, -0.00649505, -0.00376223, -0.00842588,\n",
            "       -0.00842615, -0.00604389, -0.00365584, -0.00593873, -0.00576415,\n",
            "       -0.00484582, -0.00661672, -0.00825501, -0.00612159, -0.00661015,\n",
            "       -0.00331496, -0.00679756, -0.00609577, -0.00341438, -0.00564251,\n",
            "       -0.0080354 , -0.0075368 , -0.00600003, -0.00331273, -0.0035093 ,\n",
            "       -0.00629108, -0.00601081, -0.00362004, -0.00356843, -0.00362582,\n",
            "       -0.00615842, -0.00344443, -0.00842577, -0.00324133, -0.00341243,\n",
            "       -0.00600886, -0.00569651, -0.00370386, -0.00333893, -0.00651092,\n",
            "       -0.00576783, -0.00607937, -0.00803237, -0.00671545, -0.00500785,\n",
            "       -0.00782678, -0.00781939, -0.00573   , -0.00842585, -0.00574003,\n",
            "       -0.00490013, -0.00566727, -0.00568579, -0.00601775, -0.00686955,\n",
            "       -0.00842245, -0.00602241, -0.00619941, -0.00888851, -0.00563707,\n",
            "       -0.0035871 , -0.00643113, -0.00838527, -0.00376128, -0.00569968,\n",
            "       -0.00601837, -0.00396748, -0.00782878, -0.00645805, -0.00338571,\n",
            "       -0.00683478, -0.00327492, -0.00672262, -0.00636292, -0.00403743,\n",
            "       -0.00839901, -0.00739377, -0.00589352, -0.00595199, -0.00404924,\n",
            "       -0.00581757, -0.0041369 , -0.00534613], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[ 0.01920497,  0.05783387, -0.0979767 , ..., -0.1444712 ,\n",
            "         0.18752769, -0.15595494],\n",
            "       [ 0.1855257 , -0.16534883, -0.19107886, ..., -0.04171174,\n",
            "         0.13292825,  0.05250443],\n",
            "       [ 0.17774679,  0.1789255 , -0.07314532, ...,  0.04281954,\n",
            "         0.12669507,  0.04535551],\n",
            "       ...,\n",
            "       [-0.14799179,  0.10000856,  0.03800937, ..., -0.14066488,\n",
            "        -0.00318479, -0.11953481],\n",
            "       [-0.20608117, -0.08037669, -0.1288431 , ..., -0.09889741,\n",
            "        -0.00110024,  0.06943077],\n",
            "       [ 0.16364554, -0.19957103, -0.19758053, ..., -0.04074754,\n",
            "         0.00933902,  0.0485101 ]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-1.3179821 ,  0.33656466,  1.3389138 , -0.9665481 , -0.86602014,\n",
            "        4.2195244 , -2.2669628 , -2.7469888 ,  2.434175  , -0.2529714 ],\n",
            "      dtype=float32)>]\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.06202856,  0.05014295, -0.13210635, -0.02812419,\n",
            "          -0.06932499,  0.00484942, -0.02333109,  0.09960455,\n",
            "           0.08221591,  0.05807344,  0.09276387,  0.08513191,\n",
            "          -0.07835997, -0.01386511, -0.12508532,  0.03721204,\n",
            "           0.04695119,  0.08166332,  0.03454292,  0.11252072,\n",
            "           0.03706631,  0.10830042,  0.03283131,  0.05252631,\n",
            "          -0.03488038,  0.03010919,  0.13159613, -0.00925291,\n",
            "          -0.01023544,  0.09489118, -0.10082849, -0.14053127]],\n",
            "\n",
            "        [[ 0.00249597, -0.0783968 ,  0.1233348 ,  0.06705999,\n",
            "           0.04455622,  0.06970557, -0.13608931,  0.12992008,\n",
            "          -0.02727869,  0.13120602, -0.06019425,  0.08174113,\n",
            "           0.07721741,  0.05482655, -0.00259487, -0.09592575,\n",
            "           0.06706798, -0.06159519,  0.1392652 ,  0.0987114 ,\n",
            "          -0.01633115, -0.08949215, -0.01266699,  0.13684088,\n",
            "           0.14086436, -0.13885099, -0.05200045,  0.13710865,\n",
            "          -0.13077584, -0.11186041, -0.07764996,  0.10710786]],\n",
            "\n",
            "        [[-0.03069373,  0.00702035, -0.12879436, -0.10537256,\n",
            "          -0.02802309,  0.05892619, -0.12192397,  0.03425682,\n",
            "          -0.12366469,  0.10084802,  0.04794036,  0.05822574,\n",
            "           0.00668348, -0.07263146, -0.08305137, -0.09823068,\n",
            "          -0.05065713,  0.07076769, -0.03317459, -0.02624558,\n",
            "          -0.00258005, -0.01363758, -0.00982865,  0.08919286,\n",
            "           0.10976722,  0.07036143,  0.13991347, -0.13388212,\n",
            "           0.13103156, -0.037078  , -0.10752662, -0.0866694 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.07412991, -0.09595376,  0.04210574, -0.0476921 ,\n",
            "          -0.03610288,  0.03001294, -0.14109747, -0.07817936,\n",
            "          -0.08793124,  0.04588717, -0.08404898,  0.0604384 ,\n",
            "          -0.09408069, -0.00367751,  0.14138883,  0.09411197,\n",
            "          -0.02879274, -0.08985905,  0.0796673 , -0.11078194,\n",
            "          -0.0948124 , -0.06853653,  0.12520373,  0.13625085,\n",
            "          -0.11714021, -0.01037177,  0.13489549,  0.04826215,\n",
            "          -0.03527536, -0.08881437, -0.12745184,  0.09332817]],\n",
            "\n",
            "        [[ 0.11378999, -0.00791644,  0.07322919, -0.09426878,\n",
            "          -0.0334513 , -0.00302515,  0.0700658 , -0.06241706,\n",
            "          -0.0490274 , -0.079239  ,  0.07385737,  0.06505667,\n",
            "           0.00539763, -0.0419738 ,  0.08032528,  0.02251007,\n",
            "           0.12563002,  0.13094811,  0.02967912, -0.12132199,\n",
            "          -0.14012006,  0.09857967,  0.02680316, -0.09036358,\n",
            "          -0.05032411, -0.010203  , -0.07579824,  0.00898009,\n",
            "           0.01308346, -0.06985516,  0.04522499,  0.11637746]],\n",
            "\n",
            "        [[ 0.11213239,  0.00241366, -0.00729572, -0.07177906,\n",
            "           0.11773024,  0.12709284, -0.10576161,  0.05821696,\n",
            "          -0.05235052,  0.01336579,  0.09582432, -0.0530754 ,\n",
            "          -0.10397846, -0.01828397,  0.03170863,  0.08607525,\n",
            "           0.02994699, -0.11480095,  0.08653051, -0.09112059,\n",
            "          -0.05838883, -0.07402168,  0.04332776,  0.0007032 ,\n",
            "           0.07268424, -0.05909398, -0.07649388,  0.09262356,\n",
            "          -0.09645572,  0.13073309,  0.1012977 , -0.04572782]]],\n",
            "\n",
            "\n",
            "       [[[-0.0979704 , -0.08454851, -0.09056082,  0.00423675,\n",
            "          -0.10456272,  0.02287782, -0.12610416,  0.07786541,\n",
            "          -0.00419454,  0.0730189 , -0.08534931, -0.01275937,\n",
            "           0.09062144,  0.04615173, -0.02734124,  0.02106691,\n",
            "          -0.03535959, -0.08256157,  0.12913978,  0.02704783,\n",
            "           0.04879972, -0.01569001, -0.01388762,  0.03570298,\n",
            "          -0.01455456,  0.0197239 ,  0.0830362 ,  0.05966683,\n",
            "           0.07741973, -0.0789151 , -0.105644  , -0.06022153]],\n",
            "\n",
            "        [[ 0.08758924, -0.05517194,  0.05702516,  0.10708377,\n",
            "          -0.11925049, -0.03550239,  0.13866036, -0.077084  ,\n",
            "           0.09195867, -0.0518985 , -0.02180975,  0.02071336,\n",
            "           0.11471535,  0.0963527 ,  0.11030308, -0.12262659,\n",
            "           0.08906279, -0.08450389, -0.14244479,  0.11484022,\n",
            "           0.10688809,  0.03647962, -0.12267335,  0.12980713,\n",
            "          -0.04347834,  0.00548032, -0.12233563, -0.01448329,\n",
            "          -0.07177961, -0.10123114, -0.0144809 ,  0.04654104]],\n",
            "\n",
            "        [[ 0.03782939,  0.1269201 ,  0.08049585,  0.05070779,\n",
            "          -0.04414065,  0.03340891, -0.10825917, -0.12431242,\n",
            "           0.0717251 ,  0.09378184,  0.05687805, -0.02080578,\n",
            "          -0.01133154, -0.07365052, -0.09479876,  0.0411536 ,\n",
            "           0.05902185,  0.12052424,  0.08089989, -0.06529094,\n",
            "          -0.13747199, -0.1350784 , -0.00036737, -0.02964802,\n",
            "          -0.11615554,  0.08652553, -0.14339562,  0.00238161,\n",
            "           0.13349923, -0.07748175,  0.08071343, -0.03476932]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([0.00564745, 0.00575184, 0.00561189, 0.00564333, 0.00557935,\n",
            "       0.00536721, 0.00548672, 0.00575975, 0.00604404, 0.00550545,\n",
            "       0.00569685, 0.00590295, 0.00571191, 0.00568212, 0.00574921,\n",
            "       0.00573382, 0.00559204, 0.00554901, 0.00566101, 0.00570602,\n",
            "       0.00550203, 0.00600863, 0.00543001, 0.00578629, 0.00573254,\n",
            "       0.00560171, 0.00562991, 0.00540037, 0.00557529, 0.00601533,\n",
            "       0.00568759, 0.00557825], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-0.01104863, -0.01569864,  0.00177612, ..., -0.01847203,\n",
            "         0.00310316,  0.00771448],\n",
            "       [-0.00925448, -0.00265528, -0.0087408 , ..., -0.00247854,\n",
            "         0.0007723 , -0.02143149],\n",
            "       [ 0.00774184, -0.02313373, -0.01894658, ..., -0.004254  ,\n",
            "        -0.02058014,  0.00213366],\n",
            "       ...,\n",
            "       [ 0.00313085,  0.00512195, -0.00227743, ..., -0.0040302 ,\n",
            "        -0.00072019, -0.00145574],\n",
            "       [ 0.00160082, -0.0177766 , -0.01249252, ..., -0.00406026,\n",
            "         0.00312158, -0.02011246],\n",
            "       [ 0.00019007, -0.01070052, -0.01990644, ..., -0.00559603,\n",
            "        -0.00999445, -0.00700347]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.00842417, -0.00555125, -0.00325719, -0.00645145, -0.00600843,\n",
            "       -0.00353425, -0.00389545, -0.00574814, -0.00842584, -0.00552653,\n",
            "       -0.00363381, -0.00842575, -0.00603284, -0.00454745, -0.00518222,\n",
            "       -0.0073994 , -0.00346652, -0.00333299, -0.00842554, -0.00363305,\n",
            "       -0.00400056, -0.00744497, -0.00576731, -0.00622624, -0.00382348,\n",
            "       -0.00700141, -0.00398429, -0.00696739, -0.00568952, -0.0071525 ,\n",
            "       -0.00590593, -0.00362756, -0.00581427, -0.0035934 , -0.00615328,\n",
            "       -0.00577438, -0.0063106 , -0.00667454, -0.00593763, -0.00514508,\n",
            "       -0.00590599, -0.00809625, -0.00638245, -0.00351065, -0.00644704,\n",
            "       -0.00913655, -0.00630396, -0.00649505, -0.00376223, -0.00842588,\n",
            "       -0.00842615, -0.00604389, -0.00365584, -0.00593873, -0.00576415,\n",
            "       -0.00484582, -0.00661672, -0.00825501, -0.00612159, -0.00661015,\n",
            "       -0.00331496, -0.00679756, -0.00609577, -0.00341438, -0.00564251,\n",
            "       -0.0080354 , -0.0075368 , -0.00600003, -0.00331273, -0.0035093 ,\n",
            "       -0.00629108, -0.00601081, -0.00362004, -0.00356843, -0.00362582,\n",
            "       -0.00615842, -0.00344443, -0.00842577, -0.00324133, -0.00341243,\n",
            "       -0.00600886, -0.00569651, -0.00370386, -0.00333893, -0.00651092,\n",
            "       -0.00576783, -0.00607937, -0.00803237, -0.00671545, -0.00500785,\n",
            "       -0.00782678, -0.00781939, -0.00573   , -0.00842585, -0.00574003,\n",
            "       -0.00490013, -0.00566727, -0.00568579, -0.00601775, -0.00686955,\n",
            "       -0.00842245, -0.00602241, -0.00619941, -0.00888851, -0.00563707,\n",
            "       -0.0035871 , -0.00643113, -0.00838527, -0.00376128, -0.00569968,\n",
            "       -0.00601837, -0.00396748, -0.00782878, -0.00645805, -0.00338571,\n",
            "       -0.00683478, -0.00327492, -0.00672262, -0.00636292, -0.00403743,\n",
            "       -0.00839901, -0.00739377, -0.00589352, -0.00595199, -0.00404924,\n",
            "       -0.00581757, -0.0041369 , -0.00534613], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[ 0.01920497,  0.05783387, -0.0979767 , ..., -0.1444712 ,\n",
            "         0.18752769, -0.15595494],\n",
            "       [ 0.1855257 , -0.16534883, -0.19107886, ..., -0.04171174,\n",
            "         0.13292825,  0.05250443],\n",
            "       [ 0.17774679,  0.1789255 , -0.07314532, ...,  0.04281954,\n",
            "         0.12669507,  0.04535551],\n",
            "       ...,\n",
            "       [-0.14799179,  0.10000856,  0.03800937, ..., -0.14066488,\n",
            "        -0.00318479, -0.11953481],\n",
            "       [-0.20608117, -0.08037669, -0.1288431 , ..., -0.09889741,\n",
            "        -0.00110024,  0.06943077],\n",
            "       [ 0.16364554, -0.19957103, -0.19758053, ..., -0.04074754,\n",
            "         0.00933902,  0.0485101 ]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-1.2170718 ,  0.41640353,  1.3878798 , -0.8689388 , -0.7698752 ,\n",
            "        3.5236135 , -2.1571589 , -2.632729  ,  2.3935153 , -0.16393414],\n",
            "      dtype=float32)>]\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.06202856,  0.05014295, -0.13210635, -0.02812419,\n",
            "          -0.06932499,  0.00484942, -0.02333109,  0.09960455,\n",
            "           0.08221591,  0.05807344,  0.09276387,  0.08513191,\n",
            "          -0.07835997, -0.01386511, -0.12508532,  0.03721204,\n",
            "           0.04695119,  0.08166332,  0.03454292,  0.11252072,\n",
            "           0.03706631,  0.10830042,  0.03283131,  0.05252631,\n",
            "          -0.03488038,  0.03010919,  0.13159613, -0.00925291,\n",
            "          -0.01023544,  0.09489118, -0.10082849, -0.14053127]],\n",
            "\n",
            "        [[ 0.00249597, -0.0783968 ,  0.1233348 ,  0.06705999,\n",
            "           0.04455622,  0.06970557, -0.13608931,  0.12992008,\n",
            "          -0.02727869,  0.13120602, -0.06019425,  0.08174113,\n",
            "           0.07721741,  0.05482655, -0.00259487, -0.09592575,\n",
            "           0.06706798, -0.06159519,  0.1392652 ,  0.0987114 ,\n",
            "          -0.01633115, -0.08949215, -0.01266699,  0.13684088,\n",
            "           0.14086436, -0.13885099, -0.05200045,  0.13710865,\n",
            "          -0.13077584, -0.11186041, -0.07764996,  0.10710786]],\n",
            "\n",
            "        [[-0.03069373,  0.00702035, -0.12879436, -0.10537256,\n",
            "          -0.02802309,  0.05892619, -0.12192397,  0.03425682,\n",
            "          -0.12366469,  0.10084802,  0.04794036,  0.05822574,\n",
            "           0.00668348, -0.07263146, -0.08305137, -0.09823068,\n",
            "          -0.05065713,  0.07076769, -0.03317459, -0.02624558,\n",
            "          -0.00258005, -0.01363758, -0.00982865,  0.08919286,\n",
            "           0.10976722,  0.07036143,  0.13991347, -0.13388212,\n",
            "           0.13103156, -0.037078  , -0.10752662, -0.0866694 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.07412991, -0.09595376,  0.04210574, -0.0476921 ,\n",
            "          -0.03610288,  0.03001294, -0.14109747, -0.07817936,\n",
            "          -0.08793124,  0.04588717, -0.08404898,  0.0604384 ,\n",
            "          -0.09408069, -0.00367751,  0.14138883,  0.09411197,\n",
            "          -0.02879274, -0.08985905,  0.0796673 , -0.11078194,\n",
            "          -0.0948124 , -0.06853653,  0.12520373,  0.13625085,\n",
            "          -0.11714021, -0.01037177,  0.13489549,  0.04826215,\n",
            "          -0.03527536, -0.08881437, -0.12745184,  0.09332817]],\n",
            "\n",
            "        [[ 0.11378999, -0.00791644,  0.07322919, -0.09426878,\n",
            "          -0.0334513 , -0.00302515,  0.0700658 , -0.06241706,\n",
            "          -0.0490274 , -0.079239  ,  0.07385737,  0.06505667,\n",
            "           0.00539763, -0.0419738 ,  0.08032528,  0.02251007,\n",
            "           0.12563002,  0.13094811,  0.02967912, -0.12132199,\n",
            "          -0.14012006,  0.09857967,  0.02680316, -0.09036358,\n",
            "          -0.05032411, -0.010203  , -0.07579824,  0.00898009,\n",
            "           0.01308346, -0.06985516,  0.04522499,  0.11637746]],\n",
            "\n",
            "        [[ 0.11213239,  0.00241366, -0.00729572, -0.07177906,\n",
            "           0.11773024,  0.12709284, -0.10576161,  0.05821696,\n",
            "          -0.05235052,  0.01336579,  0.09582432, -0.0530754 ,\n",
            "          -0.10397846, -0.01828397,  0.03170863,  0.08607525,\n",
            "           0.02994699, -0.11480095,  0.08653051, -0.09112059,\n",
            "          -0.05838883, -0.07402168,  0.04332776,  0.0007032 ,\n",
            "           0.07268424, -0.05909398, -0.07649388,  0.09262356,\n",
            "          -0.09645572,  0.13073309,  0.1012977 , -0.04572782]]],\n",
            "\n",
            "\n",
            "       [[[-0.0979704 , -0.08454851, -0.09056082,  0.00423675,\n",
            "          -0.10456272,  0.02287782, -0.12610416,  0.07786541,\n",
            "          -0.00419454,  0.0730189 , -0.08534931, -0.01275937,\n",
            "           0.09062144,  0.04615173, -0.02734124,  0.02106691,\n",
            "          -0.03535959, -0.08256157,  0.12913978,  0.02704783,\n",
            "           0.04879972, -0.01569001, -0.01388762,  0.03570298,\n",
            "          -0.01455456,  0.0197239 ,  0.0830362 ,  0.05966683,\n",
            "           0.07741973, -0.0789151 , -0.105644  , -0.06022153]],\n",
            "\n",
            "        [[ 0.08758924, -0.05517194,  0.05702516,  0.10708377,\n",
            "          -0.11925049, -0.03550239,  0.13866036, -0.077084  ,\n",
            "           0.09195867, -0.0518985 , -0.02180975,  0.02071336,\n",
            "           0.11471535,  0.0963527 ,  0.11030308, -0.12262659,\n",
            "           0.08906279, -0.08450389, -0.14244479,  0.11484022,\n",
            "           0.10688809,  0.03647962, -0.12267335,  0.12980713,\n",
            "          -0.04347834,  0.00548032, -0.12233563, -0.01448329,\n",
            "          -0.07177961, -0.10123114, -0.0144809 ,  0.04654104]],\n",
            "\n",
            "        [[ 0.03782939,  0.1269201 ,  0.08049585,  0.05070779,\n",
            "          -0.04414065,  0.03340891, -0.10825917, -0.12431242,\n",
            "           0.0717251 ,  0.09378184,  0.05687805, -0.02080578,\n",
            "          -0.01133154, -0.07365052, -0.09479876,  0.0411536 ,\n",
            "           0.05902185,  0.12052424,  0.08089989, -0.06529094,\n",
            "          -0.13747199, -0.1350784 , -0.00036737, -0.02964802,\n",
            "          -0.11615554,  0.08652553, -0.14339562,  0.00238161,\n",
            "           0.13349923, -0.07748175,  0.08071343, -0.03476932]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([0.00564745, 0.00575184, 0.00561189, 0.00564333, 0.00557935,\n",
            "       0.00536721, 0.00548672, 0.00575975, 0.00604404, 0.00550545,\n",
            "       0.00569685, 0.00590295, 0.00571191, 0.00568212, 0.00574921,\n",
            "       0.00573382, 0.00559204, 0.00554901, 0.00566101, 0.00570602,\n",
            "       0.00550203, 0.00600863, 0.00543001, 0.00578629, 0.00573254,\n",
            "       0.00560171, 0.00562991, 0.00540037, 0.00557529, 0.00601533,\n",
            "       0.00568759, 0.00557825], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-0.01104863, -0.01569864,  0.00177612, ..., -0.01847203,\n",
            "         0.00310316,  0.00771448],\n",
            "       [-0.00925448, -0.00265528, -0.0087408 , ..., -0.00247854,\n",
            "         0.0007723 , -0.02143149],\n",
            "       [ 0.00774184, -0.02313373, -0.01894658, ..., -0.004254  ,\n",
            "        -0.02058014,  0.00213366],\n",
            "       ...,\n",
            "       [ 0.00313085,  0.00512195, -0.00227743, ..., -0.0040302 ,\n",
            "        -0.00072019, -0.00145574],\n",
            "       [ 0.00160082, -0.0177766 , -0.01249252, ..., -0.00406026,\n",
            "         0.00312158, -0.02011246],\n",
            "       [ 0.00019007, -0.01070052, -0.01990644, ..., -0.00559603,\n",
            "        -0.00999445, -0.00700347]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.00842417, -0.00555125, -0.00325719, -0.00645145, -0.00600843,\n",
            "       -0.00353425, -0.00389545, -0.00574814, -0.00842584, -0.00552653,\n",
            "       -0.00363381, -0.00842575, -0.00603284, -0.00454745, -0.00518222,\n",
            "       -0.0073994 , -0.00346652, -0.00333299, -0.00842554, -0.00363305,\n",
            "       -0.00400056, -0.00744497, -0.00576731, -0.00622624, -0.00382348,\n",
            "       -0.00700141, -0.00398429, -0.00696739, -0.00568952, -0.0071525 ,\n",
            "       -0.00590593, -0.00362756, -0.00581427, -0.0035934 , -0.00615328,\n",
            "       -0.00577438, -0.0063106 , -0.00667454, -0.00593763, -0.00514508,\n",
            "       -0.00590599, -0.00809625, -0.00638245, -0.00351065, -0.00644704,\n",
            "       -0.00913655, -0.00630396, -0.00649505, -0.00376223, -0.00842588,\n",
            "       -0.00842615, -0.00604389, -0.00365584, -0.00593873, -0.00576415,\n",
            "       -0.00484582, -0.00661672, -0.00825501, -0.00612159, -0.00661015,\n",
            "       -0.00331496, -0.00679756, -0.00609577, -0.00341438, -0.00564251,\n",
            "       -0.0080354 , -0.0075368 , -0.00600003, -0.00331273, -0.0035093 ,\n",
            "       -0.00629108, -0.00601081, -0.00362004, -0.00356843, -0.00362582,\n",
            "       -0.00615842, -0.00344443, -0.00842577, -0.00324133, -0.00341243,\n",
            "       -0.00600886, -0.00569651, -0.00370386, -0.00333893, -0.00651092,\n",
            "       -0.00576783, -0.00607937, -0.00803237, -0.00671545, -0.00500785,\n",
            "       -0.00782678, -0.00781939, -0.00573   , -0.00842585, -0.00574003,\n",
            "       -0.00490013, -0.00566727, -0.00568579, -0.00601775, -0.00686955,\n",
            "       -0.00842245, -0.00602241, -0.00619941, -0.00888851, -0.00563707,\n",
            "       -0.0035871 , -0.00643113, -0.00838527, -0.00376128, -0.00569968,\n",
            "       -0.00601837, -0.00396748, -0.00782878, -0.00645805, -0.00338571,\n",
            "       -0.00683478, -0.00327492, -0.00672262, -0.00636292, -0.00403743,\n",
            "       -0.00839901, -0.00739377, -0.00589352, -0.00595199, -0.00404924,\n",
            "       -0.00581757, -0.0041369 , -0.00534613], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[ 0.01920497,  0.05783387, -0.0979767 , ..., -0.1444712 ,\n",
            "         0.18752769, -0.15595494],\n",
            "       [ 0.1855257 , -0.16534883, -0.19107886, ..., -0.04171174,\n",
            "         0.13292825,  0.05250443],\n",
            "       [ 0.17774679,  0.1789255 , -0.07314532, ...,  0.04281954,\n",
            "         0.12669507,  0.04535551],\n",
            "       ...,\n",
            "       [-0.14799179,  0.10000856,  0.03800937, ..., -0.14066488,\n",
            "        -0.00318479, -0.11953481],\n",
            "       [-0.20608117, -0.08037669, -0.1288431 , ..., -0.09889741,\n",
            "        -0.00110024,  0.06943077],\n",
            "       [ 0.16364554, -0.19957103, -0.19758053, ..., -0.04074754,\n",
            "         0.00933902,  0.0485101 ]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-1.1187012 ,  0.4835708 ,  1.4047084 , -0.77491266, -0.6776794 ,\n",
            "        2.9679546 , -2.0483577 , -2.5190957 ,  2.2762895 , -0.08207208],\n",
            "      dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MclZYfOldN"
      },
      "source": [
        "再テストの実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jAmhPk_tOldN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0710c2-7908-4624-9b71-51c9be939005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Test Loss: 3.651007890701294, Test Accuracy: 8.920000076293945\n",
            "Epoch 2, Test Loss: 3.651007890701294, Test Accuracy: 8.920000076293945\n",
            "Epoch 3, Test Loss: 3.651007890701294, Test Accuracy: 8.920000076293945\n",
            "Epoch 4, Test Loss: 3.651007890701294, Test Accuracy: 8.920000076293945\n",
            "Epoch 5, Test Loss: 3.651007890701294, Test Accuracy: 8.920000076293945\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQmyQyMYKM4P"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('pythonenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d1685d247089585e01bacc0e11595c4779ea690fa157e920ca16120e3c1da301"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}