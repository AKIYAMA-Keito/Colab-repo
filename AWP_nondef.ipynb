{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKIYAMA-Keito/Colab-repo/blob/main/AWP_nondef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d1Z8uIInOldG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKEv8KiMOldH"
      },
      "source": [
        "Step1 Tensorflowチュートリアル4から引用"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "version2\n"
      ],
      "metadata": {
        "id": "Yk9ofpRIRw2k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVrpxk0rOldI"
      },
      "source": [
        "データセットを読み込んで正規化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QobaZNJyOldJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf60389-55c2-4d73-808d-d91e1ae64bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "random_index_train = np.array(range(len(x_train)))\n",
        "np.random.shuffle(random_index_train)\n",
        "x_train = x_train[random_index_train][:1000]\n",
        "y_train = y_train[random_index_train][:1000]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test/255.0\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNcHvWE9OldJ"
      },
      "source": [
        "データセットをシャッフルしてバッチ化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wg2lQwV_OldJ"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)\n",
        ").batch(1000)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_test, y_test)\n",
        ").batch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQHK9sMOldK"
      },
      "source": [
        "CNNモデルを定義しインスタンスを取り出す．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1-UIMbDyOldK"
      },
      "outputs": [],
      "source": [
        "class CNNModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32, 3, activation = \"relu\")\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation = \"relu\")\n",
        "        self.d2 = Dense(10)\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return x\n",
        "\n",
        "model = CNNModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R46fxEjOOldK"
      },
      "source": [
        "損失関数とoptmizerを選択する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9pzC_gytOldL"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph_DSqV9OldL"
      },
      "source": [
        "損失関数とoptimizerの尺度評価のための関数を導入する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MipedjyLOldL"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD6sZQRdOldL"
      },
      "source": [
        "モデルを訓練するための関数train_stepを定義する．\n",
        "予測値と正解ラベルの間の損失関数の勾配を最適化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KCmbB-cnOldL"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training = True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdL3GJY2OldM"
      },
      "source": [
        "モデルをテストするための関数test_stepを定義する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IsRpIQFEOldM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images, training = False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    \n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D-PUsW-OldM"
      },
      "source": [
        "学習を実行してテストし，結果を出力する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJEwX2bUOldM",
        "outputId": "ba4256d1-f730-4e00-e9a3-17093f69d23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.296882152557373, Accuracy: 12.199999809265137, Test Loss: 1.9357314109802246, Test Accuracy: 46.650001525878906\n",
            "Epoch 2, Loss: 1.9050135612487793, Accuracy: 51.099998474121094, Test Loss: 1.5488656759262085, Test Accuracy: 69.44000244140625\n",
            "Epoch 3, Loss: 1.4882415533065796, Accuracy: 75.70000457763672, Test Loss: 1.2314039468765259, Test Accuracy: 75.97000122070312\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "    \n",
        "    for train_images, train_labels in train_ds:\n",
        "        train_step(train_images, train_labels)\n",
        "    \n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Loss: {train_loss.result()}, '\n",
        "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTaFZYwFOldM"
      },
      "source": [
        "AWPのアルゴリズムを記述する．\n",
        "まず，学習済みのmodelから重みを取り出してvを加えて再設定する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RwzvYTxcOldM"
      },
      "outputs": [],
      "source": [
        "# weights = model.get_weights()\n",
        "# ordinary_weights = weights\n",
        "# new_weights = []\n",
        "# v_array = []\n",
        "# for w in weights:\n",
        "#   v = 0.02 * np.random.rand() - 0.01\n",
        "#   new_weights.append(w + v)\n",
        "#   v_array.append(tf.fill(w.shape, v))\n",
        "# model.set_weights(new_weights)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()\n",
        "ordinary_weights = weights\n",
        "v_array = []\n",
        "for w in weights:\n",
        "  v = 0.02 * np.random.rand() - 0.01\n",
        "  v_array.append(tf.fill(w.shape, v))"
      ],
      "metadata": {
        "id": "XRSISCKw7GT9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKvxUYsOldM"
      },
      "source": [
        "Step2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "    weights = model.get_weights()\n",
        "    new_weights = []\n",
        "    for w, v in zip(weights, additive_weights):\n",
        "      new_weights.append(w + v)\n",
        "    model.set_weights(new_weights)\n",
        "\n",
        "    adversarial_image_list = []\n",
        "    # eps1 = 1\n",
        "    # eta1 = 0.1\n",
        "    for (images, labels) in dataset:\n",
        "      for (image, label) in zip(images, labels):\n",
        "        image = tf.Variable([image])\n",
        "\n",
        "        initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        image_dashed = tf.add(image, initial_noise)\n",
        "\n",
        "        # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "        # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "        # image_dashed_list = []\n",
        "        # for image_0 in image:\n",
        "        #   for image_h in image_0:\n",
        "        #     for image_v in image_h:\n",
        "        #       for image_pixel in image_v:\n",
        "        #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "        # image_dashed_list.append(image_pixel_dashed)\n",
        "        # # image_dashed = np.array(image_dashed_list)\n",
        "        # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "        # print(image_dashed.numpy())\n",
        "\n",
        "        for j in range(5):\n",
        "          with tf.GradientTape() as tape:\n",
        "            tape.watch(image_dashed)\n",
        "            prediction = model(image_dashed, training = True)\n",
        "            loss = loss_object(label, prediction)\n",
        "          gradients = tape.gradient(loss, image_dashed)\n",
        "          image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "          difference = tf.subtract(image_med, image)\n",
        "          if tf.norm(difference) <= eps1:\n",
        "            image_dashed = image_med \n",
        "          else:\n",
        "            image_dashed = difference\n",
        "            image_dashed = tf.multiply(image_dashed, eps1)\n",
        "            image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "            image_dashed = tf.add(image_dashed, image)\n",
        "        adversarial_image_list.append(image_dashed[0])\n",
        "        adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "    return adversarial_image\n",
        "\n",
        "    # def calculate_loss(adversarial_dataset, batch_size = 100):\n",
        "    #   # batch_size = 100\n",
        "    #   loss_sum = 0.0\n",
        "    #   for (images, labels) in adversarial_ds:\n",
        "    #     predictions = model(images, training = True)\n",
        "    #     loss = loss_object(labels, predictions)\n",
        "    #     loss_sum_batch = loss * batch_size\n",
        "    #     loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "    #   average_loss = tf.divide(loss_sum, 1000)\n",
        "    # return average_loss"
      ],
      "metadata": {
        "id": "V3j-1XQM1lMS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "# weights = model.get_weights()\n",
        "# new_weights = []\n",
        "# for w, v in zip(weights, v_array):\n",
        "#   new_weights.append(w + v)\n",
        "# model.set_weights(new_weights)\n",
        "\n",
        "# adversarial_image_list = []\n",
        "# eps1 = 1\n",
        "# eta1 = 0.1\n",
        "# for (images, labels) in train_ds:\n",
        "#   for (image, label) in zip(images, labels):\n",
        "#     image = tf.Variable([image])\n",
        "\n",
        "#     initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     image_dashed = tf.add(image, initial_noise)\n",
        "#     # print(image)\n",
        "#     # print(image_dashed)\n",
        "\n",
        "#     # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "#     # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "#     # image_dashed_list = []\n",
        "#     # for image_0 in image:\n",
        "#     #   for image_h in image_0:\n",
        "#     #     for image_v in image_h:\n",
        "#     #       for image_pixel in image_v:\n",
        "#     #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "#     # image_dashed_list.append(image_pixel_dashed)\n",
        "#     # # image_dashed = np.array(image_dashed_list)\n",
        "#     # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "#     # print(image_dashed.numpy())\n",
        "\n",
        "#     for j in range(1):\n",
        "#       with tf.GradientTape() as tape:\n",
        "#         tape.watch(image_dashed)\n",
        "#         prediction = model(image_dashed, training = False)\n",
        "#         # print(prediction)\n",
        "#         loss = loss_object(label, prediction)\n",
        "#       gradients = tape.gradient(loss, image_dashed)\n",
        "#       image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "#       difference = tf.subtract(image_med, image)\n",
        "#       if tf.norm(difference) <= eps1:\n",
        "#         image_dashed = image_med \n",
        "#       else:\n",
        "#         image_dashed = difference\n",
        "#         image_dashed = tf.multiply(image_dashed, eps1)\n",
        "#         image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "#         image_dashed = tf.add(image_dashed, image)\n",
        "#     adversarial_image_list.append(image_dashed[0])\n",
        "#     adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "# print(adversarial_image[0] - x_train[0])\n",
        "\n",
        "# # print(adversarial_image)"
      ],
      "metadata": {
        "id": "2HGcWwIkljvE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adversarial = adversary(train_ds, v_array)"
      ],
      "metadata": {
        "id": "LzKpbHhf5dup"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Mpzb3j_c8kKF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(10):\n",
        "plt.imshow(np.squeeze(x_adversarial[0] - x_train[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "aMZJZZYgA04d",
        "outputId": "7be2f5c9-601b-4dcc-bd81-1c4882ee01f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAX8UlEQVR4nO2dXWxkZ3nH/8982h7bu/Zu1tls9ivJAgkVXVo30BIhKgRNcpPQi4hcoLRFLBcgQcVFEb0gl1FVQFxUSEsTESoKpQVEkMJHGiFFFIHipNtk872BXbJer727/v6az6cXHqgJ+/5fZ8aemfL+f5Ll8TzznvPOOed/jmf+53kec3cIIX7/yXR7AkKIziCxC5EIErsQiSCxC5EIErsQiZDr6Mr6Sl4YGg2/wPh4q5Ng5LQV8xwiq25v4Ts9nk0+tuzY6T5Rs8Zjx2JsfDsrb+NgrCzNora2ctUltCV2M7sdwBcBZAH8s7s/wF5fGBrFW/7yb4Pxep6/y+JCIzy2yMdGd14be8fC02qunIczdf4CepIDUC+E31xs2WwsEH9vsbk5OZnElu1ZHo9tV7buGLGxseOlrXVH3jdb9sv//oVgrOUpmVkWwD8BuAPALQDuNbNbWl2eEGJnaecz+60Azrj7L9y9AuAbAO7anmkJIbabdsR+AMBrm/4+33zutzCzE2Y2YWYTtfWVNlYnhGiHHf823t1Puvu4u4/n+ko7vTohRIB2xD4J4OCmv69vPieE6EHaEfuTAI6Z2VEzKwD4IIBHtmdaQojtpmXrzd1rZvZxAD/EhvX2kLs/x8aYA9n1cDxT5X4Gs96y69wDWjxaoPH+S3x8Ixu2qPLLfGzMpmlELEfE7K9GeAWNAj+f1/p5PLfKV96IWHdsfMwOjS07W47YisSOjR1r9T6+XRoReyy31vrcqgORdefDMXasteWzu/ujAB5tZxlCiM6g22WFSASJXYhEkNiFSASJXYhEkNiFSASJXYhE6Gg+OxwwUs227wr3dAsL1WAsu1yhYweL/LyWXePr9hzx2Rf5uj3L152pcJ9+7dp+Gs/P14Kxeix9lnj0AODGve7CQnjdAFAdDBvS/dPkpgsA1UFiKAMoXlqlcZC514aKdGhhjh8P9X4unVzkeKwNhe/7aOT4+/YM2Sdkd+rKLkQiSOxCJILELkQiSOxCJILELkQiSOxCJEJnrbcIsaqa+dmw1VLZx6vg5Be5RRRjdU/YKvEMt3HyS2HLEAAaOX7O7Zteo/HKSHj9/b9aoGOXbialvRGvkpqpcmvuylvDh9jYCreY5m/iacm7SNoxwG2/WOpudZC/8Vg14+ICP5gH/ztc52V9z8FgDAAaRLUsbVhXdiESQWIXIhEkdiESQWIXIhEkdiESQWIXIhEkdiESobM+u/FOrbVIGmp1JJzqWRvgvqbVeCpnfpn78PmVsC8bKwVtde7pru7nKazZCh9f3hV+7+WRPXRsfjmSyhnxk+fezL3w0oXwdl+9lvvspWk+t8UjfHyGZJl6xKOv9fF4PuLT91/grc5q58M+e2FhPx1bHubvO4Su7EIkgsQuRCJI7EIkgsQuRCJI7EIkgsQuRCJI7EIkQkd9djeeH11YbL31cf8k9zVBSlgDQG13H41niE9fj3i2sXx1Vl4bAJb3892ULYdjSzfyuQ1c4PHZ49xPLl0/T+OXZgfCwSrfLvndvNT0TWOXafzI4GwwNpTjy96V5TUEHpt+C40vfZl75cMvhusvxNpJF5bD8QzZXW2J3czOAlgCUAdQc/fxdpYnhNg5tuPK/ufuzk+xQoiuo8/sQiRCu2J3AD8ys6fM7MTVXmBmJ8xswswmauuRz9VCiB2j3X/jb3P3STPbB+AxM3vR3Z/Y/AJ3PwngJAAMXHOQf/MghNgx2rqyu/tk8/cMgO8AuHU7JiWE2H5aFruZlcxs6NePAbwfwOntmpgQYntp59/4MQDfsY22uDkA/+ruP2ADzIEsyzEmbZEBoF4M52038hGfvMw9/Gyk7XJjJLx8y0U+nUR8+JV9PBd/5QAfv/tPZoKxQ33cL55aHKbxvXme579a5vnshw+GjZrZVZ7Hf2g39/BfnLyWxn9ZCOfyDw1wn/2+oz+j8c/e8D0a/5t3f4TGd50+EIzFdMDuVWFHYstid/dfAPjDVscLITqLrDchEkFiFyIRJHYhEkFiFyIRJHYhEqHjKa517pBR6v3hc1N2nadiVka4RZSp8fK8fa+FWx+vHtlNxy5dz1s6NyJWS6PIrb2bR6eDsf86e5SOjXHjKM9xupwbpPE5Yq+tLPGD4eX1a2h8oMTts+X5cHptf5FbrQ+e+TMaf3r832gcQ7xNd3U0PDfWdnkr8RC6sguRCBK7EIkgsQuRCBK7EIkgsQuRCBK7EIkgsQuRCJ1t2QzuEdYLsbLH4ZrJXoictyJZqNG0wmLYh8/U+cIHJ7mnWxniPvyBP75A4y/O7QvGqvPcyz5whPvoz54Pp2ICQL7AU2D9dDiFto9vFvRf4tu1OsD3WXEkHFuZ5PddVPbx93X3K39B49lpvk/nSCXq0kWejk3bTZOQruxCJILELkQiSOxCJILELkQiSOxCJILELkQiSOxCJEJHfXZr8HazjTz3TbMrxGev8HLMHvGyc4s8/7i2Kzw+U+W59Mz7BIAMt3QxeZnny5cGwtulMMJzvq/8lJdjRol73TYf8boXw7E63yXR+y6K83xuOVJFu3JHuD4BAFRmwi2VAeDV791I46MzfG7ZCmm7HDmeGll+rAeX29IoIcT/OyR2IRJBYhciESR2IRJBYhciESR2IRJBYhciETqfz85OL7Gcc5JTXh/gb2V9L68LPzDJc4jXR8P5zwOTq3RsdTc3lAcvcKN9cA/3hBfXw8s/tHeOjv3lrnD9cgAYerW96wHL9c+Gbw8AANz01y/R+OlHSFI4gNGXwtt1NuKjx+6NyJP7RQCgFumPYORwK+/mxzLz6JmGonvSzB4ysxkzO73puVEze8zMXmn+JmUChBC9wFZO218BcPvrnvs0gMfd/RiAx5t/CyF6mKjY3f0JALOve/ouAA83Hz8M4O5tnpcQYptp9QPZmLtPNR9fBDAWeqGZnTCzCTObqJVXWlydEKJd2v423t0d5GsBdz/p7uPuPp4rRr4UEULsGK2KfdrM9gNA8/fM9k1JCLETtCr2RwDc13x8H4Dvbs90hBA7RdRnN7OvA3gPgL1mdh7AZwE8AOCbZvZhAOcA3LOltRnvRd6/wL1uuuga9z3rkVz5mK/K4p7l58zyrkj+sfGVT70U/EoEALD78HwwNr8W7o8OAHtv5nXjFxbCNekBRLdbZSS8XzzP99mTT76JxhvHeOH5bDl8b8Su5+hQDF7gx2J+OVIvP1bDgNx/EKvrsLaHyJYMjYrd3e8NhN4bGyuE6B10u6wQiSCxC5EIErsQiSCxC5EIErsQidDxFFeWglcvRvwKJzZOpOVyYTlSnrfA7bHCfNhqqZX4ZoyVRKYpiwD6Zvjc3ndbOBX0++dupmPzEVdw1zv5/VKlAre/Vqvh1OJLc0N0rDf4drN53nY5t0bKNUfaRcfSrYuXSZ1qAGvX8tThzFrY2ivv5u/LGjuU4iqE+P1AYhciESR2IRJBYhciESR2IRJBYhciESR2IRKhoz67G9AgFmKtFktDJXGSMggAFolXh/im6L8QLqkVS3G1fbyMdXkXHx9Ll/yP028Pxm667hIde3mV+8G5DL8/YaTIy2ifmz4YjNWX+Ta3Kt8uu17kNwnsPhOuVV3r52NjaaYZ0j4cAPqn+PG2cngwGIvtb2c6ICFd2YVIBIldiESQ2IVIBIldiESQ2IVIBIldiESQ2IVIhI767OZAphqOZ3h1XppzTnN8AXg2khsdKUW9vi/sR/fNcK85v8q96vVRvhvYNgMAr4fP2a/N7aZj1xZ5b2Fb5n703AFeqjpDfPrS8/z+A4/k2mdJvjoA1AbCC8hU+dj+Sd6qrHzdMI0XLy7TeOlX4eUvHAt78IDy2YUQESR2IRJBYhciESR2IRJBYhciESR2IRJBYhciETpeN57l6ubWuR/N6rMXrvA63vUi95P7Ii14c0vhQuNX3sY911w54gfzqaH4p1dovEA26vJKez66D/DWxWsXuCc89tPw3FYj3aBLF/nxkFuP1NufDh8TlZEiHVsv8XsAsquRls2R+zrq/eHlZyP3AFRK5BrdTj67mT1kZjNmdnrTc/eb2aSZnWr+3BlbjhCiu2zl3/ivALj9Ks9/wd2PN38e3d5pCSG2m6jY3f0JALMdmIsQYgdp5wu6j5vZM81/80dCLzKzE2Y2YWYTtXV+v7EQYudoVexfAnAjgOMApgB8LvRCdz/p7uPuPp7rK7W4OiFEu7Qkdnefdve6uzcAfBnArds7LSHEdtOS2M1s/6Y/PwDgdOi1QojeIOqzm9nXAbwHwF4zOw/gswDeY2bHsZE9exbAR7e6wgyxbWO1unMz4cTu7ORlOrZ/INLzusY93ZVD4Y8gsbzrxcP8nPrmO16h8Rdnxmi8Ug57to1ID3Mv8vdtuUje93U8b7syHL4HYXCKrzu/xD3+TKQXwNp14Vz74mXeoD1WH6FRjOx0cB+f3TNSL3AdeIsfvqNid/d7r/L0g62tTgjRLXS7rBCJILELkQgSuxCJILELkQgSuxCJ0NkUVwcypGRzcS5SSzoTtiR8mKdaxsjErLd9rZ8Xs++Yo/HTF/bTeK3Cd1PhbNjmyZQjJbQb3EJafytPHa7VIq2P7wy/97UfBO+y3hib48uOleiuF8L7zPN8fzZYW2QA2TV+rGbXeP1vdrxVhngbbR8gOlDLZiGExC5EIkjsQiSCxC5EIkjsQiSCxC5EIkjsQiRCZ312AxqkxO76Hl6+t/8SSTuM+KJwnrK4eAOvosPaSc++jfu9x0d5+u2pZ26gcc/wuWcq4fc+8jJPE6318fP96jHudY9dM0/jlxbD9z8McQsfhUW+XQvzPE119bpwGe3KcOTehQXuo1eH+bEaS4HNz4XffOz+gUYuvL+NDNWVXYhEkNiFSASJXYhEkNiFSASJXYhEkNiFSASJXYhE6HjLZkYu4i9mKiQHeD9vm1w8M03j1eHraHzu5rCv+t538LL5P586ROOszS4A9E/y3TR8NrxdVq7lfm+s7TGMx+dWw+WaAaBWDa8/1qo6H2mjXR/g26X0GjHyI9u8OhRp2VyOHKvVSIluks/O8vAB7rO31bJZCPH7gcQuRCJI7EIkgsQuRCJI7EIkgsQuRCJI7EIkQufrxpM2u/UiNz8z6+Fa3LV+btp6pBZ3PZLX3TcTjsV89NVV3r63eIl74aUL3OvOr4bjtf6Ijx6jHGtNzGFrj7XotkhL5qiXXQ/HPR/JN19sve47AFR28VbZ2YXwe6+WIjogvRfYBo9e2c3soJn92MyeN7PnzOwTzedHzewxM3ul+ZtX/BdCdJWt/BtfA/Apd78FwDsBfMzMbgHwaQCPu/sxAI83/xZC9ChRsbv7lLs/3Xy8BOAFAAcA3AXg4ebLHgZw905NUgjRPm/oCzozOwLg7QB+DmDM3aeaoYsAxgJjTpjZhJlN1NZX2piqEKIdtix2MxsE8C0An3T3xc0xd3cEvhpw95PuPu7u47k+XtRRCLFzbEnsZpbHhtC/5u7fbj49bWb7m/H9AMj31UKIbhO13szMADwI4AV3//ym0CMA7gPwQPP3d6NrM6BO7Ja+KzylsVEMTzeWcmhLqzRe+iW3Shq5oWBskfXJBXDNyBKNH33fORr/2ak30XhmpByM1Rf4+8oMcotp9zCv95zP8VLV9Xr4epItc2utVuKHZy7SNrl8TdiOjaXP1voipabnwtsc4BYzANT2hFODmZUKAOUhco0mh+JWfPZ3AfgQgGfN7FTzuc9gQ+TfNLMPAzgH4J4tLEsI0SWiYnf3nyB8vnjv9k5HCLFT6HZZIRJBYhciESR2IRJBYhciESR2IRKhp1Jcq0M87bD/fNivru7lKaxrt+znyz7D2yoX58O+6PJUuC0xABy+ZY7G1+t8Nxx+00UarzfC5+zqCD+fDxe4X3z28iiNH9k7S+PlauuHWCzluTDPPX4MhtfdyPHtsj7K5x3z6T0TSd8l6bkeuQRHqnsH0ZVdiESQ2IVIBIldiESQ2IVIBIldiESQ2IVIBIldiETorM8eyWfPcOsS5THiZ0da8Bau8Lzs8mHuJzPfdOQZfn/AyjGeU14o8jc+u8LvIajWwusfGeR5/HPrvOVyg+SjA8DLr/L7F4pT4dbHpUVegyDmVce8cpDFx46HSIkC1Pr5Po/VV8gtrgdjjQORXtYtoiu7EIkgsQuRCBK7EIkgsQuRCBK7EIkgsQuRCBK7EInQWZ+9TbKkTnhtKOznAkB1F/cuc6u8fvrKtWGvfGiS51Vf+f4BGj93POy5AuB9jwH0lSrB2OUFnmtfmeXbxQb4PQD5WX4I9ZPWIdX+SL76At+uHvHZ80vhfVov8Xsfipe5D79ymG/Xwhzfp/Wh8HbPRTz66kBrbbR1ZRciESR2IRJBYhciESR2IRJBYhciESR2IRJBYhciEbbSn/0ggK8CGMOG43vS3b9oZvcD+AiAS82XfsbdH40uj3jGjchsPEt82QY3oxsFfl7zNe75Zqvh5fdd4p5qaZDnow//it8jsHCU+6qNXNizzUZO5wPc0kVxjq+7b45v9yypj16Y5x5+dj3Sf320SOPFufD9B+VR7rP3VbnHH+stH4P1nrdIXYdMpFx+iK3cVFMD8Cl3f9rMhgA8ZWaPNWNfcPd/bG3VQohOspX+7FMAppqPl8zsBQD8ljAhRM/xhj6zm9kRAG8H8PPmUx83s2fM7CEzGwmMOWFmE2Y2UVtfaWuyQojW2bLYzWwQwLcAfNLdFwF8CcCNAI5j48r/uauNc/eT7j7u7uO5vtI2TFkI0QpbEruZ5bEh9K+5+7cBwN2n3b3u7g0AXwZw685NUwjRLlGxm5kBeBDAC+7++U3Pby4r+gEAp7d/ekKI7WIr38a/C8CHADxrZqeaz30GwL1mdhwbdtxZAB+NLcgzQJ26Jdz+Ku8J2yVre7hFNDjJU1jX9kdSPYlFtXyIW2seyUisRGzBHM+2pC1+s+vcIqpF0kxj5b2rpYhlOR9ef3mEH37mPJ6p8Pe2dCi8TzM1PnZ9Hy+xXRmOWLnZyDFBymQ3SLl1IF7mOsRWvo3/Ca6uwqinLoToHXQHnRCJILELkQgSuxCJILELkQgSuxCJILELkQgdLyXdIGmq3s+9z7VMayV0AWDxCE8jzYSzIaNE7GDaOngr5FYj6ZQsHGtlvcSXzTx8IJ6WvDYSXgC7d2FbYBnRuciGuWqmx/8Ru/+gXuAbpkEO5dh2YfuEefC6sguRCBK7EIkgsQuRCBK7EIkgsQuRCBK7EIkgsQuRCObeXkncN7Qys0sAzm16ai+Ayx2bwBujV+fWq/MCNLdW2c65HXb3a64W6KjYf2flZhPuPt61CRB6dW69Oi9Ac2uVTs1N/8YLkQgSuxCJ0G2xn+zy+hm9OrdenRegubVKR+bW1c/sQojO0e0ruxCiQ0jsQiRCV8RuZreb2UtmdsbMPt2NOYQws7Nm9qyZnTKziS7P5SEzmzGz05ueGzWzx8zslebvSOZ1R+d2v5lNNrfdKTO7s0tzO2hmPzaz583sOTP7RPP5rm47Mq+ObLeOf2Y3syyAlwG8D8B5AE8CuNfdn+/oRAKY2VkA4+7e9RswzOzdAJYBfNXd/6D53D8AmHX3B5onyhF3/7semdv9AJa73ca72a1o/+Y24wDuBvBX6OK2I/O6Bx3Ybt24st8K4Iy7/8LdKwC+AeCuLsyj53H3JwDMvu7puwA83Hz8MDYOlo4TmFtP4O5T7v508/ESgF+3Ge/qtiPz6gjdEPsBAK9t+vs8eqvfuwP4kZk9ZWYnuj2ZqzDm7lPNxxcBjHVzMlch2sa7k7yuzXjPbLtW2p+3i76g+11uc/c/AnAHgI81/13tSXzjM1gveadbauPdKa7SZvw3dHPbtdr+vF26IfZJAAc3/X1987mewN0nm79nAHwHvdeKevrXHXSbv2e6PJ/f0EttvK/WZhw9sO262f68G2J/EsAxMztqZgUAHwTwSBfm8TuYWan5xQnMrATg/ei9VtSPALiv+fg+AN/t4lx+i15p4x1qM44ub7uutz93947/ALgTG9/Ivwrg77sxh8C8bgDwP82f57o9NwBfx8a/dVVsfLfxYQB7ADwO4BUA/wlgtIfm9i8AngXwDDaEtb9Lc7sNG/+iPwPgVPPnzm5vOzKvjmw33S4rRCLoCzohEkFiFyIRJHYhEkFiFyIRJHYhEkFiFyIRJHYhEuF/AXt7d96rcycPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.squeeze(x_adversarial[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6uaLXa-goe2o",
        "outputId": "b8fa5b91-2dec-41a7-8c81-aaa7547ba493"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "# for i in range(10):\n",
        "#   plt.imshow(np.squeeze(x_adversarial[i]))\n",
        "#   plt.show()\n",
        "#   print(y_train[i])"
      ],
      "metadata": {
        "id": "8C5mNp328y8q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_adversarial, y_train)\n",
        ").batch(100)"
      ],
      "metadata": {
        "id": "Cjf3frQs4Io4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(dataset, batch_size = 100):\n",
        "  batch_size = 100\n",
        "  loss_sum = 0.0\n",
        "  for (images, labels) in adversarial_ds:\n",
        "    predictions = model(images, training = True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "    loss_sum_batch = loss * batch_size\n",
        "    loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "  average_loss = tf.divide(loss_sum, 1000)\n",
        "  return average_loss"
      ],
      "metadata": {
        "id": "ozxGyYUn3KGZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q_McCc8IOldM"
      },
      "outputs": [],
      "source": [
        "# x_adversarial_list = []\n",
        "# eps1 = 1\n",
        "# eta1 = 0.1\n",
        "# for i, (images, labels) in enumerate(train_ds):\n",
        "#   for (image, label) in zip(images, labels):\n",
        "#     image = tf.Variable([image])\n",
        "\n",
        "#     initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     image_dashed = tf.add(image, initial_noise)\n",
        "\n",
        "#     # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "#     # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "#     # image_dashed_list = []\n",
        "#     # for image_0 in image:\n",
        "#     #   for image_h in image_0:\n",
        "#     #     for image_v in image_h:\n",
        "#     #       for image_pixel in image_v:\n",
        "#     #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "#     # image_dashed_list.append(image_pixel_dashed)\n",
        "#     # # image_dashed = np.array(image_dashed_list)\n",
        "#     # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "#     # print(image_dashed.numpy())\n",
        "\n",
        "#     for j in range(5):\n",
        "#       with tf.GradientTape() as tape:\n",
        "#         tape.watch(image_dashed)\n",
        "#         prediction = model(image_dashed, training = True)\n",
        "#         loss = loss_object(label, prediction)\n",
        "#       gradients = tape.gradient(loss, image_dashed)\n",
        "#       image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "#       difference = tf.subtract(image_med, image)\n",
        "#       if tf.norm(difference) <= eps1:\n",
        "#         image_dashed = image_med \n",
        "#       else:\n",
        "#         image_dashed = difference\n",
        "#         image_dashed = tf.multiply(image_dashed, eps1)\n",
        "#         image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "#         image_dashed = tf.add(image_dashed, image)\n",
        "#     x_adversarial_list.append(image_dashed[0])\n",
        "# x_adversarial = tf.convert_to_tensor(x_adversarial_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxll_dsBOldN"
      },
      "source": [
        "Step3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 100\n",
        "# loss_sum = 0.0\n",
        "# for (images, labels) in adversarial_ds:\n",
        "#   predictions = model(images, training = True)\n",
        "#   loss = loss_object(labels, predictions)\n",
        "#   loss_sum_batch = loss * batch_size\n",
        "#   loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "# average_loss = tf.divide(loss_sum, 1000)"
      ],
      "metadata": {
        "id": "rD2V2J5I5E1E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_loss(dataset, batch_size = 100, additive_noise = v_array):\n",
        "#   # batch_size = 100\n",
        "#   loss_sum = 0.0\n",
        "#   for (images, labels) in dataset:\n",
        "#     predictions = model(images, training = True)\n",
        "#     loss = loss_object(labels, predictions)\n",
        "#     loss_sum_batch = loss * batch_size\n",
        "#     loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "#   average_loss = tf.divide(loss_sum, 1000)\n",
        "#   return average_loss"
      ],
      "metadata": {
        "id": "H1C7Lp-g3JzR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZ9Ze5LOldN"
      },
      "source": [
        "Step4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# o0 = ordinary_weights[0].flatten()\n",
        "# o1 = ordinary_weights[1].flatten()\n",
        "# o2 = ordinary_weights[2].flatten()\n",
        "# o3 = ordinary_weights[3].flatten()\n",
        "# o4 = ordinary_weights[4].flatten()\n",
        "# o5 = ordinary_weights[5].flatten()\n",
        "\n",
        "# ordinary_flatten_weights = [o0, o1, o2, o3, o4, o5]\n",
        "\n",
        "# w_med_list = []\n",
        "# for w_layer in ordinary_flatten_weights:\n",
        "#   w_med = tf.square(w_layer)\n",
        "#   w_med = tf.add_n(w_med)\n",
        "#   w_med_list.append(w_med)\n",
        "# w_fro = tf.add_n(w_med_list)\n",
        "# w_fro = tf.sqrt(w_fro)"
      ],
      "metadata": {
        "id": "yeew8RqfP59o"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# w_fro = 0.0\n",
        "# for w in ordinary_weights:\n",
        "#   w_reshape = tf.reshape(w, [-1])\n",
        "#   w_med = tf.square(w_reshape)\n",
        "#   w_med = tf.add_n(w_med)\n",
        "#   w_fro = tf.add(w_fro, w_med)\n",
        "# w_fro = tf.sqrt(w_fro)"
      ],
      "metadata": {
        "id": "Di60HjVBEPN0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from numpy import linalg as LA"
      ],
      "metadata": {
        "id": "KckrXgZWSwGR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_flat = np.ndarray([])\n",
        "for w in ordinary_weights:\n",
        "  w_reshape = tf.reshape(w, [-1])\n",
        "  print(w_reshape.shape)\n",
        "  w_flat = np.hstack([w_flat, w_reshape])\n",
        "w_fro = np.linalg.norm(w_flat)\n",
        "print(w_fro)\n",
        "  # w_fro = tf.add(w_fro, np.linalg.norm(w_reshape, ord=2))\n",
        "# w_fro = tf.sqrt(w_fro)"
      ],
      "metadata": {
        "id": "BD3YeKDISlsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc0530c-85bd-4389-f20e-ac3a36cdd5db"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288,)\n",
            "(32,)\n",
            "(2768896,)\n",
            "(128,)\n",
            "(1280,)\n",
            "(10,)\n",
            "16.91876054870113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.rcsetup import validate_axisbelow\n",
        "eps2 = 1\n",
        "eta2 = 0.1\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "v_updated = v_array\n",
        "# vの初期値を，step2で固定したvに設定する．\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  # 重みをw + (現在の)vに設定する　　ここから\n",
        "  current_weights = []\n",
        "  for layer_weights, v in zip(ordinary_weights, v_updated):\n",
        "    current_layer_weight = tf.add(layer_weights, v)\n",
        "    current_weights.append(current_layer_weight)\n",
        "  model.set_weights(current_weights)\n",
        "  # 重みをw + (現在の)vに設定する　　ここまで\n",
        "\n",
        "  # gradientの計算　　ここから\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = calculate_loss(adversarial_ds)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  # gradientの計算　　ここまで\n",
        "\n",
        "  # gradientのノルムの計算　　ここから\n",
        "  gradients_flat = np.ndarray([])\n",
        "  for g in gradients:\n",
        "    g_reshape = tf.reshape(g, [-1])\n",
        "    gradients_flat = np.hstack([gradients_flat, g_reshape])\n",
        "  gradients_norm = np.linalg.norm(gradients_flat)\n",
        "  # gradientのノルムの計算　　ここまで\n",
        "\n",
        "  # 勾配降下の実行　　ここから\n",
        "  v_difference = []\n",
        "  for g, v, w in zip(gradients, v_updated, ordinary_weights):\n",
        "    g = tf.divide(g, gradients_norm)\n",
        "    g = tf.multiply(g, w_fro)\n",
        "    g = tf.multiply(eta2, g)\n",
        "    v_med = tf.add(v, g)\n",
        "  # 勾配降下の実行　　ここまで\n",
        "\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここから\n",
        "    v_difference.append(tf.subtract(v_med, w))\n",
        "  v_difference_flat = np.ndarray([])\n",
        "  for v_flat in v_difference:\n",
        "    v_flat_reshape = tf.reshape(v_flat, [-1])\n",
        "    # print(g_reshape.shape)\n",
        "    v_difference_flat = np.hstack([v_difference_flat, v_flat_reshape])\n",
        "  v_difference_norm = np.linalg.norm(v_difference_flat)\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここまで\n",
        "\n",
        "  # 射影の実行　　ここから\n",
        "  if v_difference_norm <= eps2:\n",
        "    v_hat = v_med \n",
        "  else:\n",
        "    v_hat = v_difference\n",
        "    for v_hat_med, w in zip(v_hat, ordinary_weights):\n",
        "      v_hat_med = tf.multiply(v_hat_med, eps2)\n",
        "      v_hat_med = tf.divide(v_hat_med, v_difference_norm)\n",
        "      v_hat_med = tf.add(w, v_hat_med)\n",
        "  v_updated = v_hat\n",
        "  # 射影の実行　　ここまで\n",
        "\n",
        "  # for (images, labels) in adversarial_ds:\n",
        "  #   for (image, label) in zip(images, labels):\n",
        "  #     with tf.GradientTape() as tape:\n",
        "  #       prediction = model(image, training = False)\n",
        "  #       loss = loss_object(label, prediction)"
      ],
      "metadata": {
        "id": "dhQbeCasjVRp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LJ08Zz7eOldN"
      },
      "outputs": [],
      "source": [
        "# additive_weights = v_array\n",
        "\n",
        "# for (images, labels) in adversarial_ds:\n",
        "#   for (image, label) in zip(images, labels):\n",
        "#     with tf.GradientTape() as tape:\n",
        "#       prediction = model(image, training = False)\n",
        "#       loss = loss_object(label, prediction)\n",
        "\n",
        "# for j in range(5):\n",
        "#   # norm = tf.linalg.norm(gradients)\n",
        "#   # print(len(gradients))\n",
        "#   # gradients_withrate = []\n",
        "#   for v, gradient in zip(v_array, gradients_forallweights):\n",
        "#     norm = tf.linalg.norm(gradient)\n",
        "#     # normalized_gradient = tf.divide(gradient, norm + 1e-12)\n",
        "#     # gradient_withrate = tf.multiply(normalized_gradient, w_fro)\n",
        "#     # gradient_withrate = tf.multiply(eta2, gradient_withrate)\n",
        "#     v_med = tf.add(v, gradient)\n",
        "#     x = v_med - v\n",
        "#     if tf.norm(x) <= eps2:\n",
        "#       v_hat = v_med \n",
        "#     else:\n",
        "#       v_hat = x\n",
        "#       v_hat = tf.multiply(v_hat, eps2)\n",
        "#       v_hat = tf.divide(v_hat, tf.norm(x))\n",
        "#       v_hat = tf.add(v, v_hat)\n",
        "#     new_v.append(v_hat)\n",
        "  \n",
        "# print(new_v)\n",
        "\n",
        "# for i, (images, labels) in enumerate(adversarial_ds):\n",
        "#   loss_sum = 0.0\n",
        "#   gradients_forallweights = np.zeros(6)\n",
        "#   for (image, label) in zip(images, labels):\n",
        "#     image = tf.Variable([image])\n",
        "#     print(f'i={i}')\n",
        "#     with tf.GradientTape() as tape:\n",
        "#       # tape.watch(model.trainable_variables)\n",
        "#       # loss = calculate_loss(adversarial_ds)\n",
        "#       # batch_size = 100\n",
        "#       prediction = model(image, training = False)\n",
        "#       loss = loss_object(label, prediction)\n",
        "#     image_gradients = tape.gradient(loss, model.trainable_variables)\n",
        "#     image_gradients = np.array(image_gradients)\n",
        "#     gradients_forallweights = image_gradients + gradients_forallweights\n",
        "  \n",
        "#   # print(gradients_forallweights)\n",
        "  \n",
        "#   norm = tf.constant(0.0)\n",
        "#   for layer in gradients_forallweights:\n",
        "#     layer_flat = tf.reshape(layer, [-1])\n",
        "#     norm = tf.add(norm, tf.linalg.norm(layer_flat))\n",
        "  \n",
        "#   # print(norm)\n",
        "\n",
        "#   # gradients_forallweights = tf.convert_to_tensor(gradients_forallweights)\n",
        "#   # norm = tf.linalg.norm(gradients_forallweights)\n",
        "#   # normalized_gradients = \n",
        "#   # print(gradients_forallweights)\n",
        "#   for gradients_layer in gradients_forallweights:\n",
        "#     gradients_layer = gradients_layer / (norm + 1e-12)\n",
        "#     # print(gradients_layer)\n",
        "#     gradients_layer = tf.multiply(gradients_layer, w_fro)\n",
        "#     gradients_layer = tf.multiply(eta2, gradients_layer)\n",
        "#   # print(gradients_forallweights)\n",
        "\n",
        "# for j in range(5):\n",
        "#   # norm = tf.linalg.norm(gradients)\n",
        "#   # print(len(gradients))\n",
        "#   # gradients_withrate = []\n",
        "#   new_v = []\n",
        "#   for v, gradient in zip(v_array, gradients_forallweights):\n",
        "#     norm = tf.linalg.norm(gradient)\n",
        "#     # normalized_gradient = tf.divide(gradient, norm + 1e-12)\n",
        "#     # gradient_withrate = tf.multiply(normalized_gradient, w_fro)\n",
        "#     # gradient_withrate = tf.multiply(eta2, gradient_withrate)\n",
        "#     v_med = tf.add(v, gradient)\n",
        "#     x = v_med - v\n",
        "#     if tf.norm(x) <= eps2:\n",
        "#       v_hat = v_med \n",
        "#     else:\n",
        "#       v_hat = x\n",
        "#       v_hat = tf.multiply(v_hat, eps2)\n",
        "#       v_hat = tf.divide(v_hat, tf.norm(x))\n",
        "#       v_hat = tf.add(v, v_hat)\n",
        "#     new_v.append(v_hat)\n",
        "  \n",
        "# print(new_v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZjbQBHOldN"
      },
      "source": [
        "Step5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta3 = 1\n",
        "weights = model.get_weights()\n",
        "new_weights = []\n",
        "for weight, v in zip(ordinary_weights, new_v):\n",
        "  new_weight = tf.add(weight, v)\n",
        "  new_weights.append(new_weight)\n",
        "model.set_weights(new_weights)\n",
        "\n",
        "for i, (images, labels) in enumerate(adversarial_ds):\n",
        "  loss_sum = 0.0\n",
        "  gradients_forallweights = np.zeros(6)\n",
        "  for (image, label) in zip(images, labels):\n",
        "    image = tf.Variable([image])\n",
        "    print(f'i={i}')\n",
        "    with tf.GradientTape() as tape:\n",
        "      # tape.watch(model.trainable_variables)\n",
        "      # loss = calculate_loss(adversarial_ds)\n",
        "      # batch_size = 100\n",
        "      prediction = model(image, training = False)\n",
        "      loss = loss_object(label, prediction)\n",
        "      print(loss)\n",
        "    image_gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    # print(image_gradients)\n",
        "    image_gradients = np.array(image_gradients)\n",
        "    gradients_forallweights = image_gradients + gradients_forallweights\n",
        "  \n",
        "  # print(gradients_forallweights)\n",
        "  \n",
        "  norm = tf.constant(0.0)\n",
        "  for layer in gradients_forallweights:\n",
        "    layer_flat = tf.reshape(layer, [-1])\n",
        "    norm = tf.add(norm, tf.linalg.norm(layer_flat))\n",
        "  \n",
        "  # print(norm)\n",
        "\n",
        "  # gradients_forallweights = tf.convert_to_tensor(gradients_forallweights)\n",
        "  # norm = tf.linalg.norm(gradients_forallweights)\n",
        "  # normalized_gradients = \n",
        "  # print(gradients_forallweights)\n",
        "  for gradients_layer in gradients_forallweights:\n",
        "    # gradients_layer = gradients_layer / (norm + 1e-12)\n",
        "    # # print(gradients_layer)\n",
        "    # gradients_layer = tf.multiply(gradients_layer, w_fro)\n",
        "    gradients_layer = tf.multiply(eta3, gradients_layer)\n",
        "  # print(gradients_forallweights)\n",
        "\n",
        "weights_updated = []\n",
        "for weight, gradient in zip(ordinary_weights, gradients_forallweights):\n",
        "  gradient_med = tf.multiply(eta3, gradient)\n",
        "  weight_updated = tf.subtract(weight, gradient_med)\n",
        "  weights_updated.append(weight_updated)\n",
        "model.set_weights(weights_updated)"
      ],
      "metadata": {
        "id": "nqve4Wgycwfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "052abdb6-c75f-48f2-8f4b-1f2c1518fda3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-bab2de399952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnew_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordinary_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mnew_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mnew_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'new_v' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDaTfdWqOldN"
      },
      "outputs": [],
      "source": [
        "# eta3 = 0.1\n",
        "# weights = model.get_weights()\n",
        "# new_weights = []\n",
        "# for weight, v in zip(ordinary_weights, new_v):\n",
        "#   new_weight = tf.add(weight, v)\n",
        "#   new_weights.append(new_weight)\n",
        "# model.set_weights(new_weights)\n",
        "\n",
        "# # adversarial_ds = tf.data.Dataset.from_tensor_slices(\n",
        "# #   (x_adversarial, y_train)\n",
        "# # ).batch(100)\n",
        "\n",
        "# average_gradients = 0.0\n",
        "# for i, (adversarial_images, labels) in enumerate(adversarial_ds):\n",
        "#   for (adversarial_image, label) in zip(images, labels):\n",
        "#     adversarial_image = tf.Variable([adversarial_image])\n",
        "#     print(f'i={i}')\n",
        "#     # print(image.shape, label)\n",
        "#     for j in range(1):\n",
        "#       with tf.GradientTape() as tape:\n",
        "#         prediction = model(adversarial_image, training = True)\n",
        "#         loss = loss_object(label, prediction)\n",
        "#       gradients = tape.gradient(loss, model.trainable_variables)\n",
        "#       average_gradients = tf.add(average_gradients, loss)\n",
        "#     average_gradients = tf.divide(average_gradients, 1000)\n",
        "\n",
        "#       # norm = tf.linalg.norm(gradients)\n",
        "#       # print(len(gradients))\n",
        "#       # gradients_withrate = []\n",
        "#       # for (images, labels) in adversarial_ds:\n",
        "#       #   with tf.GradientTape() as tape:\n",
        "#       #     # predictions = model(adversarial_images, training = True)\n",
        "#       #     # loss = loss_object(y_train, predictions)\n",
        "#       #     predictions = model(images, training = True)\n",
        "#       #     loss = loss_object(labels, predictions)\n",
        "#       #     average_loss = tf.add(average_loss, loss)\n",
        "#       #     average_loss = tf.divide(average_loss, 100)\n",
        "\n",
        "\n",
        "# # ordinary_weights = np.ndarray(ordinary_weights)\n",
        "# print(type(ordinary_weights))\n",
        "# print(type(average_gradients))\n",
        "# weights_updated = []\n",
        "# for weight, gradient in zip(ordinary_weights, average_gradients):\n",
        "#   gradient_med = tf.multiply(eta3, gradient)\n",
        "#   weight_updated = tf.subtract(weight, gradient_med)\n",
        "#   weights_updated.append(weight_updated)\n",
        "# model.set_weights(weights_updated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MclZYfOldN"
      },
      "source": [
        "再テストの実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAmhPk_tOldN"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('pythonenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d1685d247089585e01bacc0e11595c4779ea690fa157e920ca16120e3c1da301"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}