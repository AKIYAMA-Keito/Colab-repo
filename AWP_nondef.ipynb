{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKIYAMA-Keito/Colab-repo/blob/main/AWP_nondef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d1Z8uIInOldG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKEv8KiMOldH"
      },
      "source": [
        "Step1 Tensorflowチュートリアル4から引用"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "version2\n"
      ],
      "metadata": {
        "id": "Yk9ofpRIRw2k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVrpxk0rOldI"
      },
      "source": [
        "データセットを読み込んで正規化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QobaZNJyOldJ"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "random_index_train = np.array(range(len(x_train)))\n",
        "np.random.shuffle(random_index_train)\n",
        "x_train = x_train[random_index_train][:1000]\n",
        "y_train = y_train[random_index_train][:1000]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test/255.0\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNcHvWE9OldJ"
      },
      "source": [
        "データセットをシャッフルしてバッチ化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wg2lQwV_OldJ"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)\n",
        ").batch(1000)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_test, y_test)\n",
        ").batch(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQHK9sMOldK"
      },
      "source": [
        "CNNモデルを定義しインスタンスを取り出す．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1-UIMbDyOldK"
      },
      "outputs": [],
      "source": [
        "class CNNModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32, 3, activation = \"relu\")\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation = \"relu\")\n",
        "        self.d2 = Dense(10)\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return x\n",
        "\n",
        "model = CNNModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R46fxEjOOldK"
      },
      "source": [
        "損失関数とoptmizerを選択する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9pzC_gytOldL"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph_DSqV9OldL"
      },
      "source": [
        "損失関数とoptimizerの尺度評価のための関数を導入する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MipedjyLOldL"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD6sZQRdOldL"
      },
      "source": [
        "モデルを訓練するための関数train_stepを定義する．\n",
        "予測値と正解ラベルの間の損失関数の勾配を最適化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KCmbB-cnOldL"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training = True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdL3GJY2OldM"
      },
      "source": [
        "モデルをテストするための関数test_stepを定義する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IsRpIQFEOldM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images, training = False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    \n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D-PUsW-OldM"
      },
      "source": [
        "学習を実行してテストし，結果を出力する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJEwX2bUOldM",
        "outputId": "b7f83c40-c8ea-4058-c137-40eef5493e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.3132567405700684, Accuracy: 10.0, Test Loss: 1.9391796588897705, Test Accuracy: 32.849998474121094\n",
            "Epoch 2, Loss: 1.9042017459869385, Accuracy: 37.70000076293945, Test Loss: 1.4725091457366943, Test Accuracy: 67.00999450683594\n",
            "Epoch 3, Loss: 1.4265064001083374, Accuracy: 70.70000457763672, Test Loss: 1.11604905128479, Test Accuracy: 74.12999725341797\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "    \n",
        "    for train_images, train_labels in train_ds:\n",
        "        train_step(train_images, train_labels)\n",
        "    \n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Loss: {train_loss.result()}, '\n",
        "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTaFZYwFOldM"
      },
      "source": [
        "AWPのアルゴリズムを記述する．\n",
        "まず，学習済みのmodelから重みを取り出してvを加えて再設定する．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()\n",
        "ordinary_weights = weights\n",
        "v_array = []\n",
        "for w in weights:\n",
        "  v = 0.00002 * np.random.rand() - 0.00001\n",
        "  v_array.append(tf.fill(w.shape, v))"
      ],
      "metadata": {
        "id": "XRSISCKw7GT9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKvxUYsOldM"
      },
      "source": [
        "Step2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "    weights = model.get_weights()\n",
        "    new_weights = []\n",
        "    for w, v in zip(weights, additive_weights):\n",
        "      new_weights.append(w + v)\n",
        "    model.set_weights(new_weights)\n",
        "\n",
        "    adversarial_image_list = []\n",
        "    # eps1 = 1\n",
        "    # eta1 = 0.1\n",
        "    for (images, labels) in dataset:\n",
        "      for (image, label) in zip(images, labels):\n",
        "        image = tf.Variable([image])\n",
        "\n",
        "        initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        image_dashed = tf.add(image, initial_noise)\n",
        "\n",
        "        # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "        # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "        # image_dashed_list = []\n",
        "        # for image_0 in image:\n",
        "        #   for image_h in image_0:\n",
        "        #     for image_v in image_h:\n",
        "        #       for image_pixel in image_v:\n",
        "        #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "        # image_dashed_list.append(image_pixel_dashed)\n",
        "        # # image_dashed = np.array(image_dashed_list)\n",
        "        # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "        # print(image_dashed.numpy())\n",
        "\n",
        "        for j in range(5):\n",
        "          with tf.GradientTape() as tape:\n",
        "            tape.watch(image_dashed)\n",
        "            prediction = model(image_dashed, training = True)\n",
        "            loss = loss_object(label, prediction)\n",
        "          gradients = tape.gradient(loss, image_dashed)\n",
        "          image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "          difference = tf.subtract(image_med, image)\n",
        "          if tf.norm(difference) <= eps1:\n",
        "            image_dashed = image_med \n",
        "          else:\n",
        "            image_dashed = difference\n",
        "            image_dashed = tf.multiply(image_dashed, eps1)\n",
        "            image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "            image_dashed = tf.add(image_dashed, image)\n",
        "        adversarial_image_list.append(image_dashed[0])\n",
        "        adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "    return adversarial_image"
      ],
      "metadata": {
        "id": "V3j-1XQM1lMS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "# weights = model.get_weights()\n",
        "# new_weights = []\n",
        "# for w, v in zip(weights, v_array):\n",
        "#   new_weights.append(w + v)\n",
        "# model.set_weights(new_weights)\n",
        "\n",
        "# adversarial_image_list = []\n",
        "# eps1 = 1\n",
        "# eta1 = 0.1\n",
        "# for (images, labels) in train_ds:\n",
        "#   for (image, label) in zip(images, labels):\n",
        "#     image = tf.Variable([image])\n",
        "\n",
        "#     initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     image_dashed = tf.add(image, initial_noise)\n",
        "#     # print(image)\n",
        "#     # print(image_dashed)\n",
        "\n",
        "#     # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "#     # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "#     # image_dashed_list = []\n",
        "#     # for image_0 in image:\n",
        "#     #   for image_h in image_0:\n",
        "#     #     for image_v in image_h:\n",
        "#     #       for image_pixel in image_v:\n",
        "#     #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "#     # image_dashed_list.append(image_pixel_dashed)\n",
        "#     # # image_dashed = np.array(image_dashed_list)\n",
        "#     # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "#     # print(image_dashed.numpy())\n",
        "\n",
        "#     for j in range(1):\n",
        "#       with tf.GradientTape() as tape:\n",
        "#         tape.watch(image_dashed)\n",
        "#         prediction = model(image_dashed, training = False)\n",
        "#         # print(prediction)\n",
        "#         loss = loss_object(label, prediction)\n",
        "#       gradients = tape.gradient(loss, image_dashed)\n",
        "#       image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "#       difference = tf.subtract(image_med, image)\n",
        "#       if tf.norm(difference) <= eps1:\n",
        "#         image_dashed = image_med \n",
        "#       else:\n",
        "#         image_dashed = difference\n",
        "#         image_dashed = tf.multiply(image_dashed, eps1)\n",
        "#         image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "#         image_dashed = tf.add(image_dashed, image)\n",
        "#     adversarial_image_list.append(image_dashed[0])\n",
        "#     adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "# print(adversarial_image[0] - x_train[0])\n",
        "\n",
        "# # print(adversarial_image)"
      ],
      "metadata": {
        "id": "2HGcWwIkljvE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adversarial = adversary(train_ds, v_array)"
      ],
      "metadata": {
        "id": "LzKpbHhf5dup"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Mpzb3j_c8kKF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(10):\n",
        "plt.imshow(np.squeeze(x_adversarial[0] - x_train[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "aMZJZZYgA04d",
        "outputId": "357a8d12-f65e-46c9-a5e9-ffec4c2358de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.squeeze(x_adversarial[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6uaLXa-goe2o",
        "outputId": "a7e08ed3-d307-4463-dd31-0cb5312b0f6e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARbUlEQVR4nO3db4xcV3kG8OfZ9Xrd2AnYBFw3OCSYKKrVgoGtlSghBNFAEiE5/kDAbZEruSytYhEoVFjpB9wPVBEliYLapl2IhYMgIYik8YeojrEQAaGEbFzXf2LAaeoothw7rtvGobG9f95+2Otocfa+ZzxnztzZvM9PsnZ3zty5x3fm2Ts77z3n0MwgIm98fU13QES6Q2EXCUJhFwlCYRcJQmEXCWJON3c2l4M2j/Pr75AqDNBpK11U8PZddmPk/edy911SzhPeicd/4zlpv8ZpOzXjgcsKO8nrAdwNoB/AN83sdu/+8zgfV8z5aG27TfpPDvvqn/zUtrm8fbewcd7ObbK5fZeU+n81edxmqSfGt9a2tX00SfYD+AcANwBYDmANyeXtPp6IlJXzq3MlgGfN7DkzOw3gAQCrOtMtEem0nLBfBOCFaT8frG77DSSHSY6SHB2zUxm7E5Ecxf+gM7MRMxsys6EBDpbenYjUyAn7IQBLp/389uo2EelBOWF/CsBlJC8lORfAJwFs6Uy3RKTT2i69mdk4yfUAtmKq9LbJzPbmdCanvJXaNqesV1zJElTq/5UqWWaWr7zjnnzOJibc9qLl0Ddg2S6rzm5mjwJ4tEN9EZGCeviKCxHpJIVdJAiFXSQIhV0kCIVdJAiFXSSIro5nz5VTsy2q6Zqt939vsI6evW2ib+aX4cH+/nPs0fSN857TnONS6rWsM7tIEAq7SBAKu0gQCrtIEAq7SBAKu0gQs6r01mh5zVOwDAMA7EuUxyad39mF+zb5gXe77Rs23Vfb9r65J9xtb9jwl277m777pNvul2rzjkvqtZh8rXqlvUKlWp3ZRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYKYVXX2ksMGs+qqyameE2MxE9J9a78umzoufQucJbYBvPuunW77lYOv1rZNJs419/3tHW77Z7/3Qbe99Mq+efuuf01oiKuIZFHYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgphVdfasWnfJ6ZwTj118HH7BsdG//sDlbvvfvO3v3fZB1r/ExhPXH/zs1Yvd9pxrI3LHq+fPUdD9uRmywk7yAIATmLpCYNzMhjrRKRHpvE6c2T9kZsc68DgiUpD+ZhcJIjfsBuAxkk+THJ7pDiSHSY6SHB2zU5m7E5F25b6Nv9rMDpF8G4BtJH9hZo9Pv4OZjQAYAYAL+hY1NzJBJLisM7uZHaq+HgXwMICVneiUiHRe22EnOZ/k+We+B/ARAHs61TER6ayct/GLATxM8szjfNfM/rUjvapTsJ5csu5Zelx1znj2lIM3j7nt5/XNddsnnOdl6/+9yd32gTXXue3s3++2e6+JrHndAaTmKOjFNQ7aDruZPQfgPR3si4gUpNKbSBAKu0gQCrtIEAq7SBAKu0gQ3R3iaqlldBPlCqeUUnrIYU6/2d/vP/ZEc2Wc43/8B277Y9f8nds+Yee57f1OCevWn/yRu+3le3a57SWPm437JcdUaS53CG0JOrOLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBDGrppJ2a92JWnZqCGzJaYnLL9ncfs325Or/cdsvnvNbbT824A9xvWC3Pzw2pdFrIwoOWy71fOvMLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhJEd+vszKsJu7XuzLHNJccXlx677NVl+5e9w932x++/122fxIDb3ge/Hv37/7S+tu3if3za3TZX1nFPjFdn4rKOnOs6Sr1edGYXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCaKnxrPnjONNjmdP7TtRp/dk10VTc5BnXEPwq43+ssiD9F8CcxJ19FfslNu+dOuJ+sbUmPDUMtypZZUzl/Eu+dg9OW88yU0kj5LcM+22RSS3kdxffV1YtpsikquVt/HfAnD9WbdtALDdzC4DsL36WUR6WDLsZvY4gONn3bwKwObq+80Abupwv0Skw9r9m32xmR2uvn8RwOK6O5IcBjAMAPPgrwsmIuVkfxpvZgag9pMWMxsxsyEzGxrgYO7uRKRN7Yb9CMklAFB9Pdq5LolICe2GfQuAtdX3awE80pnuiEgpyb/ZSd4P4FoAF5I8CODLAG4H8CDJdQCeB3BzS3vLXJ/dr8MnatGJOnwTdc8zkjX+RE2Xc+vndt/1wX92t03V2VOufOLTbvvFO/bVN6bq5E3W0RuUNSe9s2nymTazNTVNH26zOyLSAF0uKxKEwi4ShMIuEoTCLhKEwi4SRE9NJZ0cypkzjLVkmaZwiaj/XZe67c+uq71aGf38sbvtpFerATDyv5e47Zd+3l/yecI5Nieve4+77eSAXw6d86p/XAd++G+1bclSa8Elvqs7OE0ZrxdnU53ZRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYLoqamkc+ro2XXPHIWHWj7/8d9223f8yZ21bX3JJZfzjsv+v1jqto9duKS2bccNd7vbpobfHp887bZ/4otfrG1b8P0n3W2TSzZnDcduYcnnAnRmFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwmiu3X2xFTSOXLr6CXr9MmpohM13ZO/+6rb3uf8zp70BjhXW3tuefMLbvufrf164tG9vqWuAfD7dn6fX6x+yy0HattOP+Rvm3o95L6OvddEqWtCdGYXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCaKn5o3PkVv3zJnnO3s8+6Rfh//Kyn9p+6HnwK8n9ydq/GPm9y31+P5j+8/ZRGIZ7v7EWPwDj7yztu13cMzdttElvAtd85E8s5PcRPIoyT3TbttI8hDJndW/G9vau4h0TStv478F4PoZbr/LzFZU/x7tbLdEpNOSYTezxwEc70JfRKSgnA/o1pPcVb3NX1h3J5LDJEdJjo7ZqYzdiUiOdsN+D4BlAFYAOAzgjro7mtmImQ2Z2dAAB9vcnYjkaivsZnbEzCbMbBLANwCs7Gy3RKTT2go7yenzA68GsKfuviLSG5J1dpL3A7gWwIUkDwL4MoBrSa4AYAAOAPhMS3vLHM+eU/tMzvOdHHNeZhw+ALz051e67R+b/4TbPsD6ceGp9ddT1wik5pVPPr6jn/5jTyTq8L8c889VS372Sm1b7hwDOWscpPZfqsafDLuZrZnh5nsL9EVECtLlsiJBKOwiQSjsIkEo7CJBKOwiQfTUENesslyiFJIqtXCOP62xu33uENdEpSU1pfIpG6ttG3TKcgAwnhhGmjOENVdqGuxfnL7If4Cf761vy1ySufQy3f6unZw4TTqziwShsIsEobCLBKGwiwShsIsEobCLBKGwiwTR3Tp7JrfWnRqCmqyL+vVk//qAzN+Zia6n6s0DrO97attUHT1Vh89x0sbd9uOJayO+/pWb3fY34+fn3KczSk9NnjNEln3Oc+o06cwuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEsSsqrOnxiDnbJsc7+7UTZPTVCdqtgtWv+i2TyQK8X2JKZddLFdHB9K1dM91D/6V277s2/4U266c11IHNDGVtM7sIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkHMqjp7qTnnS0vVTU+O+0/DPPrt3tLGqWWRU1LLJud4/wOfd9uXfckfj55cK6Dg8uCpx87Zd9ZrOWfeeJJLSf6I5DMk95K8tbp9EcltJPdXXxe230MRKa2Vt/HjAL5gZssBXAHgFpLLAWwAsN3MLgOwvfpZRHpUMuxmdtjMdlTfnwCwD8BFAFYB2FzdbTOAm0p1UkTyndPf7CQvAfBeAE8CWGxmh6umFwEsrtlmGMAwAMzDee32U0QytfxpPMkFAH4A4HNm9vL0NjMz1Hw0YGYjZjZkZkMDHMzqrIi0r6WwkxzAVNC/Y2YPVTcfIbmkal8C4GiZLopIJyTfxpMkgHsB7DOzO6c1bQGwFsDt1ddHknuzJksSiamkCw6fTXnrupfd9k9872Nu+/ff9Wht25jlDWFNTUWdWk76D3eurW27/Gv/6W47UWioJ1BuGOlrEq+3nKmkXc5uW/mb/SoAnwKwm+TO6rbbMBXyB0muA/A8AH8SbxFpVDLsZvZTAHW/Bj/c2e6ISCm6XFYkCIVdJAiFXSQIhV0kCIVdJIieGuKarH069ezUVNCpWnjWkEYb8x97zoDbPvFf/+3v+6b5bvtVq9bXth370Cl324euucdtX731s257yvKv1l9rNX70WNZjpxSvpfs7d5tLDr+tozO7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBC0glMFn+2CvkV2xZyP1rY3OfVvjuL13NR4+Zz9p65PSEgdV3fcdmqOgdx9e1OPZ16XkZLzesx5PT0xvhUvTx6f8QF0ZhcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJYlaNZ5+tdfj8mm5ie6c5d1nj9Pzmib45tfTcY55Vy849LpnXVhRbfjxnyWYReWNQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJoZX32pQDuA7AYU1W8ETO7m+RGAJ8G8FJ119vMrH6h8Fak5nb3hkanatkF12cvPTY6p+827s9pn5zfPLF9zjrjjc7rHlArF9WMA/iCme0geT6Ap0luq9ruMrOvleueiHRKK+uzHwZwuPr+BMl9AC4q3TER6axzen9J8hIA7wXwZHXTepK7SG4iubBmm2GSoyRHx8xfikhEymk57CQXAPgBgM+Z2csA7gGwDMAKTJ3575hpOzMbMbMhMxsa4GAHuiwi7Wgp7CQHMBX075jZQwBgZkfMbMLMJgF8A8DKct0UkVzJsJMkgHsB7DOzO6fdvmTa3VYD2NP57olIp7TyafxVAD4FYDfJndVttwFYQ3IFpspxBwB8JvlIlppCt/2phdNlnPZLREBi2GHJ5aCRORwzt+yXu72j5LBiYPaW9rL67USolU/jfwpgpr3n1dRFpKt0BZ1IEAq7SBAKu0gQCrtIEAq7SBAKu0gQ3Z1KmgWn0M2Uqm2WrNlm1+Ez+pZ7zHP6VroOnrMscpPPSSk6s4sEobCLBKGwiwShsIsEobCLBKGwiwShsIsEQbPu1bZJvgTg+Wk3XQjgWNc6cG56tW+92i9AfWtXJ/v2DjN760wNXQ3763ZOjprZUGMdcPRq33q1X4D61q5u9U1v40WCUNhFgmg67CMN79/Tq33r1X4B6lu7utK3Rv9mF5HuafrMLiJdorCLBNFI2EleT/KXJJ8luaGJPtQheYDkbpI7SY423JdNJI+S3DPttkUkt5HcX32dcY29hvq2keSh6tjtJHljQ31bSvJHJJ8huZfkrdXtjR47p19dOW5d/5udZD+AXwG4DsBBAE8BWGNmz3S1IzVIHgAwZGaNX4BB8hoArwC4z8x+r7rtqwCOm9nt1S/KhWb2pR7p20YArzS9jHe1WtGS6cuMA7gJwJ+iwWPn9OtmdOG4NXFmXwngWTN7zsxOA3gAwKoG+tHzzOxxAMfPunkVgM3V95sx9WLpupq+9QQzO2xmO6rvTwA4s8x4o8fO6VdXNBH2iwC8MO3ng+it9d4NwGMknyY53HRnZrDYzA5X378IYHGTnZlBchnvbjprmfGeOXbtLH+eSx/Qvd7VZvY+ADcAuKV6u9qTbOpvsF6qnba0jHe3zLDM+GuaPHbtLn+eq4mwHwKwdNrPb69u6wlmdqj6ehTAw+i9paiPnFlBt/p6tOH+vKaXlvGeaZlx9MCxa3L58ybC/hSAy0heSnIugE8C2NJAP16H5PzqgxOQnA/gI+i9pai3AFhbfb8WwCMN9uU39Moy3nXLjKPhY9f48udm1vV/AG7E1Cfy/wHgr5voQ02/3gng36t/e5vuG4D7MfW2bgxTn22sA/AWANsB7AfwQwCLeqhv3wawG8AuTAVrSUN9uxpTb9F3AdhZ/bux6WPn9Ksrx02Xy4oEoQ/oRIJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYL4f+h166s+qx5FAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "# for i in range(10):\n",
        "#   plt.imshow(np.squeeze(x_adversarial[i]))\n",
        "#   plt.show()\n",
        "#   print(y_train[i])"
      ],
      "metadata": {
        "id": "8C5mNp328y8q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxll_dsBOldN"
      },
      "source": [
        "Step3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_adversarial, y_train)\n",
        ").batch(100)"
      ],
      "metadata": {
        "id": "Cjf3frQs4Io4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(dataset, batch_size = 100):\n",
        "  batch_size = 100\n",
        "  loss_sum = 0.0\n",
        "  for (images, labels) in adversarial_ds:\n",
        "    predictions = model(images, training = True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "    loss_sum_batch = loss * batch_size\n",
        "    loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "  average_loss = tf.divide(loss_sum, 1000)\n",
        "  return average_loss"
      ],
      "metadata": {
        "id": "ozxGyYUn3KGZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 100\n",
        "# loss_sum = 0.0\n",
        "# for (images, labels) in adversarial_ds:\n",
        "#   predictions = model(images, training = True)\n",
        "#   loss = loss_object(labels, predictions)\n",
        "#   loss_sum_batch = loss * batch_size\n",
        "#   loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "# average_loss = tf.divide(loss_sum, 1000)"
      ],
      "metadata": {
        "id": "rD2V2J5I5E1E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_loss(dataset, batch_size = 100, additive_noise = v_array):\n",
        "#   # batch_size = 100\n",
        "#   loss_sum = 0.0\n",
        "#   for (images, labels) in dataset:\n",
        "#     predictions = model(images, training = True)\n",
        "#     loss = loss_object(labels, predictions)\n",
        "#     loss_sum_batch = loss * batch_size\n",
        "#     loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "#   average_loss = tf.divide(loss_sum, 1000)\n",
        "#   return average_loss"
      ],
      "metadata": {
        "id": "H1C7Lp-g3JzR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZ9Ze5LOldN"
      },
      "source": [
        "Step4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_flat = np.ndarray([])\n",
        "for w in ordinary_weights:\n",
        "  w_reshape = tf.reshape(w, [-1])\n",
        "  print(w_reshape.shape)\n",
        "  w_flat = np.hstack([w_flat, w_reshape])\n",
        "w_fro = np.linalg.norm(w_flat)\n",
        "print(w_fro)\n",
        "  # w_fro = tf.add(w_fro, np.linalg.norm(w_reshape, ord=2))\n",
        "# w_fro = tf.sqrt(w_fro)"
      ],
      "metadata": {
        "id": "BD3YeKDISlsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99199c2-0f7b-4014-c685-4618650b100c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288,)\n",
            "(32,)\n",
            "(2768896,)\n",
            "(128,)\n",
            "(1280,)\n",
            "(10,)\n",
            "16.902204696736412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.rcsetup import validate_axisbelow\n",
        "eps2 = 1\n",
        "eta2 = 0.1\n",
        "batch_size = 100\n",
        "\n",
        "v_updated = v_array\n",
        "# vの初期値を，step2で固定したvに設定する．\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  # 重みをw + (現在の)vに設定する　　ここから\n",
        "  current_weights = []\n",
        "  for layer_weights, v in zip(ordinary_weights, v_updated):\n",
        "    current_layer_weight = tf.add(layer_weights, v)\n",
        "    current_weights.append(current_layer_weight)\n",
        "  model.set_weights(current_weights)\n",
        "  # 重みをw + (現在の)vに設定する　　ここまで\n",
        "\n",
        "  # gradientの計算　　ここから\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = calculate_loss(adversarial_ds)\n",
        "    # print(loss)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  print(gradients)\n",
        "  #　計算できているし，悪い値ではない．\n",
        "  # gradientの計算　　ここまで\n",
        "\n",
        "  # gradientのノルムの計算　　ここから\n",
        "  gradients_flat = np.ndarray([])\n",
        "  for g in gradients:\n",
        "    g_reshape = tf.reshape(g, [-1])\n",
        "    gradients_flat = np.hstack([gradients_flat, g_reshape])\n",
        "  gradients_norm = np.linalg.norm(gradients_flat)\n",
        "  print(gradients_flat)\n",
        "  print(gradients_norm)\n",
        "  # ループを経るごとに値が大きくなり過ぎている？\n",
        "  # gradientのノルムの計算　　ここまで\n",
        "\n",
        "  # 勾配降下の実行　　ここから\n",
        "  v_difference = []\n",
        "  for g, v in zip(gradients, v_updated):\n",
        "    g = tf.divide(g, gradients_norm)\n",
        "    g = tf.multiply(g, w_fro)\n",
        "    g = tf.multiply(eta2, g)\n",
        "    v_med = tf.add(v, g)\n",
        "  # 勾配降下の実行　　ここまで\n",
        "\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここから\n",
        "    v_difference.append(v_med)\n",
        "  v_difference_flat = np.ndarray([])\n",
        "  for v_flat in v_difference:\n",
        "    v_flat_reshape = tf.reshape(v_flat, [-1])\n",
        "    # print(g_reshape.shape)\n",
        "    v_difference_flat = np.hstack([v_difference_flat, v_flat_reshape])\n",
        "  v_difference_norm = np.linalg.norm(v_difference_flat)\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここまで\n",
        "\n",
        "  # 射影の実行　　ここから\n",
        "  if v_difference_norm <= eps2:\n",
        "    v_hat = v_med \n",
        "  else:\n",
        "    v_hat = v_difference\n",
        "    for v_hat_med in v_hat:\n",
        "      v_hat_med = tf.multiply(v_hat_med, eps2)\n",
        "      v_hat_med = tf.divide(v_hat_med, v_difference_norm)\n",
        "  v_updated = v_hat\n",
        "  # print(v_updated)　計算できているし，悪い値ではない．\n",
        "  # 射影の実行　　ここまで"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhQbeCasjVRp",
        "outputId": "9e437672-1e1b-4f20-e4b3-1be516ba780f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.05778115, -0.00425924, -0.07217379, -0.11691163,\n",
            "          -0.06435378, -0.10477254, -0.09438086, -0.10039423,\n",
            "          -0.01539455, -0.09525649, -0.00189941, -0.07578845,\n",
            "          -0.13745448, -0.01142495, -0.13231252, -0.08595955,\n",
            "          -0.07669073, -0.11042239, -0.0995923 , -0.09146789,\n",
            "          -0.07345366, -0.11879043, -0.0061478 , -0.04435571,\n",
            "          -0.00059182, -0.12122835, -0.10477501, -0.00235963,\n",
            "          -0.02522342, -0.00583094, -0.02597409, -0.04917938]],\n",
            "\n",
            "        [[-0.0715643 , -0.0154987 , -0.08327979, -0.11879535,\n",
            "          -0.05045263, -0.11490741, -0.11004442, -0.10797343,\n",
            "          -0.00295109, -0.11897422, -0.00098291, -0.09844884,\n",
            "          -0.13679087, -0.02521974, -0.136406  , -0.106466  ,\n",
            "          -0.07800356, -0.11964705, -0.05617159, -0.12104858,\n",
            "          -0.08087014, -0.10659398, -0.00676024, -0.06883649,\n",
            "          -0.00174389, -0.13451016, -0.10391192, -0.0015799 ,\n",
            "          -0.03070595, -0.02170304, -0.01698286, -0.05586744]],\n",
            "\n",
            "        [[-0.10317353, -0.03705917, -0.08159622, -0.09921668,\n",
            "          -0.03908034, -0.10915308, -0.10751362, -0.09481449,\n",
            "          -0.01625875, -0.11918142, -0.0039129 , -0.10407288,\n",
            "          -0.11198346, -0.04249516, -0.1232991 , -0.10812777,\n",
            "          -0.05758757, -0.10687447, -0.01463757, -0.12944497,\n",
            "          -0.07968995, -0.08014534, -0.01961008, -0.07311463,\n",
            "          -0.01503179, -0.12778935, -0.10359669, -0.00303322,\n",
            "          -0.02484112, -0.0513166 , -0.02090291, -0.04686324]]],\n",
            "\n",
            "\n",
            "       [[[-0.0783807 , -0.00330027, -0.09309499, -0.13404545,\n",
            "          -0.06402133, -0.10744367, -0.11461972, -0.12440831,\n",
            "          -0.00421242, -0.12091704, -0.01117167, -0.10205279,\n",
            "          -0.12829961, -0.0034996 , -0.11188331, -0.10690595,\n",
            "          -0.105882  , -0.11891246, -0.10474026, -0.10005519,\n",
            "          -0.10433172, -0.11349574, -0.03328445, -0.06747252,\n",
            "          -0.00251549, -0.13386491, -0.07197896, -0.01529778,\n",
            "          -0.00948392, -0.00182525, -0.00401335, -0.08718541]],\n",
            "\n",
            "        [[-0.08452649, -0.01849793, -0.09240249, -0.13378072,\n",
            "          -0.05357003, -0.11362295, -0.12851205, -0.1306726 ,\n",
            "          -0.01099142, -0.13906921,  0.00050661, -0.12533987,\n",
            "          -0.11642043, -0.01498624, -0.11152532, -0.12533611,\n",
            "          -0.09978421, -0.12051933, -0.05115866, -0.12925884,\n",
            "          -0.10827705, -0.0872881 , -0.04222181, -0.07547194,\n",
            "          -0.00903265, -0.14006078, -0.06782868, -0.01535284,\n",
            "          -0.00541886, -0.00717457, -0.00205459, -0.08991066]],\n",
            "\n",
            "        [[-0.10225676, -0.05753486, -0.07362922, -0.10980435,\n",
            "          -0.0284041 , -0.10375243, -0.11918721, -0.10966793,\n",
            "          -0.04218844, -0.13460806,  0.00055885, -0.12881061,\n",
            "          -0.08827887, -0.04970692, -0.09587358, -0.1181343 ,\n",
            "          -0.07668239, -0.10006098, -0.00967639, -0.13528505,\n",
            "          -0.09841631, -0.05540813, -0.0647947 , -0.0538051 ,\n",
            "          -0.03477457, -0.12341632, -0.07541406, -0.0224599 ,\n",
            "          -0.00274801, -0.02822698, -0.00299094, -0.06827845]]],\n",
            "\n",
            "\n",
            "       [[[-0.06952763, -0.00440673, -0.09510273, -0.12145909,\n",
            "          -0.07517778, -0.09345782, -0.11493317, -0.11860581,\n",
            "          -0.00968208, -0.11769274, -0.0330847 , -0.10777871,\n",
            "          -0.09600087, -0.00263178, -0.07844078, -0.10884431,\n",
            "          -0.12494516, -0.11497755, -0.09934833, -0.08721448,\n",
            "          -0.118743  , -0.09175724, -0.06977738, -0.05280118,\n",
            "          -0.00259648, -0.11981341, -0.03281867, -0.03178349,\n",
            "          -0.00203695, -0.00139837, -0.01374053, -0.11539321]],\n",
            "\n",
            "        [[-0.06213621, -0.03068781, -0.07938537, -0.12008663,\n",
            "          -0.05499298, -0.09595981, -0.12103442, -0.11946796,\n",
            "          -0.03604476, -0.12486554, -0.0107279 , -0.12761635,\n",
            "          -0.08012089, -0.01163944, -0.07253292, -0.11691917,\n",
            "          -0.11323085, -0.10840355, -0.04749735, -0.11177102,\n",
            "          -0.11591208, -0.06326917, -0.0882251 , -0.05700334,\n",
            "          -0.0128863 , -0.11760126, -0.03423867, -0.04776416,\n",
            "          -0.00189127, -0.00187163, -0.00576223, -0.10845777]],\n",
            "\n",
            "        [[-0.06459006, -0.08333023, -0.04868977, -0.09733486,\n",
            "          -0.01743342, -0.0848468 , -0.10816915, -0.09750383,\n",
            "          -0.0586863 , -0.11198557, -0.00205907, -0.12669331,\n",
            "          -0.05517718, -0.05408427, -0.06022467, -0.10676895,\n",
            "          -0.09022689, -0.08485056, -0.0122577 , -0.11233306,\n",
            "          -0.09652869, -0.03250484, -0.11022373, -0.03617771,\n",
            "          -0.04026014, -0.09675429, -0.04583883, -0.06878863,\n",
            "          -0.00154197, -0.01013723, -0.00263599, -0.0772284 ]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.01171392, -0.07634361,  0.0102491 , -0.05974581, -0.0255614 ,\n",
            "       -0.06623822, -0.07860222, -0.05610309, -0.10322501, -0.09432925,\n",
            "       -0.10902055, -0.05249842, -0.08870272, -0.05345637, -0.07910068,\n",
            "       -0.06723312, -0.05066584, -0.08988733, -0.06038686, -0.06708589,\n",
            "       -0.03793267, -0.04916815, -0.10313462,  0.00082443, -0.09055042,\n",
            "       -0.10810508, -0.05772505, -0.09341317, -0.00745312, -0.05087149,\n",
            "       -0.0315248 ,  0.1275924 ], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-4.7457132e-07,  0.0000000e+00, -4.6118348e-06, ...,\n",
            "        -7.7840250e-06,  2.7010340e-06,  7.0905089e-06],\n",
            "       [-4.5386325e-05,  0.0000000e+00, -1.1210085e-05, ...,\n",
            "        -2.8305398e-05, -4.8378606e-05,  3.1400341e-05],\n",
            "       [-3.4194638e-06,  0.0000000e+00, -6.6821203e-06, ...,\n",
            "        -8.9909718e-06, -1.6496519e-06,  1.9930365e-05],\n",
            "       ...,\n",
            "       [-8.5821433e-05,  0.0000000e+00, -2.0573694e-05, ...,\n",
            "        -4.1301842e-05, -7.1721195e-05,  5.5606091e-05],\n",
            "       [-4.1571944e-05,  0.0000000e+00, -1.0647091e-05, ...,\n",
            "        -1.5712332e-05, -3.4110188e-05,  3.1248455e-05],\n",
            "       [-1.0103756e-05,  0.0000000e+00, -2.0399643e-06, ...,\n",
            "        -1.7529392e-06, -1.8800771e-06, -1.2788290e-05]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-1.17853433e-02,  0.00000000e+00, -3.65359988e-03, -4.30874201e-03,\n",
            "       -4.34358604e-03, -1.42434763e-03,  2.74795201e-03,  3.82644869e-03,\n",
            "        4.14253504e-04, -8.01865291e-03, -9.47786868e-03,  0.00000000e+00,\n",
            "        7.95886200e-03, -7.48814736e-03, -1.04589676e-02,  1.90861814e-03,\n",
            "       -1.56707782e-02, -9.15094372e-03, -1.19728763e-02, -2.75913114e-03,\n",
            "       -1.09788533e-02, -1.19322967e-02,  7.89332378e-04,  7.73001811e-04,\n",
            "        0.00000000e+00,  1.49375084e-03, -3.42720887e-04,  0.00000000e+00,\n",
            "        3.46474815e-03, -5.33041195e-04,  0.00000000e+00, -1.34151485e-02,\n",
            "       -9.51673836e-03, -6.16465043e-03, -6.76191645e-03, -7.78586045e-03,\n",
            "       -1.26058320e-02,  7.73314387e-04, -2.44306261e-03, -2.13346239e-02,\n",
            "        1.36401365e-03,  2.60202051e-03, -8.06904864e-03,  4.21088701e-03,\n",
            "        9.08822380e-03, -1.22260593e-04, -3.82330851e-03,  5.47072012e-03,\n",
            "        0.00000000e+00, -1.24934432e-03, -1.30415726e-02,  0.00000000e+00,\n",
            "        1.31059752e-03, -1.69720186e-03,  0.00000000e+00, -1.01492666e-02,\n",
            "       -4.73128865e-03, -8.51537194e-03, -5.52099757e-03, -5.44775417e-03,\n",
            "       -8.69218446e-03, -4.24680719e-03,  0.00000000e+00,  3.13200871e-03,\n",
            "        3.73326242e-03, -9.30905156e-03, -7.88569637e-03, -7.05256243e-04,\n",
            "        1.44919811e-03,  6.99992850e-03,  2.90436135e-03, -6.21486036e-03,\n",
            "       -2.00445801e-02,  2.52680131e-03, -3.92906833e-03, -1.75917591e-03,\n",
            "       -7.45073776e-04, -2.59011309e-03, -9.95336194e-03, -1.02573950e-02,\n",
            "        2.18274328e-03,  4.18769941e-03, -5.62630221e-03, -1.13759786e-02,\n",
            "        6.54934626e-03, -4.96396841e-03, -5.61057124e-03,  0.00000000e+00,\n",
            "       -1.94168405e-03, -1.08834601e-03, -6.77398359e-03,  0.00000000e+00,\n",
            "        1.05263502e-03,  8.09053541e-04, -1.12253269e-02, -1.13887910e-03,\n",
            "       -9.02318023e-03, -5.26215602e-03,  0.00000000e+00,  0.00000000e+00,\n",
            "       -3.73789249e-03, -9.94619841e-05,  7.97283277e-03,  9.25433822e-04,\n",
            "       -1.13502778e-02, -6.01526001e-04, -2.32227538e-02, -8.80307984e-03,\n",
            "       -4.28661145e-03,  3.84755433e-03,  1.03372857e-02,  0.00000000e+00,\n",
            "       -9.38506331e-03, -2.14975700e-03, -8.09048489e-03,  0.00000000e+00,\n",
            "       -9.69206262e-03,  0.00000000e+00,  5.10031939e-04,  5.08713070e-04,\n",
            "        1.40071176e-02,  8.00924143e-04,  0.00000000e+00, -1.15249390e-02,\n",
            "        0.00000000e+00, -3.80908558e-03, -7.40226265e-03,  8.94248113e-03],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-0.01753622, -0.00437738,  0.00403604, ..., -0.01078324,\n",
            "        -0.01015308, -0.00127429],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.00077094,  0.00039976,  0.00014786, ...,  0.00064466,\n",
            "         0.00076004,  0.00056737],\n",
            "       ...,\n",
            "       [-0.0173556 ,  0.00990352,  0.00531445, ...,  0.00099195,\n",
            "        -0.00797811, -0.00711573],\n",
            "       [-0.01384451, -0.00230998, -0.00486143, ...,  0.00516297,\n",
            "        -0.00672484,  0.00455166],\n",
            "       [ 0.0023602 ,  0.00441292, -0.00022038, ..., -0.0115973 ,\n",
            "        -0.00647502, -0.01171875]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.0070506 , -0.03233394,  0.02643183,  0.00902623,  0.01646965,\n",
            "        0.00222718,  0.02202003, -0.02640524,  0.00739411, -0.01777925],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -5.77811487e-02 -4.25923709e-03 ... -2.64052413e-02\n",
            "  7.39410799e-03 -1.77792534e-02]\n",
            "1000.0014232851136\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.05784157, -0.00424288, -0.07245366, -0.11751903,\n",
            "          -0.06458377, -0.10546296, -0.09492934, -0.10092919,\n",
            "          -0.01533942, -0.09582008, -0.00187244, -0.07610425,\n",
            "          -0.1383042 , -0.01144141, -0.13327686, -0.08649486,\n",
            "          -0.07714089, -0.11133667, -0.09995727, -0.09187268,\n",
            "          -0.07388803, -0.11948226, -0.00628479, -0.04399271,\n",
            "          -0.00057731, -0.12200581, -0.10555246, -0.00236406,\n",
            "          -0.02524917, -0.00581551, -0.02603144, -0.05028989]],\n",
            "\n",
            "        [[-0.07166157, -0.01548098, -0.08373974, -0.11942726,\n",
            "          -0.05061779, -0.11564671, -0.11073922, -0.10859907,\n",
            "          -0.00290025, -0.11979998, -0.00104966, -0.09905753,\n",
            "          -0.1376852 , -0.02521021, -0.13740422, -0.10718284,\n",
            "          -0.07844345, -0.1205598 , -0.05629558, -0.1218009 ,\n",
            "          -0.08130742, -0.10705573, -0.00676838, -0.06847075,\n",
            "          -0.00169088, -0.1354504 , -0.10454334, -0.00158763,\n",
            "          -0.03077816, -0.02170915, -0.01696106, -0.05697131]],\n",
            "\n",
            "        [[-0.10346554, -0.03697615, -0.08211553, -0.09978155,\n",
            "          -0.03928083, -0.1098053 , -0.10820407, -0.09537456,\n",
            "          -0.01615553, -0.11988876, -0.00392932, -0.10462249,\n",
            "          -0.11268647, -0.04244268, -0.12407814, -0.10886396,\n",
            "          -0.05779917, -0.10763033, -0.01448386, -0.130366  ,\n",
            "          -0.08017685, -0.08051817, -0.01957254, -0.07282537,\n",
            "          -0.01493272, -0.12869534, -0.10408716, -0.00285668,\n",
            "          -0.02491393, -0.05141794, -0.02087685, -0.04791544]]],\n",
            "\n",
            "\n",
            "       [[[-0.07872929, -0.00331064, -0.09360933, -0.13494329,\n",
            "          -0.06422667, -0.10813086, -0.11534588, -0.12506853,\n",
            "          -0.00417802, -0.12179443, -0.01115378, -0.10257286,\n",
            "          -0.1292146 , -0.00350288, -0.11267224, -0.1076239 ,\n",
            "          -0.10651919, -0.11991434, -0.10497002, -0.10055714,\n",
            "          -0.10496587, -0.11408854, -0.0334363 , -0.06722839,\n",
            "          -0.00247271, -0.13482592, -0.07252192, -0.01535334,\n",
            "          -0.00953284, -0.0018363 , -0.00403885, -0.08847772]],\n",
            "\n",
            "        [[-0.08477521, -0.01847463, -0.09300615, -0.13466078,\n",
            "          -0.05374489, -0.11432566, -0.12932694, -0.1314373 ,\n",
            "          -0.01098198, -0.14015415,  0.00047961, -0.12616765,\n",
            "          -0.11732104, -0.01489976, -0.11226043, -0.12619479,\n",
            "          -0.10032049, -0.12135743, -0.0510553 , -0.13012002,\n",
            "          -0.10891175, -0.08763123, -0.04227473, -0.07510123,\n",
            "          -0.00897647, -0.14102066, -0.06809764, -0.01525082,\n",
            "          -0.00545843, -0.00715794, -0.00206709, -0.0911634 ]],\n",
            "\n",
            "        [[-0.1026082 , -0.05757817, -0.0740352 , -0.11053993,\n",
            "          -0.02856006, -0.10439231, -0.11997702, -0.11029012,\n",
            "          -0.04215316, -0.13553391,  0.00056586, -0.12970324,\n",
            "          -0.08897404, -0.0496492 , -0.09636657, -0.11895429,\n",
            "          -0.07693528, -0.10062923, -0.00951271, -0.1362338 ,\n",
            "          -0.09894314, -0.05556876, -0.06496596, -0.05337141,\n",
            "          -0.03470671, -0.12428735, -0.07568325, -0.02212546,\n",
            "          -0.00275334, -0.02823199, -0.00299757, -0.06944189]]],\n",
            "\n",
            "\n",
            "       [[[-0.06994206, -0.00439053, -0.09567225, -0.1223595 ,\n",
            "          -0.0755652 , -0.09403195, -0.11565138, -0.11935823,\n",
            "          -0.00962953, -0.11868062, -0.03314701, -0.10850274,\n",
            "          -0.09675424, -0.00264393, -0.07895867, -0.10961311,\n",
            "          -0.12590116, -0.11597818, -0.09957189, -0.08775038,\n",
            "          -0.11947508, -0.09237633, -0.0699362 , -0.05257224,\n",
            "          -0.0025529 , -0.12071434, -0.03291437, -0.03170052,\n",
            "          -0.00206117, -0.00140697, -0.01384099, -0.11683663]],\n",
            "\n",
            "        [[-0.06222376, -0.03065223, -0.07980594, -0.12097125,\n",
            "          -0.05529461, -0.09655155, -0.12179039, -0.12022859,\n",
            "          -0.03602593, -0.1258054 , -0.01072386, -0.12844576,\n",
            "          -0.08081148, -0.01154537, -0.07300604, -0.11776306,\n",
            "          -0.11396273, -0.10915047, -0.04747321, -0.11258922,\n",
            "          -0.11664868, -0.06361782, -0.0885367 , -0.05653633,\n",
            "          -0.01284706, -0.11842281, -0.03423677, -0.04754457,\n",
            "          -0.00190007, -0.00185798, -0.0058092 , -0.10982519]],\n",
            "\n",
            "        [[-0.06465378, -0.08348152, -0.04891254, -0.09808169,\n",
            "          -0.01758246, -0.08538726, -0.10885262, -0.09801427,\n",
            "          -0.05859298, -0.1127762 , -0.00203984, -0.12760463,\n",
            "          -0.05572917, -0.05412535, -0.06037575, -0.10752086,\n",
            "          -0.09072872, -0.08532753, -0.01212383, -0.11316739,\n",
            "          -0.09703815, -0.03262239, -0.11064667, -0.03562849,\n",
            "          -0.04022234, -0.09742151, -0.04591244, -0.06855728,\n",
            "          -0.00154583, -0.01008618, -0.00263071, -0.07846095]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.00809619, -0.07530634,  0.01087992, -0.05997929, -0.01866262,\n",
            "       -0.06612162, -0.07834708, -0.05561159, -0.102148  , -0.0931589 ,\n",
            "       -0.10862136, -0.05223096, -0.08824533, -0.052821  , -0.07823609,\n",
            "       -0.06703729, -0.04927857, -0.09006616, -0.06004864, -0.06706492,\n",
            "       -0.03754221, -0.04782145, -0.10222036, -0.00185193, -0.0900861 ,\n",
            "       -0.10823821, -0.05664754, -0.09252673, -0.00714944, -0.05071501,\n",
            "       -0.03079914,  0.12622245], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-2.29304788e-07,  0.00000000e+00, -4.51059532e-06, ...,\n",
            "        -7.75380067e-06,  2.73406249e-06,  6.88930049e-06],\n",
            "       [-4.50522530e-05,  0.00000000e+00, -1.11721065e-05, ...,\n",
            "        -2.81501871e-05, -4.82246396e-05,  3.13159107e-05],\n",
            "       [-3.39283770e-06,  0.00000000e+00, -6.67584936e-06, ...,\n",
            "        -8.98628605e-06, -1.73571084e-06,  1.99530896e-05],\n",
            "       ...,\n",
            "       [-8.60599030e-05,  0.00000000e+00, -2.06870354e-05, ...,\n",
            "        -4.13769012e-05, -7.20955650e-05,  5.59873006e-05],\n",
            "       [-4.16352959e-05,  0.00000000e+00, -1.06922771e-05, ...,\n",
            "        -1.57161812e-05, -3.42412750e-05,  3.13988567e-05],\n",
            "       [-1.07741371e-05,  0.00000000e+00, -2.43085015e-06, ...,\n",
            "        -2.18195328e-06, -2.11617908e-06, -1.25044953e-05]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.01188949,  0.        , -0.00368649, -0.00430738, -0.00430097,\n",
            "       -0.00136722,  0.00279059,  0.00389039,  0.00044478, -0.00812812,\n",
            "       -0.00960365,  0.        ,  0.00792338, -0.00762162, -0.01054097,\n",
            "        0.00195305, -0.01589177, -0.00920191, -0.01198266, -0.00277236,\n",
            "       -0.01110717, -0.01212209,  0.00072522,  0.00077299,  0.        ,\n",
            "        0.00156365, -0.00040277,  0.        ,  0.00340079, -0.00053474,\n",
            "        0.        , -0.01349274, -0.00949084, -0.00618524, -0.0066694 ,\n",
            "       -0.00778304, -0.01283789,  0.00094929, -0.00264006, -0.02139774,\n",
            "        0.00156751,  0.00260583, -0.00822514,  0.00419814,  0.00922749,\n",
            "       -0.00012401, -0.00387087,  0.00550735,  0.        , -0.00127787,\n",
            "       -0.01310267,  0.        ,  0.00131898, -0.00178146,  0.        ,\n",
            "       -0.01046692, -0.00475386, -0.00871633, -0.00554913, -0.00538969,\n",
            "       -0.0087856 , -0.00431521,  0.        ,  0.00310412,  0.00372274,\n",
            "       -0.00953464, -0.00784325, -0.00079416,  0.00151203,  0.00710828,\n",
            "        0.00298048, -0.00620259, -0.02033092,  0.00259834, -0.00398878,\n",
            "       -0.00185975, -0.00079859, -0.00251757, -0.01004518, -0.01041702,\n",
            "        0.0022192 ,  0.00419798, -0.005642  , -0.01139995,  0.00663461,\n",
            "       -0.00502034, -0.00570009,  0.        , -0.00199838, -0.00124018,\n",
            "       -0.00706264,  0.        ,  0.00110862,  0.00082834, -0.0112647 ,\n",
            "       -0.00124059, -0.00900148, -0.0053477 ,  0.        ,  0.        ,\n",
            "       -0.00380532, -0.00010004,  0.0080295 ,  0.00091973, -0.01149039,\n",
            "       -0.00060615, -0.02343383, -0.00887121, -0.00435055,  0.00390965,\n",
            "        0.01036053,  0.        , -0.00940635, -0.00223166, -0.00825046,\n",
            "        0.        , -0.00997064,  0.        ,  0.00058972,  0.00053478,\n",
            "        0.01410323,  0.00081231,  0.        , -0.01168013,  0.        ,\n",
            "       -0.00383754, -0.00751641,  0.00902469], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-0.01770019, -0.00440377,  0.00402652, ..., -0.01072495,\n",
            "        -0.01017673, -0.00120955],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.00076497,  0.00040344,  0.00014725, ...,  0.00064773,\n",
            "         0.00076242,  0.00056972],\n",
            "       ...,\n",
            "       [-0.0175424 ,  0.00988995,  0.00532562, ...,  0.00100828,\n",
            "        -0.00798943, -0.00706016],\n",
            "       [-0.01399402, -0.00232359, -0.00487112, ...,  0.00518686,\n",
            "        -0.00672406,  0.004568  ],\n",
            "       [ 0.00232335,  0.00440174, -0.00026579, ..., -0.01157587,\n",
            "        -0.00655602, -0.0116283 ]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00724963, -0.03262161,  0.02655173,  0.00897475,  0.01661384,\n",
            "        0.00248763,  0.02220509, -0.0264773 ,  0.00726372, -0.01774821],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -5.78415692e-02 -4.24288120e-03 ... -2.64772959e-02\n",
            "  7.26372097e-03 -1.77482124e-02]\n",
            "1000.0014361457212\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.05811942, -0.00422929, -0.0727573 , -0.11837494,\n",
            "          -0.06481154, -0.10618146, -0.0954699 , -0.10153027,\n",
            "          -0.01539685, -0.09629746, -0.00184583, -0.07662706,\n",
            "          -0.13913213, -0.0114327 , -0.13424413, -0.08702408,\n",
            "          -0.07761   , -0.11207674, -0.10064203, -0.09227766,\n",
            "          -0.0741988 , -0.12024671, -0.00643346, -0.04364818,\n",
            "          -0.00059093, -0.12285927, -0.10611048, -0.00238273,\n",
            "          -0.02516356, -0.00584002, -0.02618241, -0.05154964]],\n",
            "\n",
            "        [[-0.07200534, -0.01550631, -0.08416365, -0.12026554,\n",
            "          -0.05083407, -0.116422  , -0.11148696, -0.10924564,\n",
            "          -0.0028963 , -0.12048983, -0.00097622, -0.09981662,\n",
            "          -0.13850822, -0.02522932, -0.13840376, -0.10794762,\n",
            "          -0.078853  , -0.1214069 , -0.05665126, -0.12258237,\n",
            "          -0.08153532, -0.10785832, -0.00687428, -0.06823288,\n",
            "          -0.00170237, -0.13636032, -0.10504063, -0.00159865,\n",
            "          -0.0307431 , -0.02180502, -0.01703734, -0.0581769 ]],\n",
            "\n",
            "        [[-0.10408552, -0.037027  , -0.08265568, -0.10048456,\n",
            "          -0.03947359, -0.11057942, -0.10894207, -0.09590779,\n",
            "          -0.01613992, -0.12059727, -0.00380796, -0.10536741,\n",
            "          -0.11338291, -0.04248036, -0.12488715, -0.10963638,\n",
            "          -0.05799009, -0.10835401, -0.0145232 , -0.13130018,\n",
            "          -0.08054063, -0.08115177, -0.01965188, -0.07254153,\n",
            "          -0.01489797, -0.1295599 , -0.10463598, -0.00285365,\n",
            "          -0.02492243, -0.05163497, -0.02093543, -0.04903871]]],\n",
            "\n",
            "\n",
            "       [[[-0.07907548, -0.00330707, -0.09410647, -0.1359132 ,\n",
            "          -0.0644135 , -0.10888159, -0.11610162, -0.12580462,\n",
            "          -0.00420293, -0.12258128, -0.0111206 , -0.10315675,\n",
            "          -0.13008586, -0.00352561, -0.11353222, -0.10834083,\n",
            "          -0.10724498, -0.12073702, -0.1055922 , -0.10097967,\n",
            "          -0.10556459, -0.11488877, -0.03373228, -0.06687268,\n",
            "          -0.00249885, -0.13576306, -0.0728568 , -0.01542801,\n",
            "          -0.00944098, -0.00183566, -0.00404422, -0.089916  ]],\n",
            "\n",
            "        [[-0.08513732, -0.01846283, -0.09349767, -0.13556337,\n",
            "          -0.05395079, -0.11511086, -0.1302284 , -0.13226849,\n",
            "          -0.01099177, -0.14117621,  0.00053167, -0.12701951,\n",
            "          -0.11814544, -0.01487587, -0.1130641 , -0.12708579,\n",
            "          -0.10086929, -0.12211823, -0.05128396, -0.13100159,\n",
            "          -0.10944936, -0.08833057, -0.04249756, -0.07472803,\n",
            "          -0.00902157, -0.14195111, -0.06828758, -0.01531836,\n",
            "          -0.00541977, -0.00717835, -0.00207196, -0.09250158]],\n",
            "\n",
            "        [[-0.10301004, -0.05770063, -0.07447781, -0.11130339,\n",
            "          -0.02871186, -0.10513221, -0.12079607, -0.11092858,\n",
            "          -0.04220637, -0.13655308,  0.00058381, -0.13061118,\n",
            "          -0.08960561, -0.04975506, -0.09695221, -0.11980867,\n",
            "          -0.07729104, -0.10117725, -0.00953224, -0.13723977,\n",
            "          -0.09948587, -0.05599444, -0.06529029, -0.05292191,\n",
            "          -0.03477129, -0.12513259, -0.07601462, -0.0221273 ,\n",
            "          -0.00274131, -0.02831927, -0.0029983 , -0.07069822]]],\n",
            "\n",
            "\n",
            "       [[[-0.07019266, -0.00432852, -0.0963167 , -0.12322142,\n",
            "          -0.07598362, -0.09470221, -0.11643885, -0.12012719,\n",
            "          -0.0096569 , -0.11957199, -0.03313339, -0.10925841,\n",
            "          -0.09748416, -0.00265197, -0.07949112, -0.11035962,\n",
            "          -0.12676094, -0.11677326, -0.10003882, -0.08817831,\n",
            "          -0.12027915, -0.09311134, -0.07029848, -0.05225567,\n",
            "          -0.00257121, -0.12154528, -0.03310471, -0.03171479,\n",
            "          -0.00205798, -0.00140931, -0.01384506, -0.11839059]],\n",
            "\n",
            "        [[-0.06235053, -0.03061925, -0.08029333, -0.12184511,\n",
            "          -0.05560802, -0.09723098, -0.12264512, -0.12106404,\n",
            "          -0.03614305, -0.12683083, -0.01063039, -0.12936956,\n",
            "          -0.0814646 , -0.01150512, -0.07344984, -0.11857743,\n",
            "          -0.1146042 , -0.1098716 , -0.04764017, -0.11338536,\n",
            "          -0.11741309, -0.06420111, -0.08908147, -0.0562694 ,\n",
            "          -0.01288597, -0.11919014, -0.0343134 , -0.04765347,\n",
            "          -0.00190384, -0.00186381, -0.00578901, -0.11125064]],\n",
            "\n",
            "        [[-0.06472591, -0.08366115, -0.04918785, -0.09885831,\n",
            "          -0.0177031 , -0.085969  , -0.10953758, -0.09865624,\n",
            "          -0.05871349, -0.11373218, -0.00199818, -0.12852447,\n",
            "          -0.05619876, -0.05422905, -0.06072487, -0.1082835 ,\n",
            "          -0.09127358, -0.08583304, -0.01222594, -0.11400977,\n",
            "          -0.09762719, -0.03300338, -0.11131915, -0.03539969,\n",
            "          -0.04026259, -0.09808395, -0.04613139, -0.06875326,\n",
            "          -0.00154946, -0.01010286, -0.00263732, -0.0797811 ]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.00488541, -0.07477199,  0.01081681, -0.06058314, -0.01521024,\n",
            "       -0.06639372, -0.07834114, -0.05575762, -0.10137118, -0.09235619,\n",
            "       -0.1083391 , -0.05241019, -0.08791044, -0.05221643, -0.07799737,\n",
            "       -0.06739697, -0.04817595, -0.09003508, -0.05904772, -0.06734384,\n",
            "       -0.03744315, -0.0471604 , -0.10137796, -0.00360782, -0.08973682,\n",
            "       -0.10840823, -0.05586694, -0.09233673, -0.00704749, -0.05061234,\n",
            "       -0.03073479,  0.11918291], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-7.3059141e-09,  0.0000000e+00, -4.4207432e-06, ...,\n",
            "        -7.7277437e-06,  2.7636295e-06,  6.7152700e-06],\n",
            "       [-4.4718719e-05,  0.0000000e+00, -1.1134738e-05, ...,\n",
            "        -2.7998678e-05, -4.8073674e-05,  3.1231404e-05],\n",
            "       [-3.3685292e-06,  0.0000000e+00, -6.6712105e-06, ...,\n",
            "        -8.9827263e-06, -1.8229608e-06,  1.9979994e-05],\n",
            "       ...,\n",
            "       [-8.6294051e-05,  0.0000000e+00, -2.0801170e-05, ...,\n",
            "        -4.1455281e-05, -7.2473296e-05,  5.6369299e-05],\n",
            "       [-4.1703315e-05,  0.0000000e+00, -1.0739296e-05, ...,\n",
            "        -1.5724758e-05, -3.4379478e-05,  3.1553529e-05],\n",
            "       [-1.1842288e-05,  0.0000000e+00, -2.8516461e-06, ...,\n",
            "        -2.9862258e-06, -2.3889470e-06, -1.2124713e-05]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.01199403,  0.        , -0.00371982, -0.00430864, -0.00425689,\n",
            "       -0.001309  ,  0.00282544,  0.00395476,  0.00047529, -0.00823909,\n",
            "       -0.00964318,  0.        ,  0.00788594, -0.00781614, -0.01060146,\n",
            "        0.00199747, -0.01606054, -0.00925212, -0.01199459, -0.00278581,\n",
            "       -0.01123693, -0.0122548 ,  0.00065994,  0.00077266,  0.        ,\n",
            "        0.00154131, -0.00036459,  0.        ,  0.00338191, -0.00053645,\n",
            "        0.        , -0.01367256, -0.00949691, -0.0062411 , -0.00659412,\n",
            "       -0.00786587, -0.01299087,  0.00098474, -0.00279998, -0.02149383,\n",
            "        0.00158707,  0.00260873, -0.00838277,  0.00418423,  0.00936844,\n",
            "       -0.00012574, -0.00391946,  0.00554408,  0.        , -0.00130724,\n",
            "       -0.01316437,  0.        ,  0.00121537, -0.00178972,  0.        ,\n",
            "       -0.01039135, -0.00477648, -0.00882162, -0.00557739, -0.00533061,\n",
            "       -0.0088951 , -0.00438843,  0.        ,  0.00307476,  0.0037122 ,\n",
            "       -0.00956834, -0.00780043, -0.00088479,  0.0015752 ,  0.00721754,\n",
            "        0.00298968, -0.00618956, -0.02054917,  0.0026708 , -0.00403696,\n",
            "       -0.00196273, -0.00085261, -0.00244311, -0.01060043, -0.01046834,\n",
            "        0.00225608,  0.00420783, -0.00565734, -0.0114232 ,  0.00682852,\n",
            "       -0.00507771, -0.00579093,  0.        , -0.0020566 , -0.0012347 ,\n",
            "       -0.00742875,  0.        ,  0.00116612,  0.00084834, -0.01133456,\n",
            "       -0.00127588, -0.00912647, -0.00543364,  0.        ,  0.        ,\n",
            "       -0.00383317, -0.00010062,  0.00808597,  0.00089034, -0.01161287,\n",
            "       -0.00061082, -0.02336233, -0.00893968, -0.00441533,  0.00397265,\n",
            "        0.01028351,  0.        , -0.00942693, -0.00231544, -0.00841305,\n",
            "        0.        , -0.0100735 ,  0.        ,  0.00067087,  0.00056063,\n",
            "        0.01419915,  0.00082765,  0.        , -0.01182333,  0.        ,\n",
            "       -0.0038668 , -0.00763237,  0.00910777], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-0.01786499, -0.00443002,  0.0040163 , ..., -0.01066428,\n",
            "        -0.01019889, -0.0011442 ],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.00075882,  0.00040711,  0.00014668, ...,  0.00065083,\n",
            "         0.00076477,  0.00057209],\n",
            "       ...,\n",
            "       [-0.01772929,  0.0098761 ,  0.00533606, ...,  0.00102567,\n",
            "        -0.00800002, -0.00700356],\n",
            "       [-0.01414397, -0.00233611, -0.00488153, ...,  0.00521087,\n",
            "        -0.00672234,  0.00458439],\n",
            "       [ 0.00228587,  0.004391  , -0.00031227, ..., -0.01155149,\n",
            "        -0.00663668, -0.01153616]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00745265, -0.0329112 ,  0.02667022,  0.00892194,  0.01675658,\n",
            "        0.0027526 ,  0.02239043, -0.02654495,  0.00713083, -0.01771379],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -5.81194237e-02 -4.22929414e-03 ... -2.65449509e-02\n",
            "  7.13082589e-03 -1.77137870e-02]\n",
            "1000.0014493463805\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.05847432, -0.00421391, -0.0730481 , -0.11933135,\n",
            "          -0.0649227 , -0.1068665 , -0.0960203 , -0.10201329,\n",
            "          -0.01542455, -0.09699561, -0.00179657, -0.0772103 ,\n",
            "          -0.14002067, -0.01152412, -0.13522601, -0.08761109,\n",
            "          -0.07821578, -0.11296748, -0.10115512, -0.09279854,\n",
            "          -0.07461765, -0.12094176, -0.00657421, -0.04346221,\n",
            "          -0.00060301, -0.12368397, -0.10681999, -0.00239913,\n",
            "          -0.02520783, -0.00579987, -0.02627955, -0.0531257 ]],\n",
            "\n",
            "        [[-0.07252511, -0.01544319, -0.0845344 , -0.12119247,\n",
            "          -0.05071696, -0.11720707, -0.11214729, -0.10987434,\n",
            "          -0.00286823, -0.12149981, -0.00100987, -0.10063804,\n",
            "          -0.13931568, -0.02532999, -0.13943137, -0.10868829,\n",
            "          -0.07954595, -0.12233548, -0.05697156, -0.12337115,\n",
            "          -0.08190586, -0.10838817, -0.00694341, -0.06819718,\n",
            "          -0.00170889, -0.13738023, -0.10568084, -0.00161279,\n",
            "          -0.03082687, -0.02180186, -0.01709984, -0.05967375]],\n",
            "\n",
            "        [[-0.10479282, -0.03691198, -0.08307929, -0.1012153 ,\n",
            "          -0.03941233, -0.11132665, -0.1095739 , -0.09653562,\n",
            "          -0.01608574, -0.12156409, -0.00384483, -0.10616713,\n",
            "          -0.11385854, -0.04255408, -0.12583143, -0.11035818,\n",
            "          -0.05854589, -0.10924809, -0.01458973, -0.13222387,\n",
            "          -0.08095467, -0.08151548, -0.01968483, -0.07265501,\n",
            "          -0.01485208, -0.13050602, -0.10524073, -0.00286069,\n",
            "          -0.02495678, -0.05175023, -0.02098771, -0.05044308]]],\n",
            "\n",
            "\n",
            "       [[[-0.07969627, -0.00331094, -0.09455534, -0.13686712,\n",
            "          -0.06447539, -0.10964079, -0.11677547, -0.12651628,\n",
            "          -0.00423864, -0.12343417, -0.01110178, -0.10385055,\n",
            "          -0.13088182, -0.00355448, -0.11432762, -0.10906069,\n",
            "          -0.10796752, -0.12168358, -0.10612233, -0.1015898 ,\n",
            "          -0.10622117, -0.1156404 , -0.03398678, -0.0668131 ,\n",
            "          -0.00249321, -0.13673243, -0.07326695, -0.01546165,\n",
            "          -0.00946222, -0.00183255, -0.00403678, -0.09164628]],\n",
            "\n",
            "        [[-0.085814  , -0.01843761, -0.09405881, -0.13650037,\n",
            "          -0.05390266, -0.11595719, -0.13101709, -0.13306266,\n",
            "          -0.01100955, -0.14225674,  0.00052542, -0.12791277,\n",
            "          -0.11876392, -0.01489236, -0.11391351, -0.12794477,\n",
            "          -0.10159408, -0.12307427, -0.05146875, -0.13188252,\n",
            "          -0.11001153, -0.08880329, -0.04262763, -0.07473294,\n",
            "          -0.00899042, -0.14299983, -0.0686658 , -0.01531478,\n",
            "          -0.0054302 , -0.00715422, -0.00209066, -0.0941085 ]],\n",
            "\n",
            "        [[-0.10376759, -0.05772533, -0.07494905, -0.11198491,\n",
            "          -0.02862246, -0.10587692, -0.12155941, -0.11164118,\n",
            "          -0.04230827, -0.13762036,  0.00059731, -0.13152406,\n",
            "          -0.08993292, -0.04989339, -0.09758748, -0.12065578,\n",
            "          -0.07790895, -0.10199782, -0.00945777, -0.13820729,\n",
            "          -0.10002622, -0.05623638, -0.0655214 , -0.05293937,\n",
            "          -0.03476483, -0.12602471, -0.0764816 , -0.02201237,\n",
            "          -0.00275471, -0.02836042, -0.00300795, -0.07215215]]],\n",
            "\n",
            "\n",
            "       [[[-0.07075022, -0.00439148, -0.09693427, -0.12405743,\n",
            "          -0.07617824, -0.09541138, -0.11718176, -0.12082687,\n",
            "          -0.00970906, -0.12048067, -0.03317207, -0.11006137,\n",
            "          -0.09805165, -0.00266723, -0.07999999, -0.1111092 ,\n",
            "          -0.12765974, -0.11767404, -0.10049536, -0.08877572,\n",
            "          -0.12110628, -0.0937139 , -0.07063802, -0.05222885,\n",
            "          -0.00253858, -0.12241562, -0.03326108, -0.03171485,\n",
            "          -0.00207738, -0.00141392, -0.0138326 , -0.1201883 ]],\n",
            "\n",
            "        [[-0.06280386, -0.03068213, -0.08084657, -0.12268954,\n",
            "          -0.05567463, -0.09800815, -0.12344334, -0.12180609,\n",
            "          -0.03621822, -0.12782487, -0.01061499, -0.13030532,\n",
            "          -0.08189119, -0.01151255, -0.07395829, -0.11942048,\n",
            "          -0.11548484, -0.11069915, -0.04777826, -0.11423726,\n",
            "          -0.11814494, -0.06455669, -0.0894895 , -0.05627539,\n",
            "          -0.01282077, -0.12010342, -0.03445316, -0.04765333,\n",
            "          -0.00191981, -0.00186408, -0.0057918 , -0.11284721]],\n",
            "\n",
            "        [[-0.06521245, -0.0839166 , -0.0494729 , -0.09950395,\n",
            "          -0.01764238, -0.08660631, -0.11028076, -0.09928231,\n",
            "          -0.05880539, -0.11464278, -0.00194525, -0.12945214,\n",
            "          -0.05640974, -0.05438739, -0.06111677, -0.10910335,\n",
            "          -0.09203891, -0.08653901, -0.01226919, -0.11487403,\n",
            "          -0.09816444, -0.03311436, -0.11193614, -0.03540445,\n",
            "          -0.04022674, -0.09884724, -0.04645963, -0.06883701,\n",
            "          -0.00156511, -0.01008998, -0.00263662, -0.08121939]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.00231823, -0.07400235,  0.01127039, -0.0610249 , -0.01186687,\n",
            "       -0.06659918, -0.07841444, -0.05556636, -0.10077633, -0.09112182,\n",
            "       -0.10858697, -0.0521044 , -0.08739471, -0.05164877, -0.07758013,\n",
            "       -0.0675276 , -0.04761274, -0.09020345, -0.05763562, -0.06732375,\n",
            "       -0.03697708, -0.0456718 , -0.10056663, -0.00598622, -0.08939803,\n",
            "       -0.10855956, -0.0547986 , -0.09202539, -0.00666771, -0.05052174,\n",
            "       -0.03025068,  0.11800332], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[ 1.9424061e-07,  0.0000000e+00, -4.3409987e-06, ...,\n",
            "        -7.7050299e-06,  2.7902161e-06,  6.5645836e-06],\n",
            "       [-4.4379645e-05,  0.0000000e+00, -1.1096771e-05, ...,\n",
            "        -2.8269562e-05, -4.8126061e-05,  3.1142481e-05],\n",
            "       [-3.3407362e-06,  0.0000000e+00, -6.6658122e-06, ...,\n",
            "        -8.9788027e-06, -1.9093045e-06,  2.0003738e-05],\n",
            "       ...,\n",
            "       [-8.6523061e-05,  0.0000000e+00, -2.0916128e-05, ...,\n",
            "        -4.2297008e-05, -7.3175106e-05,  5.6748690e-05],\n",
            "       [-4.1767988e-05,  0.0000000e+00, -1.0786510e-05, ...,\n",
            "        -1.6126360e-05, -3.4685090e-05,  3.1707041e-05],\n",
            "       [-1.4061847e-05,  0.0000000e+00, -3.4595948e-06, ...,\n",
            "        -4.6445170e-06, -3.4029592e-06, -1.1413262e-05]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.01209886,  0.        , -0.00375367, -0.00430914, -0.00421188,\n",
            "       -0.00124996,  0.00286742,  0.00401887,  0.00050571, -0.00835115,\n",
            "       -0.00968265,  0.        ,  0.00784623, -0.00795242, -0.01068322,\n",
            "        0.0020418 , -0.01622065, -0.00930148, -0.01221464, -0.00285316,\n",
            "       -0.01137567, -0.01235523,  0.00059333,  0.00077205,  0.        ,\n",
            "        0.00161441, -0.00042952,  0.        ,  0.00343868, -0.00053816,\n",
            "        0.        , -0.01375052, -0.00961498, -0.00631727, -0.00661522,\n",
            "       -0.00798674, -0.01314468,  0.00105031, -0.00285747, -0.02158257,\n",
            "        0.00160642,  0.00262561, -0.00854157,  0.00416907,  0.00951013,\n",
            "       -0.00012747, -0.003969  ,  0.00558083,  0.        , -0.00133744,\n",
            "       -0.0132267 ,  0.        ,  0.00122158, -0.00179811,  0.        ,\n",
            "       -0.01057273, -0.00479922, -0.00908884, -0.00560575, -0.00527011,\n",
            "       -0.00896333, -0.00439951,  0.        ,  0.00313976,  0.00370119,\n",
            "       -0.00960062, -0.00792964, -0.00098147,  0.00160959,  0.00732716,\n",
            "        0.00306523, -0.00617588, -0.020847  ,  0.0027437 , -0.00409919,\n",
            "       -0.00206822, -0.00090733, -0.00236739, -0.01080336, -0.0105197 ,\n",
            "        0.00229361,  0.00421716, -0.005672  , -0.01151563,  0.00689762,\n",
            "       -0.00513591, -0.00588306,  0.        , -0.00211559, -0.00115548,\n",
            "       -0.00755621,  0.        ,  0.00122451,  0.00086872, -0.0113554 ,\n",
            "       -0.00139053, -0.00918899, -0.00545464,  0.        ,  0.        ,\n",
            "       -0.00386139, -0.0001012 ,  0.00814199,  0.00088431, -0.01175629,\n",
            "       -0.00061556, -0.02369112, -0.00900852, -0.00448042,  0.00403607,\n",
            "        0.01030383,  0.        , -0.00944644, -0.00240152, -0.00861174,\n",
            "        0.        , -0.01017706,  0.        ,  0.00075352,  0.0005862 ,\n",
            "        0.01429426,  0.00084011,  0.        , -0.01205666,  0.        ,\n",
            "       -0.00395397, -0.0078109 ,  0.0091911 ], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-0.01803011, -0.00445459,  0.00400487, ..., -0.01060148,\n",
            "        -0.01021989, -0.00107784],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.00075251,  0.00041081,  0.00014604, ...,  0.00065399,\n",
            "         0.00076711,  0.00057451],\n",
            "       ...,\n",
            "       [-0.01791611,  0.00986234,  0.00534563, ...,  0.00104371,\n",
            "        -0.00800938, -0.00694532],\n",
            "       [-0.01429377, -0.00234693, -0.00489283, ...,  0.00523501,\n",
            "        -0.00671983,  0.00460098],\n",
            "       [ 0.00224799,  0.00438136, -0.00036073, ..., -0.01152445,\n",
            "        -0.00671673, -0.01144119]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00765873, -0.03320095,  0.02678628,  0.0088673 ,  0.01689728,\n",
            "        0.00302115,  0.02257497, -0.02660909,  0.00699619, -0.01767441],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -5.84743172e-02 -4.21390776e-03 ... -2.66090855e-02\n",
            "  6.99619111e-03 -1.76744051e-02]\n",
            "1000.001464525541\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.05861463, -0.00428638, -0.07369171, -0.12023776,\n",
            "          -0.06489383, -0.10765274, -0.0966299 , -0.10257825,\n",
            "          -0.0155465 , -0.09752417, -0.00176846, -0.07776416,\n",
            "          -0.14090002, -0.01158455, -0.13621902, -0.08823222,\n",
            "          -0.078741  , -0.11389393, -0.10151594, -0.09337063,\n",
            "          -0.07490201, -0.12171286, -0.00664643, -0.04311933,\n",
            "          -0.00059885, -0.12442112, -0.10755468, -0.00244146,\n",
            "          -0.02525131, -0.00582692, -0.02633451, -0.05422134]],\n",
            "\n",
            "        [[-0.07265058, -0.01547887, -0.08518384, -0.12210815,\n",
            "          -0.05078917, -0.11809067, -0.1128615 , -0.11050136,\n",
            "          -0.00286937, -0.1221755 , -0.00102939, -0.10153095,\n",
            "          -0.14014   , -0.02547388, -0.1404601 , -0.10942537,\n",
            "          -0.08012797, -0.12332211, -0.05700993, -0.12417238,\n",
            "          -0.0821773 , -0.10898243, -0.00697899, -0.06777041,\n",
            "          -0.00171797, -0.13825123, -0.10632233, -0.00163395,\n",
            "          -0.0308967 , -0.02187156, -0.01710928, -0.06081648]],\n",
            "\n",
            "        [[-0.10521924, -0.0369381 , -0.08367853, -0.10201816,\n",
            "          -0.03948146, -0.11212671, -0.11026704, -0.09703126,\n",
            "          -0.01610198, -0.12227055, -0.00384922, -0.10704752,\n",
            "          -0.11449201, -0.04277145, -0.1267027 , -0.11109185,\n",
            "          -0.05895541, -0.11003114, -0.01453212, -0.13318849,\n",
            "          -0.0813994 , -0.08196663, -0.01982492, -0.07227083,\n",
            "          -0.01478643, -0.13136041, -0.10580103, -0.00283593,\n",
            "          -0.02504129, -0.05188302, -0.02101781, -0.05159841]]],\n",
            "\n",
            "\n",
            "       [[[-0.07991689, -0.00334838, -0.09534269, -0.13785133,\n",
            "          -0.0644383 , -0.11044922, -0.11760267, -0.12726569,\n",
            "          -0.00430953, -0.12418528, -0.01114034, -0.10460737,\n",
            "          -0.13160005, -0.00355977, -0.11494324, -0.10982655,\n",
            "          -0.10862966, -0.12270404, -0.10662866, -0.10224944,\n",
            "          -0.10675752, -0.11633542, -0.03418078, -0.06651162,\n",
            "          -0.002506  , -0.13762514, -0.07374214, -0.0154541 ,\n",
            "          -0.00947682, -0.00183862, -0.00404551, -0.09292005]],\n",
            "\n",
            "        [[-0.0860406 , -0.01845244, -0.09482041, -0.13745369,\n",
            "          -0.05400345, -0.11685023, -0.1319308 , -0.1338464 ,\n",
            "          -0.01101773, -0.14328474,  0.0005056 , -0.12888908,\n",
            "          -0.11936365, -0.01495715, -0.11459737, -0.12877068,\n",
            "          -0.10218452, -0.12404423, -0.05154997, -0.13284019,\n",
            "          -0.11056413, -0.08929265, -0.04276193, -0.07439886,\n",
            "          -0.00899324, -0.14389287, -0.06903857, -0.01520745,\n",
            "          -0.00544695, -0.00718807, -0.00209766, -0.09544449]],\n",
            "\n",
            "        [[-0.10427317, -0.05785226, -0.07553707, -0.11275611,\n",
            "          -0.02857617, -0.10665608, -0.12237892, -0.11223833,\n",
            "          -0.04242091, -0.13861379,  0.00060467, -0.13251281,\n",
            "          -0.09034767, -0.05011202, -0.09822422, -0.12142111,\n",
            "          -0.07836905, -0.10265312, -0.00945614, -0.13922723,\n",
            "          -0.10057519, -0.05649681, -0.06588887, -0.05254499,\n",
            "          -0.03476486, -0.1267552 , -0.07686689, -0.02173916,\n",
            "          -0.00276143, -0.02842065, -0.0030189 , -0.07340848]]],\n",
            "\n",
            "\n",
            "       [[[-0.07089471, -0.00435064, -0.0977113 , -0.12505323,\n",
            "          -0.07620481, -0.09615268, -0.11804017, -0.12155566,\n",
            "          -0.00977764, -0.12141848, -0.03329903, -0.11091167,\n",
            "          -0.09856261, -0.00268015, -0.08030836, -0.11190092,\n",
            "          -0.12853862, -0.11863514, -0.10091638, -0.08936313,\n",
            "          -0.12189715, -0.09427664, -0.07088022, -0.0519585 ,\n",
            "          -0.00254163, -0.12326822, -0.03354175, -0.03160155,\n",
            "          -0.00208969, -0.00141623, -0.01383736, -0.12168074]],\n",
            "\n",
            "        [[-0.06290939, -0.03066599, -0.08146772, -0.1235918 ,\n",
            "          -0.05561738, -0.09876937, -0.1243232 , -0.12252577,\n",
            "          -0.03634095, -0.12879749, -0.01065443, -0.13122404,\n",
            "          -0.0822802 , -0.01154422, -0.07432081, -0.12021498,\n",
            "          -0.1162586 , -0.11157402, -0.04793047, -0.11508825,\n",
            "          -0.11889115, -0.06490274, -0.08988603, -0.05602351,\n",
            "          -0.01277093, -0.12084079, -0.0346403 , -0.04751369,\n",
            "          -0.00192862, -0.00187072, -0.00576382, -0.11427701]],\n",
            "\n",
            "        [[-0.06544175, -0.08418769, -0.049884  , -0.1002825 ,\n",
            "          -0.01738907, -0.08725259, -0.11103476, -0.09988879,\n",
            "          -0.05891274, -0.11553375, -0.00192519, -0.13042584,\n",
            "          -0.05664314, -0.054607  , -0.06148362, -0.10982472,\n",
            "          -0.09268206, -0.0871359 , -0.01231492, -0.11568889,\n",
            "          -0.09876974, -0.03325662, -0.11254495, -0.03508344,\n",
            "          -0.04019014, -0.09941702, -0.04671359, -0.06875589,\n",
            "          -0.00157287, -0.01005641, -0.00260801, -0.08251778]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([ 0.00058628, -0.07351322,  0.01160895, -0.06195279, -0.00874634,\n",
            "       -0.06705468, -0.07849105, -0.05568107, -0.10032787, -0.08959685,\n",
            "       -0.10892087, -0.05186416, -0.08662532, -0.05133912, -0.07707006,\n",
            "       -0.06797397, -0.04677858, -0.09013033, -0.05548339, -0.06748063,\n",
            "       -0.03655029, -0.04439217, -0.09899178, -0.00756732, -0.08941846,\n",
            "       -0.10874224, -0.05378518, -0.0913196 , -0.00642988, -0.05022663,\n",
            "       -0.0296153 ,  0.1254678 ], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[ 3.8060239e-07,  0.0000000e+00, -4.2688689e-06, ...,\n",
            "        -7.6849228e-06,  2.7404840e-06,  6.4322312e-06],\n",
            "       [-4.4037719e-05,  0.0000000e+00, -1.1058645e-05, ...,\n",
            "        -2.7375761e-05, -4.7966481e-05,  3.1052710e-05],\n",
            "       [-3.3137001e-06,  0.0000000e+00, -6.6614857e-06, ...,\n",
            "        -8.9752366e-06, -2.1233695e-06,  2.0029707e-05],\n",
            "       ...,\n",
            "       [-8.6746157e-05,  0.0000000e+00, -2.1031537e-05, ...,\n",
            "        -4.1214960e-05, -7.3550160e-05,  5.7128447e-05],\n",
            "       [-4.1834213e-05,  0.0000000e+00, -1.0834894e-05, ...,\n",
            "        -1.5684778e-05, -3.4825931e-05,  3.1864103e-05],\n",
            "       [-1.7342411e-05,  0.0000000e+00, -4.2876627e-06, ...,\n",
            "        -5.8086730e-06, -4.9002219e-06, -9.7588245e-06]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-0.01220393,  0.        , -0.003788  , -0.00438706, -0.00433363,\n",
            "       -0.00118979,  0.0029092 ,  0.00408317,  0.00053608, -0.00846474,\n",
            "       -0.00974256,  0.        ,  0.00780449, -0.00808987, -0.01076489,\n",
            "        0.00208603, -0.01638089, -0.00935028, -0.01237363, -0.00286769,\n",
            "       -0.01150863, -0.01263709,  0.00052566,  0.00077111,  0.        ,\n",
            "        0.00168929, -0.00049464,  0.        ,  0.00357396, -0.00053987,\n",
            "        0.        , -0.01382869, -0.00977301, -0.00624038, -0.00663594,\n",
            "       -0.00812195, -0.01330006,  0.00114866, -0.00298463, -0.02159989,\n",
            "        0.00160473,  0.00264358, -0.008702  ,  0.00415285,  0.00965329,\n",
            "       -0.00012917, -0.00401942,  0.00561768,  0.        , -0.00136838,\n",
            "       -0.01349121,  0.        ,  0.00122697, -0.00180664,  0.        ,\n",
            "       -0.01066382, -0.00482207, -0.00919602, -0.00572176, -0.00520856,\n",
            "       -0.00906052, -0.00447257,  0.        ,  0.0031074 ,  0.00369018,\n",
            "       -0.00963178, -0.00806014, -0.00090514,  0.00167317,  0.00743759,\n",
            "        0.00308361, -0.00616154, -0.02106748,  0.0028174 , -0.00416271,\n",
            "       -0.00231553, -0.00096243, -0.00228992, -0.01108332, -0.01057106,\n",
            "        0.00233155,  0.00422616, -0.00568626, -0.01153701,  0.00696655,\n",
            "       -0.00519493, -0.00597663,  0.        , -0.00217585, -0.00115033,\n",
            "       -0.00768581,  0.        ,  0.00128435,  0.00088977, -0.01142172,\n",
            "       -0.00151152, -0.00925208, -0.00554169,  0.        ,  0.        ,\n",
            "       -0.00391701, -0.00010178,  0.00819783,  0.00087809, -0.0119017 ,\n",
            "       -0.00062037, -0.02377893, -0.00907786, -0.0045463 ,  0.0041004 ,\n",
            "        0.01032285,  0.        , -0.00946513, -0.00248958, -0.00877952,\n",
            "        0.        , -0.01028143,  0.        ,  0.00083783,  0.00061134,\n",
            "        0.014389  ,  0.00085308,  0.        , -0.01220124,  0.        ,\n",
            "       -0.00390255, -0.00799028,  0.00927526], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-0.01819573, -0.00447757,  0.00399275, ..., -0.01053693,\n",
            "        -0.01023997, -0.0010107 ],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.00074599,  0.00041448,  0.00014547, ...,  0.0006572 ,\n",
            "         0.00076943,  0.00057697],\n",
            "       ...,\n",
            "       [-0.01810331,  0.0098482 ,  0.00535459, ...,  0.00106274,\n",
            "        -0.00801749, -0.0068858 ],\n",
            "       [-0.0144436 , -0.00235659, -0.00490474, ...,  0.00525907,\n",
            "        -0.00671638,  0.00461754],\n",
            "       [ 0.00220944,  0.00437155, -0.00041008, ..., -0.01149451,\n",
            "        -0.0067964 , -0.01134424]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00786848, -0.03349201,  0.02690111,  0.00881049,  0.01703617,\n",
            "        0.00329417,  0.02275996, -0.0266693 ,  0.00685939, -0.0176315 ],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -5.86146340e-02 -4.28638095e-03 ... -2.66692992e-02\n",
            "  6.85939193e-03 -1.76315028e-02]\n",
            "1000.001479949356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZjbQBHOldN"
      },
      "source": [
        "Step5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta3 = 1\n",
        "\n",
        "weights_updated = ordinary_weights\n",
        "for i in range(1):\n",
        "\n",
        "  # 重みをw + (step4で決めた)vに設定する　　ここから\n",
        "  current_weights = []\n",
        "  for layer_weights, v in zip(weights_updated, v_updated):\n",
        "    current_layer_weight = tf.add(layer_weights, v)\n",
        "    current_weights.append(current_layer_weight)\n",
        "  model.set_weights(current_weights)\n",
        "  print(current_weights) \n",
        "  # 計算できている．\n",
        "  # 重みをw + (step4で決めた)vに設定する　　ここまで\n",
        "\n",
        "  # # gradientの計算　　ここから\n",
        "  # with tf.GradientTape() as tape:\n",
        "  #   loss = calculate_loss(adversarial_ds)\n",
        "  #   print(loss)\n",
        "  # gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  # # print(gradients) \n",
        "  # # 計算できているが，値が大きい．\n",
        "  # # gradientの計算　　ここまで\n",
        "\n",
        "  # # 勾配降下の実行　　ここから\n",
        "  # w_hat = []\n",
        "  # for wu, g in zip(weights_updated, gradients):\n",
        "  #   g_med = tf.multiply(eta3, g)\n",
        "  #   wu = tf.subtract(wu, g_med)\n",
        "  #   w_hat.append(wu)\n",
        "  # weights_updated = w_hat\n",
        "  # # 勾配降下の実行　　ここまで"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0bd9iyoK9EB",
        "outputId": "757cd14e-bfd6-4be4-b7a6-b81e7a382fcf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[ 0.00626376, -0.08222854,  0.04752608,  0.12255036,\n",
            "           0.10901851,  0.06975508, -0.08017899, -0.05415868,\n",
            "           0.06841972,  0.00964763, -0.12686184,  0.01810137,\n",
            "           0.1178217 , -0.03064042,  0.09693366, -0.0345461 ,\n",
            "          -0.05347079,  0.02703916, -0.01745234,  0.07549892,\n",
            "           0.10777961,  0.11346884, -0.05756018, -0.09332153,\n",
            "          -0.06876156, -0.02949584,  0.12017987, -0.13779223,\n",
            "          -0.06047055, -0.07711827,  0.05061313, -0.11099961]],\n",
            "\n",
            "        [[-0.12811439,  0.07229637, -0.13631311,  0.00432086,\n",
            "          -0.11989284,  0.05658707,  0.1119903 ,  0.08980337,\n",
            "          -0.11154863,  0.01411374,  0.04548049,  0.10528793,\n",
            "           0.1087066 ,  0.11656798,  0.02099298,  0.12097807,\n",
            "           0.13599546,  0.08144231,  0.03921156, -0.02540363,\n",
            "          -0.13546516, -0.02493352, -0.07246671, -0.00507573,\n",
            "          -0.10911008,  0.09015806,  0.02487235, -0.03863813,\n",
            "           0.0972897 , -0.03475939, -0.05772179,  0.01917199]],\n",
            "\n",
            "        [[ 0.10090632, -0.099798  ,  0.13597119, -0.11516773,\n",
            "           0.05944049,  0.04373515,  0.02483687, -0.08237915,\n",
            "          -0.10708357, -0.02155419,  0.00378112, -0.13344654,\n",
            "           0.09442652, -0.0884831 ,  0.08873914,  0.03421953,\n",
            "          -0.05462254,  0.09673025, -0.05463753,  0.09166058,\n",
            "           0.11030751,  0.12793986, -0.09413882,  0.05831396,\n",
            "          -0.10986062,  0.12220918,  0.1075667 , -0.02376658,\n",
            "          -0.02042001,  0.0834806 ,  0.03450918, -0.12391651]]],\n",
            "\n",
            "\n",
            "       [[[ 0.04580938, -0.13231899, -0.058844  ,  0.08650705,\n",
            "          -0.13963932,  0.06008456,  0.12263506,  0.13159144,\n",
            "          -0.05437912, -0.04194704, -0.03060203, -0.06937286,\n",
            "           0.12380897, -0.12992235,  0.12584813,  0.11487631,\n",
            "           0.01726334,  0.04464432,  0.11977243, -0.02466988,\n",
            "           0.01020902,  0.05220045,  0.07516835,  0.10722262,\n",
            "          -0.00500383,  0.14068864,  0.01092982,  0.07331425,\n",
            "           0.00749392, -0.10590629, -0.13458571,  0.01947603]],\n",
            "\n",
            "        [[ 0.00233916,  0.0429573 ,  0.09847283,  0.12052946,\n",
            "           0.07272877, -0.11553994, -0.08483265,  0.05659692,\n",
            "          -0.12566446,  0.11610118, -0.04689729,  0.04832124,\n",
            "           0.06890563, -0.05448425, -0.08639426, -0.05250475,\n",
            "          -0.04842327, -0.08603539, -0.11151602,  0.1387764 ,\n",
            "          -0.12751548, -0.02238348, -0.1010846 ,  0.05484742,\n",
            "           0.11794037, -0.0287606 , -0.13252223,  0.00434477,\n",
            "          -0.00758174, -0.02508523,  0.0309525 ,  0.06810823]],\n",
            "\n",
            "        [[ 0.08962135,  0.01291404, -0.01845773,  0.06420265,\n",
            "          -0.01828611,  0.0477737 ,  0.04284055,  0.11767825,\n",
            "           0.1354277 ,  0.06456859, -0.12536782,  0.13404025,\n",
            "          -0.05524478,  0.07684004,  0.01403948,  0.04017402,\n",
            "          -0.06597225, -0.09747927, -0.03473847,  0.06201446,\n",
            "           0.06747039, -0.09416085,  0.06796077, -0.09022901,\n",
            "           0.13515443, -0.02465907, -0.0203429 , -0.1055688 ,\n",
            "          -0.12797058,  0.0570708 , -0.08672358,  0.02359492]]],\n",
            "\n",
            "\n",
            "       [[[ 0.05225096, -0.05879962,  0.11966659,  0.00774712,\n",
            "           0.07055123,  0.01642939,  0.05750341,  0.0750325 ,\n",
            "          -0.10744741,  0.11615469,  0.13866219,  0.11038404,\n",
            "           0.0359825 , -0.10903082, -0.12088221,  0.03789841,\n",
            "           0.13775453,  0.09961391,  0.0136002 , -0.07999773,\n",
            "           0.13731256,  0.08351949, -0.0116749 , -0.10181004,\n",
            "          -0.12035938,  0.09674573,  0.0001466 , -0.08764923,\n",
            "          -0.09862498, -0.07725279,  0.05168913,  0.11275025]],\n",
            "\n",
            "        [[-0.07561754, -0.08715919,  0.02508552,  0.05854056,\n",
            "           0.09692041,  0.007426  ,  0.05874455,  0.08897518,\n",
            "           0.12750174, -0.09507053, -0.09317921, -0.09332638,\n",
            "          -0.06998758, -0.13489379,  0.07654124,  0.10792783,\n",
            "          -0.07852401,  0.03056334,  0.04181191,  0.05449162,\n",
            "           0.13114846,  0.05646734,  0.0380174 ,  0.06957423,\n",
            "          -0.09343331, -0.03298803, -0.08778252,  0.04629327,\n",
            "          -0.12896705, -0.07663902, -0.04621083,  0.10904449]],\n",
            "\n",
            "        [[-0.04489726,  0.10894865, -0.11992188,  0.03276087,\n",
            "          -0.14142257,  0.06942527,  0.0279998 , -0.06014488,\n",
            "          -0.05182869,  0.02276113, -0.05659043,  0.09409757,\n",
            "          -0.0989057 ,  0.05614639, -0.01647812,  0.12519833,\n",
            "           0.13628873,  0.06759049, -0.0575702 ,  0.02652103,\n",
            "          -0.037733  , -0.11582991,  0.07020293, -0.03616738,\n",
            "          -0.01722006,  0.04771883,  0.11619848,  0.0836523 ,\n",
            "          -0.07211599, -0.11936621, -0.02103952, -0.09541159]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-2.81682413e-04, -7.21110264e-05, -3.01673135e-04, -1.10693160e-04,\n",
            "       -5.00292983e-04, -3.85067135e-04, -9.27336398e-04,  8.05115269e-05,\n",
            "       -4.89284052e-04, -1.19290664e-03,  1.61736249e-03, -2.98025552e-05,\n",
            "       -3.90899542e-04, -2.10118655e-04, -8.01205984e-04, -2.15531269e-04,\n",
            "       -1.11951056e-04, -1.10915466e-03, -1.78143790e-04, -4.18879790e-05,\n",
            "        1.49807718e-04, -7.68826110e-04, -5.81865024e-04, -8.08339464e-05,\n",
            "        1.46706880e-03, -7.65910838e-04, -6.43089530e-04,  7.08777807e-05,\n",
            "        1.85939105e-04,  5.12222759e-05,  2.18396890e-04,  1.26630301e-03],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[ 0.00845978, -0.00865134, -0.00566474, ..., -0.00438007,\n",
            "         0.00658163, -0.00722924],\n",
            "       [ 0.00136422, -0.01174688,  0.01400097, ..., -0.01125234,\n",
            "        -0.00972674, -0.01542844],\n",
            "       [-0.01454264, -0.01362271,  0.00636617, ..., -0.00159043,\n",
            "         0.0027952 ,  0.00292491],\n",
            "       ...,\n",
            "       [-0.00097108,  0.0001121 , -0.00153406, ...,  0.00903908,\n",
            "         0.00343276, -0.01294877],\n",
            "       [ 0.01199624,  0.01582701,  0.00014881, ...,  0.00148155,\n",
            "        -0.01060943,  0.0161575 ],\n",
            "       [ 0.010754  ,  0.00970866,  0.0145041 , ...,  0.00696563,\n",
            "        -0.00099535,  0.00474609]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([ 1.2118157e-03, -2.1875706e-03, -1.4567826e-03, -2.5152425e-05,\n",
            "        1.2461186e-04,  2.8544308e-03,  2.6823380e-03,  1.8536171e-03,\n",
            "        2.7248534e-04,  2.4999660e-03,  3.0535521e-06, -2.1862919e-03,\n",
            "        8.6711181e-05,  4.8354082e-04,  2.7584170e-03,  2.3660699e-03,\n",
            "        2.8620861e-03,  3.7114424e-04, -1.2898770e-03,  2.6173724e-03,\n",
            "        2.6952892e-03, -1.4527317e-04,  1.8328821e-03,  2.7926506e-03,\n",
            "       -2.1875184e-03,  6.2623607e-05,  2.4987321e-04, -2.1875973e-03,\n",
            "       -1.0875631e-03, -2.1262362e-03, -2.1863547e-03,  2.8200017e-04,\n",
            "       -1.8379600e-03, -7.4024266e-04, -1.7410457e-03,  2.8902686e-03,\n",
            "        8.7252021e-04, -1.6810596e-03,  2.1800946e-03,  2.5182515e-03,\n",
            "        2.4192382e-04,  1.2005829e-03,  7.6104386e-04,  2.5212723e-03,\n",
            "        2.4316511e-03, -1.9554212e-03,  2.6446765e-03, -2.7065523e-04,\n",
            "       -2.1481579e-03,  2.9820323e-03, -1.0271454e-03, -2.1791412e-03,\n",
            "       -1.6013556e-03, -1.7402582e-03, -2.1864881e-03,  1.5802670e-04,\n",
            "       -1.2703948e-03,  3.3219732e-04, -8.3217584e-04,  2.2895890e-04,\n",
            "        2.8667161e-03, -5.0732098e-04, -2.1869030e-03,  3.0399577e-04,\n",
            "        2.6870701e-03, -1.6004747e-03,  6.6436136e-05, -4.4584731e-04,\n",
            "        2.1607394e-04,  2.4020653e-03,  1.8565357e-04,  2.6336128e-03,\n",
            "        1.6015237e-03,  2.8195647e-03,  4.7516987e-06,  4.2668905e-04,\n",
            "        5.9938611e-04,  2.8987130e-04, -2.1105341e-03, -1.1315481e-03,\n",
            "       -8.8217043e-05,  3.0414521e-04,  2.6117787e-03,  2.2424164e-03,\n",
            "        6.6101324e-04,  1.5183506e-03, -1.4038556e-04, -2.1876309e-03,\n",
            "        2.2805501e-03, -3.5254954e-04, -6.2428688e-04, -2.1665720e-03,\n",
            "        1.5361314e-03,  2.6150094e-03,  4.9342850e-04, -6.9679366e-04,\n",
            "        2.6503415e-03,  2.7669601e-03, -2.1878192e-03, -2.1879522e-03,\n",
            "       -2.1100256e-03, -2.1597513e-03,  5.3545641e-04, -7.3202449e-04,\n",
            "        1.2883004e-03, -2.2140928e-03,  7.4701675e-05, -1.0766684e-03,\n",
            "        2.7983435e-03,  1.1006529e-04, -2.5684340e-04, -2.1877419e-03,\n",
            "        2.7164521e-03,  4.7489678e-04,  2.3161178e-05, -2.1351720e-03,\n",
            "       -4.8986654e-04, -2.1873750e-03,  2.3477380e-03, -1.4493601e-04,\n",
            "        1.3214477e-03,  2.6514626e-03, -2.1667590e-03,  7.6030998e-04,\n",
            "       -2.1861547e-03, -7.2833078e-05,  4.2408654e-05, -4.0940451e-04],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[ 0.15684868,  0.14479813,  0.11395164, ...,  0.16948797,\n",
            "         0.13275982, -0.05539412],\n",
            "       [-0.16505861,  0.00919624,  0.05415145, ..., -0.18459748,\n",
            "         0.0368015 , -0.05050215],\n",
            "       [-0.02001027,  0.1103781 , -0.05443491, ..., -0.13081108,\n",
            "        -0.06188895, -0.1624332 ],\n",
            "       ...,\n",
            "       [ 0.16802728, -0.09108832,  0.02608429, ..., -0.08863258,\n",
            "         0.09269138,  0.04625659],\n",
            "       [ 0.06965654,  0.02659831,  0.16838671, ..., -0.12307877,\n",
            "         0.08616572, -0.16384049],\n",
            "       [-0.08557881, -0.07744592,  0.19633031, ...,  0.12099308,\n",
            "         0.16367774,  0.02716499]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([ 0.0003399 ,  0.00267311, -0.00274469, -0.00030728, -0.00169268,\n",
            "       -0.00134299,  0.00270965,  0.00256138, -0.00253515, -0.00076902],\n",
            "      dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MclZYfOldN"
      },
      "source": [
        "再テストの実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jAmhPk_tOldN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f8daf5-2392-40ae-965e-c7a06ef3c8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Test Loss: 1.1411813497543335, Test Accuracy: 73.86000061035156\n",
            "Epoch 2, Test Loss: 1.1411813497543335, Test Accuracy: 73.86000061035156\n",
            "Epoch 3, Test Loss: 1.1411813497543335, Test Accuracy: 73.86000061035156\n",
            "Epoch 4, Test Loss: 1.1411813497543335, Test Accuracy: 73.86000061035156\n",
            "Epoch 5, Test Loss: 1.1411813497543335, Test Accuracy: 73.86000061035156\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQmyQyMYKM4P"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('pythonenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d1685d247089585e01bacc0e11595c4779ea690fa157e920ca16120e3c1da301"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}