{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKIYAMA-Keito/Colab-repo/blob/main/AWP_nondef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d1Z8uIInOldG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKEv8KiMOldH"
      },
      "source": [
        "Step1 Tensorflowチュートリアル4から引用"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "version2\n"
      ],
      "metadata": {
        "id": "Yk9ofpRIRw2k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVrpxk0rOldI"
      },
      "source": [
        "データセットを読み込んで正規化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QobaZNJyOldJ"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "random_index_train = np.array(range(len(x_train)))\n",
        "np.random.shuffle(random_index_train)\n",
        "x_train = x_train[random_index_train][:1000]\n",
        "y_train = y_train[random_index_train][:1000]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test/255.0\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNcHvWE9OldJ"
      },
      "source": [
        "データセットをシャッフルしてバッチ化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wg2lQwV_OldJ"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)\n",
        ").batch(1000)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_test, y_test)\n",
        ").batch(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQHK9sMOldK"
      },
      "source": [
        "CNNモデルを定義しインスタンスを取り出す．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1-UIMbDyOldK"
      },
      "outputs": [],
      "source": [
        "class CNNModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32, 3, activation = \"relu\")\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation = \"relu\")\n",
        "        self.d2 = Dense(10)\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return x\n",
        "\n",
        "model = CNNModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R46fxEjOOldK"
      },
      "source": [
        "損失関数とoptmizerを選択する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9pzC_gytOldL"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph_DSqV9OldL"
      },
      "source": [
        "損失関数とoptimizerの尺度評価のための関数を導入する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MipedjyLOldL"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD6sZQRdOldL"
      },
      "source": [
        "モデルを訓練するための関数train_stepを定義する．\n",
        "予測値と正解ラベルの間の損失関数の勾配を最適化する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KCmbB-cnOldL"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training = True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdL3GJY2OldM"
      },
      "source": [
        "モデルをテストするための関数test_stepを定義する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IsRpIQFEOldM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images, training = False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    \n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D-PUsW-OldM"
      },
      "source": [
        "学習を実行してテストし，結果を出力する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJEwX2bUOldM",
        "outputId": "34d6186b-6d62-47dd-c7e2-00a38ece7ae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.3125832080841064, Accuracy: 13.09999942779541, Test Loss: 1.9220012426376343, Test Accuracy: 59.60000228881836\n",
            "Epoch 2, Loss: 1.895452618598938, Accuracy: 63.30000305175781, Test Loss: 1.4931464195251465, Test Accuracy: 71.97000122070312\n",
            "Epoch 3, Loss: 1.4492336511611938, Accuracy: 75.19999694824219, Test Loss: 1.154617190361023, Test Accuracy: 79.6500015258789\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "    \n",
        "    for train_images, train_labels in train_ds:\n",
        "        train_step(train_images, train_labels)\n",
        "    \n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Loss: {train_loss.result()}, '\n",
        "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTaFZYwFOldM"
      },
      "source": [
        "AWPのアルゴリズムを記述する．\n",
        "まず，学習済みのmodelから重みを取り出してvを加えて再設定する．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()\n",
        "ordinary_weights = weights\n",
        "v_array = []\n",
        "for w in weights:\n",
        "  v = 0.02 * np.random.rand() - 0.01\n",
        "  v_array.append(tf.fill(w.shape, v))"
      ],
      "metadata": {
        "id": "XRSISCKw7GT9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKvxUYsOldM"
      },
      "source": [
        "Step2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "    weights = model.get_weights()\n",
        "    new_weights = []\n",
        "    for w, v in zip(weights, additive_weights):\n",
        "      new_weights.append(w + v)\n",
        "    model.set_weights(new_weights)\n",
        "\n",
        "    adversarial_image_list = []\n",
        "    # eps1 = 1\n",
        "    # eta1 = 0.1\n",
        "    for (images, labels) in dataset:\n",
        "      for (image, label) in zip(images, labels):\n",
        "        image = tf.Variable([image])\n",
        "\n",
        "        initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        image_dashed = tf.add(image, initial_noise)\n",
        "\n",
        "        # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "        # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "        # image_dashed_list = []\n",
        "        # for image_0 in image:\n",
        "        #   for image_h in image_0:\n",
        "        #     for image_v in image_h:\n",
        "        #       for image_pixel in image_v:\n",
        "        #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "        #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "        # image_dashed_list.append(image_pixel_dashed)\n",
        "        # # image_dashed = np.array(image_dashed_list)\n",
        "        # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "        # print(image_dashed.numpy())\n",
        "\n",
        "        for j in range(5):\n",
        "          with tf.GradientTape() as tape:\n",
        "            tape.watch(image_dashed)\n",
        "            prediction = model(image_dashed, training = True)\n",
        "            loss = loss_object(label, prediction)\n",
        "          gradients = tape.gradient(loss, image_dashed)\n",
        "          image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "          difference = tf.subtract(image_med, image)\n",
        "          if tf.norm(difference) <= eps1:\n",
        "            image_dashed = image_med \n",
        "          else:\n",
        "            image_dashed = difference\n",
        "            image_dashed = tf.multiply(image_dashed, eps1)\n",
        "            image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "            image_dashed = tf.add(image_dashed, image)\n",
        "        adversarial_image_list.append(image_dashed[0])\n",
        "        adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "    return adversarial_image"
      ],
      "metadata": {
        "id": "V3j-1XQM1lMS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # def adversary(dataset, additive_weights, eps1 = 1, eta1 = 0.1):\n",
        "# weights = model.get_weights()\n",
        "# new_weights = []\n",
        "# for w, v in zip(weights, v_array):\n",
        "#   new_weights.append(w + v)\n",
        "# model.set_weights(new_weights)\n",
        "\n",
        "# adversarial_image_list = []\n",
        "# eps1 = 1\n",
        "# eta1 = 0.1\n",
        "# for (images, labels) in train_ds:\n",
        "#   for (image, label) in zip(images, labels):\n",
        "#     image = tf.Variable([image])\n",
        "\n",
        "#     initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     image_dashed = tf.add(image, initial_noise)\n",
        "#     # print(image)\n",
        "#     # print(image_dashed)\n",
        "\n",
        "#     # この書き方でも，initial_noiseが一様に入ってしまっている．\n",
        "#     # tf.Variableで1次元追加しているから，より内側のループを作らないといけないよ\n",
        "#     # image_dashed_list = []\n",
        "#     # for image_0 in image:\n",
        "#     #   for image_h in image_0:\n",
        "#     #     for image_v in image_h:\n",
        "#     #       for image_pixel in image_v:\n",
        "#     #         initial_noise = 2 * eps1 * np.random.rand() - eps1\n",
        "#     #         image_pixel_dashed = tf.add(image_pixel, initial_noise)\n",
        "#     # image_dashed_list.append(image_pixel_dashed)\n",
        "#     # # image_dashed = np.array(image_dashed_list)\n",
        "#     # image_dashed = tf.convert_to_tensor(image_dashed_list)\n",
        "#     # print(image_dashed.numpy())\n",
        "\n",
        "#     for j in range(1):\n",
        "#       with tf.GradientTape() as tape:\n",
        "#         tape.watch(image_dashed)\n",
        "#         prediction = model(image_dashed, training = False)\n",
        "#         # print(prediction)\n",
        "#         loss = loss_object(label, prediction)\n",
        "#       gradients = tape.gradient(loss, image_dashed)\n",
        "#       image_med = tf.add(image_dashed, tf.multiply(eta1, gradients))\n",
        "#       difference = tf.subtract(image_med, image)\n",
        "#       if tf.norm(difference) <= eps1:\n",
        "#         image_dashed = image_med \n",
        "#       else:\n",
        "#         image_dashed = difference\n",
        "#         image_dashed = tf.multiply(image_dashed, eps1)\n",
        "#         image_dashed = tf.divide(image_dashed, tf.norm(difference))\n",
        "#         image_dashed = tf.add(image_dashed, image)\n",
        "#     adversarial_image_list.append(image_dashed[0])\n",
        "#     adversarial_image = np.array(adversarial_image_list)\n",
        "\n",
        "# print(adversarial_image[0] - x_train[0])\n",
        "\n",
        "# # print(adversarial_image)"
      ],
      "metadata": {
        "id": "2HGcWwIkljvE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adversarial = adversary(train_ds, v_array)"
      ],
      "metadata": {
        "id": "LzKpbHhf5dup"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Mpzb3j_c8kKF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(10):\n",
        "plt.imshow(np.squeeze(x_adversarial[0] - x_train[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "aMZJZZYgA04d",
        "outputId": "8585c053-0746-4e0b-c7de-8b2c28b5d218"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.squeeze(x_adversarial[0]))\n",
        "plt.show()\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6uaLXa-goe2o",
        "outputId": "71f3b8b1-f670-4525-e228-43a6b67c65c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "# for i in range(10):\n",
        "#   plt.imshow(np.squeeze(x_adversarial[i]))\n",
        "#   plt.show()\n",
        "#   print(y_train[i])"
      ],
      "metadata": {
        "id": "8C5mNp328y8q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxll_dsBOldN"
      },
      "source": [
        "Step3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_adversarial, y_train)\n",
        ").batch(100)"
      ],
      "metadata": {
        "id": "Cjf3frQs4Io4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(dataset, batch_size = 100):\n",
        "  batch_size = 100\n",
        "  loss_sum = 0.0\n",
        "  for (images, labels) in adversarial_ds:\n",
        "    predictions = model(images, training = True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "    loss_sum_batch = loss * batch_size\n",
        "    loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "  average_loss = tf.divide(loss_sum, 1000)\n",
        "  return average_loss"
      ],
      "metadata": {
        "id": "ozxGyYUn3KGZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 100\n",
        "# loss_sum = 0.0\n",
        "# for (images, labels) in adversarial_ds:\n",
        "#   predictions = model(images, training = True)\n",
        "#   loss = loss_object(labels, predictions)\n",
        "#   loss_sum_batch = loss * batch_size\n",
        "#   loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "# average_loss = tf.divide(loss_sum, 1000)"
      ],
      "metadata": {
        "id": "rD2V2J5I5E1E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_loss(dataset, batch_size = 100, additive_noise = v_array):\n",
        "#   # batch_size = 100\n",
        "#   loss_sum = 0.0\n",
        "#   for (images, labels) in dataset:\n",
        "#     predictions = model(images, training = True)\n",
        "#     loss = loss_object(labels, predictions)\n",
        "#     loss_sum_batch = loss * batch_size\n",
        "#     loss_sum = tf.add(loss_sum_batch, loss_sum)\n",
        "#   average_loss = tf.divide(loss_sum, 1000)\n",
        "#   return average_loss"
      ],
      "metadata": {
        "id": "H1C7Lp-g3JzR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZ9Ze5LOldN"
      },
      "source": [
        "Step4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_flat = np.ndarray([])\n",
        "for w in ordinary_weights:\n",
        "  w_reshape = tf.reshape(w, [-1])\n",
        "  print(w_reshape.shape)\n",
        "  w_flat = np.hstack([w_flat, w_reshape])\n",
        "w_fro = np.linalg.norm(w_flat)\n",
        "print(w_fro)\n",
        "  # w_fro = tf.add(w_fro, np.linalg.norm(w_reshape, ord=2))\n",
        "# w_fro = tf.sqrt(w_fro)"
      ],
      "metadata": {
        "id": "BD3YeKDISlsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fc86be-365d-4a8b-96e8-4b2ca42a4142"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288,)\n",
            "(32,)\n",
            "(2768896,)\n",
            "(128,)\n",
            "(1280,)\n",
            "(10,)\n",
            "16.91391410434028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.rcsetup import validate_axisbelow\n",
        "eps2 = 1\n",
        "eta2 = 0.1\n",
        "batch_size = 100\n",
        "\n",
        "v_updated = v_array\n",
        "# vの初期値を，step2で固定したvに設定する．\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  # 重みをw + (現在の)vに設定する　　ここから\n",
        "  current_weights = []\n",
        "  for layer_weights, v in zip(ordinary_weights, v_updated):\n",
        "    current_layer_weight = tf.add(layer_weights, v)\n",
        "    current_weights.append(current_layer_weight)\n",
        "  model.set_weights(current_weights)\n",
        "  # 重みをw + (現在の)vに設定する　　ここまで\n",
        "\n",
        "  # gradientの計算　　ここから\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = calculate_loss(adversarial_ds)\n",
        "    # print(loss)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  print(gradients)\n",
        "  #　計算できているし，悪い値ではない．\n",
        "  # gradientの計算　　ここまで\n",
        "\n",
        "  # gradientのノルムの計算　　ここから\n",
        "  gradients_flat = np.ndarray([])\n",
        "  for g in gradients:\n",
        "    g_reshape = tf.reshape(g, [-1])\n",
        "    gradients_flat = np.hstack([gradients_flat, g_reshape])\n",
        "  gradients_norm = np.linalg.norm(gradients_flat)\n",
        "  print(gradients_flat)\n",
        "  print(gradients_norm)\n",
        "  # ループを経るごとに値が大きくなり過ぎている？\n",
        "  # gradientのノルムの計算　　ここまで\n",
        "\n",
        "  # 勾配降下の実行　　ここから\n",
        "  v_difference = []\n",
        "  for g, v in zip(gradients, v_updated):\n",
        "    g = tf.divide(g, gradients_norm)\n",
        "    g = tf.multiply(g, w_fro)\n",
        "    g = tf.multiply(eta2, g)\n",
        "    v_med = tf.add(v, g)\n",
        "  # 勾配降下の実行　　ここまで\n",
        "\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここから\n",
        "    v_difference.append(v_med)\n",
        "  v_difference_flat = np.ndarray([])\n",
        "  for v_flat in v_difference:\n",
        "    v_flat_reshape = tf.reshape(v_flat, [-1])\n",
        "    # print(g_reshape.shape)\n",
        "    v_difference_flat = np.hstack([v_difference_flat, v_flat_reshape])\n",
        "  v_difference_norm = np.linalg.norm(v_difference_flat)\n",
        "  # (現在の)vと(元の重み)wの差分と，　そのノルムを計算　　ここまで\n",
        "\n",
        "  # 射影の実行　　ここから\n",
        "  if v_difference_norm <= eps2:\n",
        "    v_hat = v_med \n",
        "  else:\n",
        "    v_hat = v_difference\n",
        "    for v_hat_med in v_hat:\n",
        "      v_hat_med = tf.multiply(v_hat_med, eps2)\n",
        "      v_hat_med = tf.divide(v_hat_med, v_difference_norm)\n",
        "  v_updated = v_hat\n",
        "  # print(v_updated)　計算できているし，悪い値ではない．\n",
        "  # 射影の実行　　ここまで"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhQbeCasjVRp",
        "outputId": "469c360e-4f0e-42e9-ee9e-3436f2c47fbf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.01388858, -0.12425757, -0.09768622, -0.09131607,\n",
            "          -0.01259538, -0.05310222, -0.09750977, -0.13820317,\n",
            "          -0.05514771, -0.01126109, -0.10054965, -0.04824799,\n",
            "          -0.07919753, -0.03971104, -0.07089454, -0.01913343,\n",
            "          -0.14198823, -0.13637449, -0.07845011, -0.04799979,\n",
            "          -0.09163976, -0.07823772, -0.02084053, -0.07877657,\n",
            "          -0.01267855, -0.01088417, -0.13894099, -0.0751406 ,\n",
            "          -0.14324388, -0.01548722, -0.01443853, -0.0492127 ]],\n",
            "\n",
            "        [[-0.00496828, -0.14038694, -0.07870398, -0.1188408 ,\n",
            "          -0.02811035, -0.07811373, -0.12567556, -0.1177846 ,\n",
            "          -0.0744113 , -0.01118572, -0.10557625, -0.02349814,\n",
            "          -0.04338102, -0.05174763, -0.04687183, -0.00342343,\n",
            "          -0.14068837, -0.1508141 , -0.09424871, -0.02823608,\n",
            "          -0.08849756, -0.04115797, -0.01657786, -0.04456184,\n",
            "          -0.0170893 , -0.00401611, -0.13802695, -0.05893567,\n",
            "          -0.14758034, -0.03761347, -0.01828054, -0.05099965]],\n",
            "\n",
            "        [[-0.00290513, -0.13392599, -0.06032786, -0.12869287,\n",
            "          -0.04298506, -0.09339621, -0.13352875, -0.08129611,\n",
            "          -0.08117042, -0.02323151, -0.10248003, -0.01128089,\n",
            "          -0.00719425, -0.06248397, -0.04047998, -0.00165656,\n",
            "          -0.11343953, -0.14270218, -0.10636632, -0.0094653 ,\n",
            "          -0.06693082, -0.00572634, -0.02296993, -0.01524405,\n",
            "          -0.03349828, -0.00362936, -0.10917486, -0.05108963,\n",
            "          -0.13554223, -0.06476906, -0.02141825, -0.04566181]]],\n",
            "\n",
            "\n",
            "       [[[-0.04301494, -0.14160334, -0.09699634, -0.12334205,\n",
            "          -0.04675391, -0.03825357, -0.10831924, -0.1324384 ,\n",
            "          -0.02335142, -0.01649965, -0.10860871, -0.06048354,\n",
            "          -0.08870869, -0.04249987, -0.03457183, -0.00663986,\n",
            "          -0.14474574, -0.14801264, -0.09957357, -0.07587673,\n",
            "          -0.12292315, -0.09549178, -0.05486225, -0.08126771,\n",
            "          -0.01322733, -0.00466687, -0.12806015, -0.03259349,\n",
            "          -0.14687797, -0.02017055, -0.00285466, -0.02214009]],\n",
            "\n",
            "        [[-0.0303751 , -0.15346414, -0.09061366, -0.14947534,\n",
            "          -0.06084286, -0.05098389, -0.13661197, -0.10662769,\n",
            "          -0.03964065, -0.0254143 , -0.11994909, -0.02669339,\n",
            "          -0.0486543 , -0.04743408, -0.01487789, -0.00131195,\n",
            "          -0.14393127, -0.15786418, -0.10942402, -0.05686726,\n",
            "          -0.11950598, -0.05785184, -0.05908308, -0.04101034,\n",
            "          -0.01440748, -0.00253955, -0.11431812, -0.01893522,\n",
            "          -0.14750062, -0.05068465, -0.00212289, -0.02005764]],\n",
            "\n",
            "        [[-0.02271624, -0.1415057 , -0.08497315, -0.1515665 ,\n",
            "          -0.06316159, -0.05800207, -0.13869323, -0.0716099 ,\n",
            "          -0.05192266, -0.05158119, -0.12003331, -0.01173516,\n",
            "          -0.01224346, -0.05084484, -0.02558942, -0.00099135,\n",
            "          -0.11651352, -0.14441825, -0.10919752, -0.03597443,\n",
            "          -0.09364411, -0.02582198, -0.06632727, -0.01383238,\n",
            "          -0.02558054, -0.00511939, -0.08104983, -0.01518748,\n",
            "          -0.13174012, -0.08007344, -0.00315236, -0.01798764]]],\n",
            "\n",
            "\n",
            "       [[[-0.06954014, -0.1273928 , -0.07990441, -0.12615925,\n",
            "          -0.06774414, -0.01709174, -0.09268397, -0.0919404 ,\n",
            "          -0.0014888 , -0.03791539, -0.08708479, -0.0721293 ,\n",
            "          -0.08234421, -0.02038205, -0.00975024, -0.00303795,\n",
            "          -0.11714017, -0.13360487, -0.10362532, -0.09692492,\n",
            "          -0.13429269, -0.10118486, -0.08513829, -0.07695433,\n",
            "          -0.01354985, -0.00141055, -0.09497571, -0.00871467,\n",
            "          -0.11971315, -0.04058956, -0.00162882, -0.0135957 ]],\n",
            "\n",
            "        [[-0.05465464, -0.13319714, -0.09131642, -0.14257894,\n",
            "          -0.06721383, -0.0211207 , -0.11092531, -0.07180766,\n",
            "          -0.01531263, -0.05765144, -0.10055496, -0.03663507,\n",
            "          -0.04901407, -0.01764066, -0.00268123, -0.00171115,\n",
            "          -0.11575493, -0.1388347 , -0.10370201, -0.08298957,\n",
            "          -0.13265395, -0.07578502, -0.09843917, -0.03956813,\n",
            "          -0.0132423 , -0.00458327, -0.07627507, -0.00437997,\n",
            "          -0.11793303, -0.07476932, -0.00187002, -0.01433106]],\n",
            "\n",
            "        [[-0.04894704, -0.11690697, -0.09833169, -0.13640189,\n",
            "          -0.05278255, -0.02266316, -0.11080945, -0.04725483,\n",
            "          -0.02788493, -0.08504401, -0.10684792, -0.01827946,\n",
            "          -0.01801967, -0.01852343, -0.01766017, -0.00159951,\n",
            "          -0.09236689, -0.12158172, -0.08919826, -0.06168651,\n",
            "          -0.10569217, -0.05198382, -0.1022546 , -0.01742839,\n",
            "          -0.01820358, -0.01654891, -0.04513498, -0.00660361,\n",
            "          -0.10255139, -0.09979498, -0.00216272, -0.014122  ]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.02238053, -0.01287014,  0.01530565, -0.02625915, -0.09144488,\n",
            "       -0.10483028,  0.05056889, -0.02766525, -0.0931883 ,  0.20040461,\n",
            "        0.00261238,  0.2105124 , -0.1132642 ,  0.21363707, -0.10315465,\n",
            "        0.00348068,  0.06628667, -0.00778739,  0.03533152,  0.20722684,\n",
            "        0.04503525,  0.00334975, -0.13914855,  0.25823945,  0.33758187,\n",
            "        0.04903046, -0.00822105,  0.03770487, -0.07313178,  0.23179308,\n",
            "        0.02749575,  0.32157862], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-2.4788353e-06,  0.0000000e+00, -1.4229723e-06, ...,\n",
            "         0.0000000e+00, -1.2936761e-06, -1.7362808e-06],\n",
            "       [-4.8688384e-05,  0.0000000e+00, -1.4880564e-04, ...,\n",
            "        -4.1447597e-06, -1.2378559e-04, -1.9328325e-04],\n",
            "       [-2.5322937e-05,  0.0000000e+00, -1.7389442e-05, ...,\n",
            "        -7.9863833e-07, -3.1896881e-05, -2.9225914e-05],\n",
            "       ...,\n",
            "       [-1.0446075e-05,  0.0000000e+00, -1.4274645e-05, ...,\n",
            "        -3.2884611e-07, -7.3886140e-06, -2.0407628e-05],\n",
            "       [-5.4840206e-05,  0.0000000e+00, -6.8434987e-05, ...,\n",
            "        -8.9788966e-07, -2.9933013e-05, -7.7459357e-05],\n",
            "       [-1.2835642e-04,  0.0000000e+00, -1.6061030e-04, ...,\n",
            "        -2.1278199e-06, -8.2777209e-05, -1.9564267e-04]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-1.4024160e-02,  0.0000000e+00, -2.3018783e-02, -8.3541013e-03,\n",
            "       -2.3059504e-02, -1.4161015e-02, -2.0812890e-02, -1.3698844e-02,\n",
            "       -2.6634265e-02, -1.7172525e-04, -1.3460899e-02,  0.0000000e+00,\n",
            "        0.0000000e+00, -7.4166441e-03, -1.3673137e-02, -1.8621601e-02,\n",
            "        0.0000000e+00, -1.7421670e-02,  0.0000000e+00,  0.0000000e+00,\n",
            "       -2.5471363e-02, -3.6219884e-05, -2.0749163e-02, -4.2447518e-04,\n",
            "       -2.3231365e-02, -2.0052733e-02,  0.0000000e+00, -1.5893627e-02,\n",
            "       -1.3546741e-02, -1.7412446e-02, -1.6167488e-02, -4.2551138e-02,\n",
            "       -1.4045867e-03,  0.0000000e+00, -2.2755638e-02, -2.7726889e-02,\n",
            "       -4.8591546e-03,  0.0000000e+00, -2.8439775e-02, -3.5844773e-02,\n",
            "       -3.0092964e-02, -1.4672454e-02,  0.0000000e+00, -2.5208738e-02,\n",
            "       -4.4184014e-02, -8.7666442e-04, -2.5037993e-02, -2.2313045e-02,\n",
            "       -2.9246729e-02, -2.1532830e-02, -1.5063662e-02, -2.3063270e-02,\n",
            "        0.0000000e+00, -1.2393128e-04, -9.6370978e-03, -1.6810404e-02,\n",
            "       -2.1971928e-02, -1.5288329e-02,  0.0000000e+00,  0.0000000e+00,\n",
            "       -2.1113951e-02, -1.7722661e-02, -1.7547606e-02, -2.5802219e-02,\n",
            "       -1.9884311e-02,  2.7545488e-03, -3.3424839e-02, -1.7402139e-02,\n",
            "       -1.3903586e-02, -2.9648447e-02, -1.4306295e-02, -1.9943230e-02,\n",
            "       -1.1824966e-02, -2.5417205e-02, -2.4270924e-02, -1.2572075e-02,\n",
            "        0.0000000e+00, -2.2228174e-02, -2.4137080e-02, -1.8113755e-02,\n",
            "       -1.7813597e-02, -1.3234008e-02, -1.9674011e-02,  0.0000000e+00,\n",
            "       -1.1865057e-02, -1.6831096e-02, -1.7825939e-02, -1.4291048e-02,\n",
            "       -1.6392920e-02, -7.6710070e-03, -9.7955773e-03,  0.0000000e+00,\n",
            "       -2.2826349e-02, -1.1006283e-02, -1.1324703e-03, -2.2768250e-02,\n",
            "       -1.8046705e-02,  0.0000000e+00,  0.0000000e+00, -1.2739579e-02,\n",
            "       -2.3143357e-02, -2.1344643e-02, -2.6997864e-02, -3.0404627e-02,\n",
            "        1.4621357e-03, -1.3840814e-02, -6.3675065e-03,  0.0000000e+00,\n",
            "       -2.4945920e-02,  0.0000000e+00, -3.9504655e-03, -1.6458156e-02,\n",
            "        0.0000000e+00,  0.0000000e+00, -3.1190164e-02, -1.1052913e-02,\n",
            "       -3.0146528e-02,  8.1959562e-03, -8.8392003e-03, -1.9849762e-02,\n",
            "        0.0000000e+00,  0.0000000e+00, -2.4625776e-02, -1.1738152e-02,\n",
            "       -1.1755116e-03, -4.3572349e-04, -1.4884605e-02, -2.9088713e-02],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-3.24302912e-02,  1.79772209e-02,  9.14722215e-03, ...,\n",
            "         4.08759981e-04, -8.19335692e-03,  6.91023935e-03],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "       [ 1.04788004e-03,  3.19415820e-04, -1.24365445e-02, ...,\n",
            "         4.59560379e-03, -2.65278411e-03,  3.79255204e-03],\n",
            "       ...,\n",
            "       [ 2.28333738e-05,  1.31084034e-05,  3.25366746e-05, ...,\n",
            "         1.33503345e-05,  1.49489224e-05,  1.38878295e-05],\n",
            "       [-6.99304231e-03, -9.28177591e-03,  8.46929010e-03, ...,\n",
            "         5.85770886e-03, -6.43347623e-03,  3.93337850e-03],\n",
            "       [ 4.45908308e-03, -2.31112689e-02, -1.23170961e-04, ...,\n",
            "        -3.22381523e-03,  1.07282773e-03,  2.44987314e-03]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00566442, -0.03200153,  0.00367712,  0.01029505, -0.00308567,\n",
            "        0.02468734,  0.01090785, -0.00209158, -0.00108107, -0.00564308],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -1.38885817e-02 -1.24257572e-01 ... -2.09157844e-03\n",
            " -1.08107296e-03 -5.64308418e-03]\n",
            "1000.0022444785541\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.01391124, -0.12407479, -0.0977102 , -0.09092706,\n",
            "          -0.01247452, -0.05299342, -0.09758831, -0.13841529,\n",
            "          -0.05529357, -0.01127982, -0.10056219, -0.04830973,\n",
            "          -0.0799244 , -0.0376024 , -0.07060289, -0.01926999,\n",
            "          -0.14185037, -0.13603213, -0.07840464, -0.04872156,\n",
            "          -0.09165586, -0.07815953, -0.02096105, -0.07754312,\n",
            "          -0.01268489, -0.0109096 , -0.13889089, -0.07524525,\n",
            "          -0.14308642, -0.0150432 , -0.01452434, -0.049364  ]],\n",
            "\n",
            "        [[-0.004969  , -0.14011322, -0.07859828, -0.11840286,\n",
            "          -0.02804539, -0.07807018, -0.12581018, -0.11772265,\n",
            "          -0.0745224 , -0.01118734, -0.10564588, -0.02351193,\n",
            "          -0.04398295, -0.04959089, -0.04652436, -0.00343205,\n",
            "          -0.1405867 , -0.15044802, -0.09420119, -0.02901272,\n",
            "          -0.08852504, -0.0408642 , -0.01661702, -0.04317887,\n",
            "          -0.0172007 , -0.00405519, -0.13795713, -0.05903393,\n",
            "          -0.14745754, -0.03714598, -0.01837661, -0.05108397]],\n",
            "\n",
            "        [[-0.00281057, -0.13348672, -0.06001644, -0.12824209,\n",
            "          -0.04304279, -0.09347825, -0.13368462, -0.08111421,\n",
            "          -0.08111971, -0.02321187, -0.10256359, -0.01130111,\n",
            "          -0.00778048, -0.06040117, -0.04003625, -0.00165992,\n",
            "          -0.11327453, -0.14227313, -0.10640333, -0.01028087,\n",
            "          -0.06693249, -0.00527326, -0.02286819, -0.01380161,\n",
            "          -0.03376134, -0.00366273, -0.1090484 , -0.05118117,\n",
            "          -0.13542056, -0.0644663 , -0.0215258 , -0.04576745]]],\n",
            "\n",
            "\n",
            "       [[[-0.0431026 , -0.14137466, -0.09689495, -0.12302147,\n",
            "          -0.04671616, -0.03815042, -0.10833138, -0.13239735,\n",
            "          -0.02331634, -0.01650212, -0.10865016, -0.06063155,\n",
            "          -0.08940548, -0.0403263 , -0.03420379, -0.00670988,\n",
            "          -0.1446267 , -0.14779204, -0.09957869, -0.07664715,\n",
            "          -0.12303501, -0.09539845, -0.05508134, -0.07992016,\n",
            "          -0.01328065, -0.00466103, -0.12808406, -0.0326653 ,\n",
            "          -0.14668867, -0.01961255, -0.00290527, -0.0222958 ]],\n",
            "\n",
            "        [[-0.03034129, -0.15321794, -0.09044227, -0.14909638,\n",
            "          -0.06089745, -0.0509685 , -0.13668148, -0.10649537,\n",
            "          -0.03968078, -0.02534046, -0.12013078, -0.02676187,\n",
            "          -0.04917442, -0.04521701, -0.01448419, -0.00130945,\n",
            "          -0.14395827, -0.15753126, -0.1094137 , -0.05776884,\n",
            "          -0.11967538, -0.05760181, -0.05917579, -0.03957997,\n",
            "          -0.01451629, -0.00256263, -0.1141872 , -0.01893607,\n",
            "          -0.14739493, -0.05018666, -0.00218408, -0.02012049]],\n",
            "\n",
            "        [[-0.02257237, -0.14118192, -0.08476269, -0.15124503,\n",
            "          -0.0633407 , -0.05804604, -0.13888508, -0.07146348,\n",
            "          -0.05192213, -0.05148757, -0.12022748, -0.01177041,\n",
            "          -0.01274097, -0.04878452, -0.02530747, -0.00099544,\n",
            "          -0.11639856, -0.14403166, -0.10917673, -0.03688253,\n",
            "          -0.09380033, -0.02542835, -0.06629458, -0.01244489,\n",
            "          -0.02579873, -0.00515852, -0.08091287, -0.01516897,\n",
            "          -0.13159478, -0.07981183, -0.0032137 , -0.01802426]]],\n",
            "\n",
            "\n",
            "       [[[-0.06958666, -0.12711905, -0.07982569, -0.12581153,\n",
            "          -0.06775124, -0.01686605, -0.09245506, -0.09167771,\n",
            "          -0.00142884, -0.03788281, -0.08703586, -0.07241179,\n",
            "          -0.08283788, -0.01817274, -0.00941035, -0.00313859,\n",
            "          -0.11694651, -0.13340704, -0.10370311, -0.09772038,\n",
            "          -0.13441288, -0.1010778 , -0.08511569, -0.07562871,\n",
            "          -0.01359186, -0.00140906, -0.09513568, -0.00879488,\n",
            "          -0.11939782, -0.04000094, -0.00165346, -0.01364104]],\n",
            "\n",
            "        [[-0.05462874, -0.132876  , -0.09125514, -0.14223269,\n",
            "          -0.06730619, -0.02097197, -0.11083429, -0.07153153,\n",
            "          -0.01546018, -0.05756495, -0.10055485, -0.03685143,\n",
            "          -0.04944286, -0.01566135, -0.00245741, -0.00172193,\n",
            "          -0.11564492, -0.13856433, -0.10379479, -0.08391186,\n",
            "          -0.13284758, -0.07563786, -0.09861202, -0.03826258,\n",
            "          -0.01331758, -0.00463058, -0.07623064, -0.00441234,\n",
            "          -0.1176407 , -0.0742396 , -0.00190716, -0.01436659]],\n",
            "\n",
            "        [[-0.04884299, -0.11654422, -0.09831662, -0.13609706,\n",
            "          -0.0529284 , -0.02275433, -0.11083859, -0.04700973,\n",
            "          -0.02794696, -0.08496433, -0.10694034, -0.01836941,\n",
            "          -0.01842227, -0.01652032, -0.01748484, -0.0016055 ,\n",
            "          -0.09208918, -0.12129353, -0.08917636, -0.06264259,\n",
            "          -0.10591812, -0.05167716, -0.10231797, -0.01603677,\n",
            "          -0.01837239, -0.01661033, -0.04504772, -0.00660736,\n",
            "          -0.10230781, -0.09942874, -0.00220007, -0.01412139]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.02311045, -0.01091275,  0.016808  , -0.02427321, -0.09157853,\n",
            "       -0.10512782,  0.05150434, -0.02484462, -0.09296538,  0.2011503 ,\n",
            "        0.00390313,  0.21079756, -0.11624064,  0.15135361, -0.10924348,\n",
            "        0.00350969,  0.06806824, -0.00563679,  0.03583538,  0.18441762,\n",
            "        0.04569112,  0.00930515, -0.14120227,  0.21567647,  0.33874375,\n",
            "        0.04983427, -0.00750652,  0.03742957, -0.07156303,  0.2186181 ,\n",
            "        0.02815966,  0.32355076], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-2.3066493e-06,  0.0000000e+00, -1.3083430e-06, ...,\n",
            "         0.0000000e+00, -1.2248881e-06, -1.4269463e-06],\n",
            "       [-4.9007092e-05,  0.0000000e+00, -1.4866807e-04, ...,\n",
            "        -4.1250532e-06, -1.2181150e-04, -1.9291275e-04],\n",
            "       [-2.5368299e-05,  0.0000000e+00, -1.7246968e-05, ...,\n",
            "        -7.9386371e-07, -3.1480587e-05, -2.9095901e-05],\n",
            "       ...,\n",
            "       [-1.5045383e-05,  0.0000000e+00, -1.9819141e-05, ...,\n",
            "        -2.6538686e-07, -1.0153706e-05, -2.6751912e-05],\n",
            "       [-5.5713164e-05,  0.0000000e+00, -6.9075446e-05, ...,\n",
            "        -6.3697041e-07, -3.0292311e-05, -7.6764976e-05],\n",
            "       [-1.3522459e-04,  0.0000000e+00, -1.6800960e-04, ...,\n",
            "        -1.5218227e-06, -8.6457752e-05, -2.0058284e-04]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-1.41281700e-02,  0.00000000e+00, -2.30882652e-02, -8.35441332e-03,\n",
            "       -2.31791176e-02, -1.42268827e-02, -2.10189112e-02, -1.34373065e-02,\n",
            "       -2.69531552e-02, -1.72674612e-04, -1.33435624e-02,  0.00000000e+00,\n",
            "        0.00000000e+00, -7.35668745e-03, -1.37488861e-02, -1.86972562e-02,\n",
            "        0.00000000e+00, -1.78275406e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.53099445e-02, -3.64918233e-05, -2.06813589e-02, -3.28056398e-04,\n",
            "       -2.31272895e-02, -2.03229617e-02,  0.00000000e+00, -1.60772167e-02,\n",
            "       -1.35449274e-02, -1.75539013e-02, -1.60277430e-02, -4.31904718e-02,\n",
            "       -1.29400077e-03,  0.00000000e+00, -2.26590708e-02, -2.76900195e-02,\n",
            "       -4.88120178e-03,  0.00000000e+00, -2.82998122e-02, -3.61615345e-02,\n",
            "       -3.05084046e-02, -1.47903552e-02,  0.00000000e+00, -2.54000146e-02,\n",
            "       -4.44769002e-02, -8.78225896e-04, -2.50326898e-02, -2.24558692e-02,\n",
            "       -2.92938836e-02, -2.15763748e-02, -1.52404401e-02, -2.32269838e-02,\n",
            "        0.00000000e+00, -1.24345854e-04, -9.85172577e-03, -1.68588627e-02,\n",
            "       -2.22550463e-02, -1.53380325e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.09929608e-02, -1.78916138e-02, -1.78445671e-02, -2.56292932e-02,\n",
            "       -1.99515373e-02,  2.78506847e-03, -3.33928280e-02, -1.75356232e-02,\n",
            "       -1.39830410e-02, -2.95873582e-02, -1.42197711e-02, -2.01416686e-02,\n",
            "       -1.19796591e-02, -2.55154520e-02, -2.42974292e-02, -1.24867894e-02,\n",
            "        0.00000000e+00, -2.22804304e-02, -2.42886692e-02, -1.81870088e-02,\n",
            "       -1.79537423e-02, -1.26738278e-02, -1.97084807e-02,  0.00000000e+00,\n",
            "       -1.18296631e-02, -1.69352535e-02, -1.77516490e-02, -1.43737458e-02,\n",
            "       -1.64883677e-02, -7.71407876e-03, -9.97484755e-03,  0.00000000e+00,\n",
            "       -2.26785820e-02, -1.11322980e-02, -1.14088284e-03, -2.29742285e-02,\n",
            "       -1.81132834e-02,  0.00000000e+00,  0.00000000e+00, -1.27345668e-02,\n",
            "       -2.31913961e-02, -2.17979513e-02, -2.73743495e-02, -3.03550586e-02,\n",
            "        1.45756430e-03, -1.34406313e-02, -6.38595223e-03,  0.00000000e+00,\n",
            "       -2.51179170e-02,  0.00000000e+00, -3.80813167e-03, -1.65787116e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -3.13259624e-02, -1.11324098e-02,\n",
            "       -3.01468372e-02,  8.18566978e-03, -8.96369666e-03, -1.98613442e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -2.45330222e-02, -1.19413286e-02,\n",
            "       -1.05450524e-03, -3.81823804e-04, -1.48136886e-02, -2.88336724e-02],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-3.2450698e-02,  1.7912719e-02,  9.1167269e-03, ...,\n",
            "         4.1282037e-04, -8.1787249e-03,  6.9535859e-03],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
            "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [ 1.0618607e-03,  3.3163017e-04, -1.2379106e-02, ...,\n",
            "         4.5388038e-03, -2.5822106e-03,  3.7787291e-03],\n",
            "       ...,\n",
            "       [ 2.2532735e-05,  1.3078631e-05,  3.2272827e-05, ...,\n",
            "         1.3255970e-05,  1.4824589e-05,  1.3750206e-05],\n",
            "       [-6.9686850e-03, -9.2062447e-03,  8.3896201e-03, ...,\n",
            "         5.8162166e-03, -6.3947993e-03,  3.9367182e-03],\n",
            "       [ 4.3908022e-03, -2.2914834e-02, -1.0846133e-04, ...,\n",
            "        -3.1804149e-03,  1.0927874e-03,  2.4414700e-03]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00586236, -0.03202077,  0.00359442,  0.01033334, -0.00290364,\n",
            "        0.02487663,  0.01091826, -0.0021544 , -0.0012145 , -0.00556699],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -1.39112398e-02 -1.24074787e-01 ... -2.15439755e-03\n",
            " -1.21449912e-03 -5.56698721e-03]\n",
            "1000.0022139800479\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.01404769, -0.12352772, -0.09808718, -0.09044789,\n",
            "          -0.01250956, -0.05298697, -0.09750095, -0.13840544,\n",
            "          -0.05561051, -0.01131591, -0.10082613, -0.0484672 ,\n",
            "          -0.08121818, -0.03702781, -0.07060324, -0.01928601,\n",
            "          -0.14172801, -0.13565479, -0.07854242, -0.04939868,\n",
            "          -0.09172484, -0.07828386, -0.02114029, -0.07746525,\n",
            "          -0.01276657, -0.01088603, -0.13907543, -0.0753143 ,\n",
            "          -0.14280704, -0.01495408, -0.01451381, -0.04947298]],\n",
            "\n",
            "        [[-0.0051408 , -0.13975722, -0.07876466, -0.11790416,\n",
            "          -0.02814696, -0.07818108, -0.12568632, -0.11752144,\n",
            "          -0.07498209, -0.01123262, -0.10590171, -0.02362005,\n",
            "          -0.04511844, -0.0490251 , -0.04656376, -0.00345836,\n",
            "          -0.14034963, -0.15013136, -0.09438439, -0.02968056,\n",
            "          -0.08847829, -0.04076254, -0.01685423, -0.04302379,\n",
            "          -0.01736241, -0.00405419, -0.13817048, -0.05903275,\n",
            "          -0.14722694, -0.0371329 , -0.01832983, -0.051275  ]],\n",
            "\n",
            "        [[-0.00293507, -0.1332882 , -0.05999335, -0.12770517,\n",
            "          -0.04329045, -0.09354591, -0.13357104, -0.08087498,\n",
            "          -0.08144902, -0.02327842, -0.10275899, -0.01136263,\n",
            "          -0.0088686 , -0.05980355, -0.04003616, -0.00166329,\n",
            "          -0.11301629, -0.1419441 , -0.10682577, -0.01103062,\n",
            "          -0.06681792, -0.00500575, -0.02305286, -0.01360858,\n",
            "          -0.03410364, -0.003666  , -0.1091672 , -0.0511663 ,\n",
            "          -0.13528635, -0.06452078, -0.02150165, -0.04606373]]],\n",
            "\n",
            "\n",
            "       [[[-0.04333657, -0.14081144, -0.09722447, -0.12257114,\n",
            "          -0.04679454, -0.03809737, -0.10828315, -0.1323539 ,\n",
            "          -0.02361189, -0.01658724, -0.10892373, -0.06088554,\n",
            "          -0.0906235 , -0.03962217, -0.03409367, -0.00672061,\n",
            "          -0.1444189 , -0.14736414, -0.09969917, -0.0773412 ,\n",
            "          -0.12324773, -0.09545159, -0.05540333, -0.07984054,\n",
            "          -0.01334147, -0.00461781, -0.12815088, -0.03269316,\n",
            "          -0.14639351, -0.01962033, -0.00292143, -0.02231365]],\n",
            "\n",
            "        [[-0.0305861 , -0.15287058, -0.09056785, -0.14865553,\n",
            "          -0.06112649, -0.05099947, -0.13659345, -0.10618871,\n",
            "          -0.04007713, -0.02543142, -0.12036552, -0.02691491,\n",
            "          -0.05038356, -0.04452495, -0.01436166, -0.00130256,\n",
            "          -0.14367247, -0.15725599, -0.10959017, -0.05854145,\n",
            "          -0.11974677, -0.05746174, -0.05956434, -0.03942367,\n",
            "          -0.01463407, -0.00254108, -0.11433189, -0.01889632,\n",
            "          -0.14718425, -0.05020406, -0.0021896 , -0.02021037]],\n",
            "\n",
            "        [[-0.02273314, -0.14099896, -0.08486614, -0.15081543,\n",
            "          -0.06360196, -0.05797576, -0.13870186, -0.07117617,\n",
            "          -0.05212176, -0.05162309, -0.12037147, -0.0118285 ,\n",
            "          -0.01385237, -0.04809336, -0.02525562, -0.00098878,\n",
            "          -0.11603269, -0.14386176, -0.10955967, -0.0377097 ,\n",
            "          -0.09385349, -0.02519163, -0.06663036, -0.01233236,\n",
            "          -0.02598654, -0.00517366, -0.08101624, -0.01512774,\n",
            "          -0.13142753, -0.07994463, -0.00322187, -0.01815723]]],\n",
            "\n",
            "\n",
            "       [[[-0.06988072, -0.12654655, -0.0799944 , -0.12532982,\n",
            "          -0.06780706, -0.01667044, -0.09238704, -0.09137248,\n",
            "          -0.00171562, -0.03803471, -0.08712366, -0.07268587,\n",
            "          -0.084114  , -0.01743621, -0.00933516, -0.00314295,\n",
            "          -0.11663415, -0.13292564, -0.10375018, -0.09856551,\n",
            "          -0.13469437, -0.10113128, -0.08527835, -0.07550616,\n",
            "          -0.01365032, -0.00140586, -0.09517156, -0.00885727,\n",
            "          -0.11911917, -0.04003102, -0.00164127, -0.01366078]],\n",
            "\n",
            "        [[-0.05489979, -0.13242626, -0.09135902, -0.14183545,\n",
            "          -0.06744175, -0.02086997, -0.11066821, -0.07120448,\n",
            "          -0.01584289, -0.05774737, -0.10062423, -0.03705229,\n",
            "          -0.05066207, -0.01508396, -0.00230058, -0.00172054,\n",
            "          -0.11525802, -0.13827899, -0.10392565, -0.0848069 ,\n",
            "          -0.13302128, -0.07559912, -0.09908125, -0.03811495,\n",
            "          -0.01340632, -0.00465373, -0.0763327 , -0.00441848,\n",
            "          -0.1174299 , -0.07424792, -0.0018933 , -0.01443189]],\n",
            "\n",
            "        [[-0.04905187, -0.11622899, -0.09844682, -0.13571234,\n",
            "          -0.05307777, -0.02274386, -0.11063789, -0.0466961 ,\n",
            "          -0.02810924, -0.08525008, -0.10696207, -0.01846583,\n",
            "          -0.01958027, -0.01591602, -0.01731184, -0.00160694,\n",
            "          -0.09167236, -0.12110187, -0.08935427, -0.06351943,\n",
            "          -0.10607219, -0.05153587, -0.10262382, -0.01584096,\n",
            "          -0.01845106, -0.01671318, -0.04498984, -0.00661023,\n",
            "          -0.10203782, -0.09964387, -0.00220628, -0.01419235]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.02285262, -0.00859126,  0.01719514, -0.02210622, -0.09183503,\n",
            "       -0.10544217,  0.05260143, -0.0221689 , -0.09339655,  0.20258686,\n",
            "        0.00443644,  0.21177863, -0.11940265,  0.13462707, -0.11140874,\n",
            "        0.00363457,  0.06948391, -0.00332041,  0.03632842,  0.16342932,\n",
            "        0.04592566,  0.01376142, -0.14199103,  0.21049984,  0.34118253,\n",
            "        0.04975858, -0.00701681,  0.0370849 , -0.07002306,  0.2163624 ,\n",
            "        0.02815238,  0.32591704], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-2.1219687e-06,  0.0000000e+00, -1.1800383e-06, ...,\n",
            "         0.0000000e+00, -1.2024444e-06, -1.2979398e-06],\n",
            "       [-4.9334809e-05,  0.0000000e+00, -1.4679279e-04, ...,\n",
            "        -4.1061571e-06, -1.2171462e-04, -1.8741083e-04],\n",
            "       [-2.5420224e-05,  0.0000000e+00, -1.6913553e-05, ...,\n",
            "        -7.8975506e-07, -3.1445939e-05, -2.8333914e-05],\n",
            "       ...,\n",
            "       [-1.9444415e-05,  0.0000000e+00, -2.5003412e-05, ...,\n",
            "        -3.1247791e-07, -1.3182227e-05, -3.2999884e-05],\n",
            "       [-5.6605848e-05,  0.0000000e+00, -6.9941147e-05, ...,\n",
            "        -6.4439547e-07, -3.1668213e-05, -7.7658697e-05],\n",
            "       [-1.4221040e-04,  0.0000000e+00, -1.7574310e-04, ...,\n",
            "        -1.5908586e-06, -9.2932620e-05, -2.0962849e-04]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-1.42324865e-02,  0.00000000e+00, -2.30519548e-02, -8.54616985e-03,\n",
            "       -2.33066939e-02, -1.42062446e-02, -2.10880470e-02, -1.33865783e-02,\n",
            "       -2.72508711e-02, -2.86355171e-05, -1.33755384e-02,  0.00000000e+00,\n",
            "        0.00000000e+00, -7.28102820e-03, -1.38240121e-02, -1.83776934e-02,\n",
            "        0.00000000e+00, -1.78467501e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.56516989e-02, -3.67606626e-05, -2.06593629e-02, -2.33737519e-04,\n",
            "       -2.33838614e-02, -2.03690156e-02,  0.00000000e+00, -1.61268450e-02,\n",
            "       -1.35821644e-02, -1.76492259e-02, -1.62900072e-02, -4.35448214e-02,\n",
            "       -1.29605818e-03,  0.00000000e+00, -2.26371698e-02, -2.74864379e-02,\n",
            "       -4.92234435e-03,  0.00000000e+00, -2.83336006e-02, -3.61736268e-02,\n",
            "       -3.03058196e-02, -1.47958091e-02,  0.00000000e+00, -2.56745107e-02,\n",
            "       -4.47053760e-02, -7.30201486e-04, -2.47580837e-02, -2.29704343e-02,\n",
            "       -2.93694511e-02, -2.15555429e-02, -1.52343577e-02, -2.32906081e-02,\n",
            "        0.00000000e+00, -1.24756756e-04, -9.93577112e-03, -1.71397571e-02,\n",
            "       -2.23828852e-02, -1.54728591e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.08016597e-02, -1.80684850e-02, -1.77668929e-02, -2.54543219e-02,\n",
            "       -2.01405063e-02,  2.81391339e-03, -3.32657471e-02, -1.78370494e-02,\n",
            "       -1.39607564e-02, -2.96370760e-02, -1.42778987e-02, -2.02171020e-02,\n",
            "       -1.21363215e-02, -2.56123208e-02, -2.44355872e-02, -1.24663152e-02,\n",
            "        0.00000000e+00, -2.22704262e-02, -2.44065505e-02, -1.84346400e-02,\n",
            "       -1.80402976e-02, -1.27323642e-02, -1.98016688e-02,  0.00000000e+00,\n",
            "       -1.20061580e-02, -1.69261191e-02, -1.78517569e-02, -1.44818863e-02,\n",
            "       -1.65818371e-02, -7.75653683e-03, -1.02057941e-02,  0.00000000e+00,\n",
            "       -2.26714611e-02, -1.12186894e-02, -1.14917650e-03, -2.30137259e-02,\n",
            "       -1.81370359e-02,  0.00000000e+00,  0.00000000e+00, -1.26272012e-02,\n",
            "       -2.31813695e-02, -2.17539631e-02, -2.72487402e-02, -3.01007461e-02,\n",
            "        1.45079056e-03, -1.36525761e-02, -6.40415493e-03,  0.00000000e+00,\n",
            "       -2.51355506e-02,  0.00000000e+00, -3.86012020e-03, -1.67090166e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -3.13058570e-02, -1.13320090e-02,\n",
            "       -3.05184238e-02,  8.17263685e-03, -8.87144916e-03, -2.00874954e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -2.45724097e-02, -1.21077187e-02,\n",
            "       -1.05734821e-03, -3.82441329e-04, -1.50544411e-02, -2.85554342e-02],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-3.2463476e-02,  1.7846912e-02,  9.0878010e-03, ...,\n",
            "         4.1661708e-04, -8.1630275e-03,  6.9959480e-03],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
            "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [ 1.0777939e-03,  3.4276757e-04, -1.2318293e-02, ...,\n",
            "         4.4825831e-03, -2.5117998e-03,  3.7626904e-03],\n",
            "       ...,\n",
            "       [ 2.2272781e-05,  1.3074009e-05,  3.2051819e-05, ...,\n",
            "         1.3196473e-05,  1.4737749e-05,  1.3660696e-05],\n",
            "       [-6.9442140e-03, -9.1295252e-03,  8.3097648e-03, ...,\n",
            "         5.7745916e-03, -6.3561406e-03,  3.9396519e-03],\n",
            "       [ 4.3242685e-03, -2.2720076e-02, -9.4765070e-05, ...,\n",
            "        -3.1374078e-03,  1.1100038e-03,  2.4332544e-03]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00605499, -0.03203584,  0.00351392,  0.01036735, -0.00272127,\n",
            "        0.02505679,  0.01092383, -0.00221587, -0.00134384, -0.00549006],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -1.40476879e-02 -1.23527721e-01 ... -2.21586903e-03\n",
            " -1.34384492e-03 -5.49006416e-03]\n",
            "1000.0022060606345\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.01425043, -0.12313064, -0.09844592, -0.0901359 ,\n",
            "          -0.01249823, -0.05287322, -0.09744863, -0.13871747,\n",
            "          -0.05598647, -0.01131893, -0.10073609, -0.04845461,\n",
            "          -0.08206742, -0.03677115, -0.07062425, -0.01927615,\n",
            "          -0.14167738, -0.135061  , -0.07841754, -0.04958157,\n",
            "          -0.09180003, -0.07869525, -0.02117345, -0.07752044,\n",
            "          -0.01282907, -0.01098822, -0.13931356, -0.07556306,\n",
            "          -0.14259964, -0.01497716, -0.01447692, -0.0494636 ]],\n",
            "\n",
            "        [[-0.00529918, -0.13940552, -0.07912702, -0.1176119 ,\n",
            "          -0.02835366, -0.07801697, -0.125556  , -0.11764531,\n",
            "          -0.07542457, -0.01126759, -0.10590096, -0.02364619,\n",
            "          -0.04595069, -0.04884052, -0.04659344, -0.00347312,\n",
            "          -0.14027531, -0.14956827, -0.09436871, -0.02997573,\n",
            "          -0.0886479 , -0.04097885, -0.01689587, -0.04302509,\n",
            "          -0.01746417, -0.00404074, -0.13824266, -0.05917318,\n",
            "          -0.14693128, -0.03712738, -0.01830418, -0.05139341]],\n",
            "\n",
            "        [[-0.00309424, -0.13296042, -0.06023481, -0.12737018,\n",
            "          -0.04354732, -0.09344839, -0.13331732, -0.0809291 ,\n",
            "          -0.0818579 , -0.02330885, -0.10285121, -0.01142341,\n",
            "          -0.00968932, -0.05959716, -0.04000404, -0.00167332,\n",
            "          -0.11280536, -0.14136963, -0.10697469, -0.01134119,\n",
            "          -0.06683941, -0.0051467 , -0.02302782, -0.01365625,\n",
            "          -0.03430514, -0.00365226, -0.10915794, -0.05120454,\n",
            "          -0.13491638, -0.06454563, -0.02149247, -0.04619534]]],\n",
            "\n",
            "\n",
            "       [[[-0.04360256, -0.14035697, -0.09741336, -0.12229666,\n",
            "          -0.04680749, -0.03794865, -0.10821422, -0.13271113,\n",
            "          -0.02383905, -0.01660273, -0.10889949, -0.06100553,\n",
            "          -0.09156284, -0.03933532, -0.03401838, -0.00672538,\n",
            "          -0.14437264, -0.14685833, -0.09962861, -0.07758114,\n",
            "          -0.1234713 , -0.09593746, -0.05546572, -0.0799559 ,\n",
            "          -0.01344007, -0.00471458, -0.12830028, -0.03285979,\n",
            "          -0.14626834, -0.01965181, -0.00290741, -0.02236735]],\n",
            "\n",
            "        [[-0.0307532 , -0.1525031 , -0.09091128, -0.14841715,\n",
            "          -0.06135169, -0.05077571, -0.13642895, -0.1062759 ,\n",
            "          -0.0403797 , -0.02544676, -0.12048517, -0.02699712,\n",
            "          -0.05133235, -0.04428162, -0.01427753, -0.00130451,\n",
            "          -0.14362785, -0.15686406, -0.10961513, -0.05887844,\n",
            "          -0.11984456, -0.05769294, -0.05960552, -0.03953071,\n",
            "          -0.01474743, -0.00254432, -0.11444531, -0.01891531,\n",
            "          -0.14692757, -0.05025361, -0.00218289, -0.02028695]],\n",
            "\n",
            "        [[-0.02280235, -0.14062762, -0.08510308, -0.15061678,\n",
            "          -0.06386666, -0.05782236, -0.13855201, -0.07122066,\n",
            "          -0.0523157 , -0.05165016, -0.12067169, -0.01190907,\n",
            "          -0.01471875, -0.04791114, -0.02527679, -0.00099424,\n",
            "          -0.11579283, -0.14347158, -0.10980241, -0.03804091,\n",
            "          -0.09384306, -0.02538203, -0.06654436, -0.01242572,\n",
            "          -0.02613795, -0.00518814, -0.08101187, -0.01514499,\n",
            "          -0.13116428, -0.08003794, -0.00321848, -0.01822895]]],\n",
            "\n",
            "\n",
            "       [[[-0.07008039, -0.12612046, -0.08010539, -0.12513173,\n",
            "          -0.06799011, -0.01639453, -0.0921924 , -0.09159859,\n",
            "          -0.00181312, -0.03805993, -0.08705129, -0.0729192 ,\n",
            "          -0.08508706, -0.01705069, -0.00928792, -0.00318069,\n",
            "          -0.11649941, -0.13248715, -0.10377481, -0.0990091 ,\n",
            "          -0.13501032, -0.10151076, -0.08532548, -0.07565594,\n",
            "          -0.01372972, -0.001498  , -0.09531964, -0.00893493,\n",
            "          -0.11901224, -0.03999503, -0.00162875, -0.01372623]],\n",
            "\n",
            "        [[-0.0549748 , -0.1320011 , -0.09151029, -0.14166981,\n",
            "          -0.06766656, -0.02064141, -0.11059831, -0.07126436,\n",
            "          -0.01590462, -0.05790202, -0.10080989, -0.03728008,\n",
            "          -0.05168957, -0.01484498, -0.00222552, -0.00172726,\n",
            "          -0.11506216, -0.13798961, -0.10405079, -0.085284  ,\n",
            "          -0.13310444, -0.07583448, -0.09918618, -0.03816674,\n",
            "          -0.01350232, -0.00465515, -0.07645395, -0.00441844,\n",
            "          -0.11721727, -0.07428903, -0.00188967, -0.0145021 ]],\n",
            "\n",
            "        [[-0.04902481, -0.11576454, -0.09858987, -0.13554272,\n",
            "          -0.05330075, -0.02268324, -0.11067111, -0.04667134,\n",
            "          -0.02814208, -0.08544181, -0.10725187, -0.01866292,\n",
            "          -0.02053377, -0.0157914 , -0.01726675, -0.00161511,\n",
            "          -0.09134302, -0.12072455, -0.08954431, -0.0640031 ,\n",
            "          -0.10608394, -0.05172051, -0.10266823, -0.01589226,\n",
            "          -0.01856214, -0.01679573, -0.04500405, -0.00662608,\n",
            "          -0.10178435, -0.09972267, -0.00220653, -0.01426306]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.02085493, -0.00616278,  0.01808921, -0.02042945, -0.09206146,\n",
            "       -0.10554375,  0.05362468, -0.01998848, -0.09396647,  0.20358466,\n",
            "        0.00573207,  0.21370102, -0.12136246,  0.13019341, -0.11341944,\n",
            "        0.00392942,  0.07078288, -0.00094515,  0.03655453,  0.15243451,\n",
            "        0.04637709,  0.01567696, -0.14270085,  0.21135706,  0.34447855,\n",
            "        0.04893694, -0.00663375,  0.0371171 , -0.06847805,  0.21814317,\n",
            "        0.02792453,  0.32860106], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-1.94998074e-06,  0.00000000e+00, -1.05681761e-06, ...,\n",
            "         0.00000000e+00, -1.15911155e-06, -1.14659349e-06],\n",
            "       [-4.86694153e-05,  0.00000000e+00, -1.47802741e-04, ...,\n",
            "        -4.08822325e-06, -1.22786776e-04, -1.86374906e-04],\n",
            "       [-2.53757316e-05,  0.00000000e+00, -1.70681760e-05, ...,\n",
            "        -7.85768066e-07, -3.15696452e-05, -2.81548528e-05],\n",
            "       ...,\n",
            "       [-2.37281838e-05,  0.00000000e+00, -2.93557496e-05, ...,\n",
            "        -3.59311059e-07, -1.65265719e-05, -3.90691857e-05],\n",
            "       [-5.72226090e-05,  0.00000000e+00, -6.91437162e-05, ...,\n",
            "        -6.51822347e-07, -3.35179429e-05, -7.80912160e-05],\n",
            "       [-1.48558509e-04,  0.00000000e+00, -1.79365656e-04, ...,\n",
            "        -1.66059590e-06, -1.00991456e-04, -2.17469060e-04]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-1.42159844e-02,  0.00000000e+00, -2.29001679e-02, -8.73196311e-03,\n",
            "       -2.33889110e-02, -1.44049469e-02, -2.10941825e-02, -1.33331781e-02,\n",
            "       -2.73749866e-02, -2.90687931e-05, -1.34071643e-02,  0.00000000e+00,\n",
            "        0.00000000e+00, -7.18673319e-03, -1.40522141e-02, -1.85449179e-02,\n",
            "        0.00000000e+00, -1.80448145e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.55538598e-02, -3.70280650e-05, -2.07947269e-02, -1.40916789e-04,\n",
            "       -2.35199817e-02, -2.06327885e-02,  0.00000000e+00, -1.61762442e-02,\n",
            "       -1.36228278e-02, -1.79732293e-02, -1.64459888e-02, -4.34919894e-02,\n",
            "       -1.29808555e-03,  0.00000000e+00, -2.25181170e-02, -2.72960477e-02,\n",
            "       -4.96394187e-03,  0.00000000e+00, -2.86353976e-02, -3.68738696e-02,\n",
            "       -3.02741434e-02, -1.48026310e-02,  0.00000000e+00, -2.58178692e-02,\n",
            "       -4.47393693e-02, -5.79201325e-04, -2.49639414e-02, -2.33514681e-02,\n",
            "       -2.89749391e-02, -2.16470696e-02, -1.53640378e-02, -2.28529945e-02,\n",
            "        0.00000000e+00, -1.25163773e-04, -1.00443121e-02, -1.72563363e-02,\n",
            "       -2.25836318e-02, -1.51489023e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.04433035e-02, -1.81210637e-02, -1.79261100e-02, -2.55087465e-02,\n",
            "       -2.03303620e-02,  2.84116785e-03, -3.28814127e-02, -1.79162659e-02,\n",
            "       -1.40220225e-02, -2.97559388e-02, -1.43360281e-02, -2.03097798e-02,\n",
            "       -1.21641206e-02, -2.52595898e-02, -2.48401035e-02, -1.25791188e-02,\n",
            "        0.00000000e+00, -2.22939570e-02, -2.43262053e-02, -1.82910115e-02,\n",
            "       -1.83168985e-02, -1.30385198e-02, -1.97671298e-02,  0.00000000e+00,\n",
            "       -1.20468531e-02, -1.70862619e-02, -1.78658608e-02, -1.45752858e-02,\n",
            "       -1.66004207e-02, -7.79866893e-03, -1.01485234e-02,  0.00000000e+00,\n",
            "       -2.26922575e-02, -1.12845534e-02, -1.15738832e-03, -2.29987688e-02,\n",
            "       -1.84635296e-02,  0.00000000e+00,  0.00000000e+00, -1.25879310e-02,\n",
            "       -2.33934913e-02, -2.17123609e-02, -2.71431208e-02, -3.01653650e-02,\n",
            "        1.44245592e-03, -1.42514743e-02, -6.42213598e-03,  0.00000000e+00,\n",
            "       -2.49628127e-02,  0.00000000e+00, -3.88607057e-03, -1.68348365e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -3.13258320e-02, -1.13718025e-02,\n",
            "       -3.08344401e-02,  8.15747492e-03, -8.92140716e-03, -2.01678537e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -2.43845042e-02, -1.24888457e-02,\n",
            "       -1.06111052e-03, -3.83050501e-04, -1.54589592e-02, -2.84825675e-02],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-3.2469705e-02,  1.7779522e-02,  9.0588778e-03, ...,\n",
            "         4.2047957e-04, -8.1464564e-03,  7.0377393e-03],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
            "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [ 1.0952643e-03,  3.5281107e-04, -1.2255521e-02, ...,\n",
            "         4.4271876e-03, -2.4414989e-03,  3.7435547e-03],\n",
            "       ...,\n",
            "       [ 2.2007143e-05,  1.3063756e-05,  3.1821768e-05, ...,\n",
            "         1.3130935e-05,  1.4646164e-05,  1.3565908e-05],\n",
            "       [-6.9171907e-03, -9.0514328e-03,  8.2272608e-03, ...,\n",
            "         5.7310117e-03, -6.3159857e-03,  3.9423304e-03],\n",
            "       [ 4.2585726e-03, -2.2526186e-02, -8.1736944e-05, ...,\n",
            "        -3.0937658e-03,  1.1271664e-03,  2.4236685e-03]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00624257, -0.03204852,  0.00343416,  0.0103984 , -0.0025398 ,\n",
            "        0.02523057,  0.01092673, -0.00227558, -0.00147151, -0.00541189],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -1.42504331e-02 -1.23130642e-01 ... -2.27558007e-03\n",
            " -1.47150550e-03 -5.41188521e-03]\n",
            "1000.0022037173933\n",
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.0145302 , -0.12248126, -0.09847172, -0.08977887,\n",
            "          -0.01258142, -0.05282655, -0.09749983, -0.1386599 ,\n",
            "          -0.05612962, -0.01136436, -0.1007557 , -0.04864478,\n",
            "          -0.08261342, -0.03695166, -0.0706507 , -0.01929532,\n",
            "          -0.14145641, -0.13475324, -0.07818078, -0.05013074,\n",
            "          -0.09195924, -0.07902448, -0.02133495, -0.07756272,\n",
            "          -0.0128193 , -0.01100032, -0.1395418 , -0.07555833,\n",
            "          -0.14259703, -0.01496211, -0.01447447, -0.04963806]],\n",
            "\n",
            "        [[-0.00555982, -0.13887002, -0.07903899, -0.11727598,\n",
            "          -0.02846957, -0.07812469, -0.12564188, -0.1172494 ,\n",
            "          -0.07561845, -0.01131353, -0.10595323, -0.02368896,\n",
            "          -0.04633061, -0.04908909, -0.04650185, -0.00349674,\n",
            "          -0.14003679, -0.14918762, -0.09425494, -0.03051758,\n",
            "          -0.08865464, -0.04118333, -0.0170733 , -0.04312337,\n",
            "          -0.01750597, -0.00406304, -0.1384812 , -0.05918034,\n",
            "          -0.14695369, -0.0371938 , -0.01828669, -0.05155512]],\n",
            "\n",
            "        [[-0.00325284, -0.13250798, -0.0600763 , -0.12705867,\n",
            "          -0.0437816 , -0.0935491 , -0.13343577, -0.08047233,\n",
            "          -0.08195604, -0.02332233, -0.10295839, -0.01147796,\n",
            "          -0.01000616, -0.05980443, -0.03981672, -0.00168962,\n",
            "          -0.11274057, -0.14098364, -0.10697809, -0.01191735,\n",
            "          -0.06673494, -0.00513796, -0.0231402 , -0.01374013,\n",
            "          -0.03440736, -0.00366749, -0.10934231, -0.05126768,\n",
            "          -0.1349115 , -0.06471237, -0.0215055 , -0.0462774 ]]],\n",
            "\n",
            "\n",
            "       [[[-0.0438297 , -0.13981499, -0.09734792, -0.12194034,\n",
            "          -0.04704287, -0.03786461, -0.10828495, -0.1323407 ,\n",
            "          -0.02385929, -0.01670351, -0.10890168, -0.06121327,\n",
            "          -0.09199186, -0.03944347, -0.03395286, -0.00674137,\n",
            "          -0.14421031, -0.1464642 , -0.09956325, -0.07818706,\n",
            "          -0.12370744, -0.09610164, -0.05574721, -0.08005798,\n",
            "          -0.01350292, -0.00473256, -0.12863865, -0.03282481,\n",
            "          -0.14623871, -0.01972844, -0.00292956, -0.02248035]],\n",
            "\n",
            "        [[-0.03090262, -0.15207778, -0.09061337, -0.14807734,\n",
            "          -0.06159654, -0.05070325, -0.13652532, -0.10577355,\n",
            "          -0.04044386, -0.02554623, -0.12053588, -0.02710513,\n",
            "          -0.05166266, -0.04445788, -0.01412396, -0.00131701,\n",
            "          -0.14343567, -0.15646294, -0.10955645, -0.05947566,\n",
            "          -0.11990522, -0.05778923, -0.05982988, -0.03963507,\n",
            "          -0.01482532, -0.00257352, -0.1147389 , -0.01891156,\n",
            "          -0.14691342, -0.05036774, -0.00220572, -0.02034632]],\n",
            "\n",
            "        [[-0.02285285, -0.14017756, -0.08484612, -0.1502332 ,\n",
            "          -0.06418958, -0.05769239, -0.13878743, -0.07080838,\n",
            "          -0.05234122, -0.05168142, -0.12078763, -0.01197573,\n",
            "          -0.0149472 , -0.04797126, -0.02509154, -0.00101912,\n",
            "          -0.11572935, -0.14307883, -0.10971276, -0.03862868,\n",
            "          -0.09380739, -0.02528623, -0.06677087, -0.01249354,\n",
            "          -0.0262648 , -0.00519345, -0.08121657, -0.01516796,\n",
            "          -0.13112548, -0.08027845, -0.00324236, -0.01826178]]],\n",
            "\n",
            "\n",
            "       [[[-0.07031357, -0.12557307, -0.07994125, -0.12473819,\n",
            "          -0.06844823, -0.01636643, -0.09220025, -0.09106237,\n",
            "          -0.00183564, -0.03815238, -0.08698769, -0.07307418,\n",
            "          -0.08548348, -0.01706712, -0.00943165, -0.00318817,\n",
            "          -0.11636923, -0.13189796, -0.10369718, -0.09965563,\n",
            "          -0.1352419 , -0.10168665, -0.08545333, -0.07564405,\n",
            "          -0.01379211, -0.00149642, -0.09574503, -0.0089216 ,\n",
            "          -0.11894136, -0.04007428, -0.00163359, -0.01380513]],\n",
            "\n",
            "        [[-0.05508867, -0.13150686, -0.09123313, -0.14122778,\n",
            "          -0.06802439, -0.0205321 , -0.11057342, -0.07070547,\n",
            "          -0.01597685, -0.05804337, -0.10077023, -0.03740071,\n",
            "          -0.05198522, -0.01490183, -0.00207999, -0.00173947,\n",
            "          -0.11486188, -0.13751268, -0.10402195, -0.08595771,\n",
            "          -0.13318087, -0.07602009, -0.09948684, -0.03814575,\n",
            "          -0.01358796, -0.00469539, -0.07668715, -0.00444189,\n",
            "          -0.11714989, -0.07446656, -0.0019135 , -0.01455071]],\n",
            "\n",
            "        [[-0.0491598 , -0.11530139, -0.09834616, -0.13498218,\n",
            "          -0.05362066, -0.02250028, -0.11066131, -0.04630404,\n",
            "          -0.02818727, -0.08554439, -0.10731849, -0.01874135,\n",
            "          -0.02076526, -0.01572846, -0.01707036, -0.00163052,\n",
            "          -0.09119032, -0.12017031, -0.08938789, -0.06455024,\n",
            "          -0.10602981, -0.05178745, -0.10297956, -0.01584157,\n",
            "          -0.01865955, -0.01680878, -0.04510904, -0.00664348,\n",
            "          -0.10168535, -0.10000615, -0.00222423, -0.01431636]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-0.01754062, -0.00382904,  0.0189379 , -0.01846841, -0.09262932,\n",
            "       -0.10602464,  0.05486363, -0.01697842, -0.09390703,  0.2055567 ,\n",
            "        0.00645737,  0.21582124, -0.12225628,  0.12914744, -0.11505871,\n",
            "        0.00446391,  0.07236546,  0.00115052,  0.03743028,  0.14265847,\n",
            "        0.04690351,  0.01657235, -0.14328629,  0.21357992,  0.34682313,\n",
            "        0.04961341, -0.0063435 ,  0.03769432, -0.06709099,  0.21981524,\n",
            "        0.02879872,  0.3305647 ], dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-1.8146395e-06,  0.0000000e+00, -9.4886417e-07, ...,\n",
            "         0.0000000e+00, -1.1040939e-06, -8.5768346e-07],\n",
            "       [-4.9016115e-05,  0.0000000e+00, -1.4260171e-04, ...,\n",
            "        -4.0712266e-06, -1.2053290e-04, -1.8503131e-04],\n",
            "       [-2.5430900e-05,  0.0000000e+00, -1.6275520e-05, ...,\n",
            "        -7.8210542e-07, -3.1090902e-05, -2.7902821e-05],\n",
            "       ...,\n",
            "       [-2.8309976e-05,  0.0000000e+00, -3.4246914e-05, ...,\n",
            "        -4.0668328e-07, -2.0417958e-05, -4.3752436e-05],\n",
            "       [-5.8241283e-05,  0.0000000e+00, -6.9359288e-05, ...,\n",
            "        -6.5920858e-07, -3.5996898e-05, -7.5735690e-05],\n",
            "       [-1.5606474e-04,  0.0000000e+00, -1.8534967e-04, ...,\n",
            "        -1.7310989e-06, -1.1086938e-04, -2.1722711e-04]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([-1.43421693e-02,  0.00000000e+00, -2.25286167e-02, -8.75998847e-03,\n",
            "       -2.34567132e-02, -1.45389931e-02, -2.13524476e-02, -1.32736750e-02,\n",
            "       -2.75459141e-02, -2.95023747e-05, -1.33627085e-02,  0.00000000e+00,\n",
            "        0.00000000e+00, -7.21774809e-03, -1.41010387e-02, -1.86200067e-02,\n",
            "        0.00000000e+00, -1.83289610e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.59111449e-02, -3.72941176e-05, -2.10789610e-02, -4.96285502e-05,\n",
            "       -2.33565252e-02, -2.08449755e-02,  0.00000000e+00, -1.62257459e-02,\n",
            "       -1.36954542e-02, -1.82988923e-02, -1.64722279e-02, -4.38088141e-02,\n",
            "       -1.30011630e-03,  0.00000000e+00, -2.27830317e-02, -2.65842397e-02,\n",
            "       -4.89832740e-03,  0.00000000e+00, -2.91218422e-02, -3.69529985e-02,\n",
            "       -3.06603573e-02, -1.47929955e-02,  0.00000000e+00, -2.57914681e-02,\n",
            "       -4.42556255e-02, -5.80294989e-04, -2.49866769e-02, -2.36366075e-02,\n",
            "       -2.89310813e-02, -2.19454877e-02, -1.54739674e-02, -2.29148883e-02,\n",
            "        0.00000000e+00, -1.25567109e-04, -1.02542173e-02, -1.75398812e-02,\n",
            "       -2.28499919e-02, -1.52392900e-02,  0.00000000e+00,  0.00000000e+00,\n",
            "       -2.03307830e-02, -1.81738213e-02, -1.81035697e-02, -2.54965853e-02,\n",
            "       -2.02440415e-02,  2.86655105e-03, -3.28568071e-02, -1.77873857e-02,\n",
            "       -1.40959490e-02, -2.96798907e-02, -1.43942013e-02, -2.02985108e-02,\n",
            "       -1.22280773e-02, -2.53061019e-02, -2.51085609e-02, -1.25538642e-02,\n",
            "        0.00000000e+00, -2.23493595e-02, -2.43000239e-02, -1.83688197e-02,\n",
            "       -1.86478458e-02, -1.31060686e-02, -1.96825210e-02,  0.00000000e+00,\n",
            "       -1.20217055e-02, -1.70188397e-02, -1.77817233e-02, -1.48627963e-02,\n",
            "       -1.67364571e-02, -7.72744697e-03, -1.01859355e-02,  0.00000000e+00,\n",
            "       -2.27821358e-02, -1.14940172e-02, -1.16553670e-03, -2.32654400e-02,\n",
            "       -1.85159612e-02,  0.00000000e+00,  0.00000000e+00, -1.26327118e-02,\n",
            "       -2.36394815e-02, -2.15577036e-02, -2.70672850e-02, -3.04398760e-02,\n",
            "        1.43288448e-03, -1.40758231e-02, -6.36000000e-03,  0.00000000e+00,\n",
            "       -2.49545090e-02,  0.00000000e+00, -3.77797289e-03, -1.69291086e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -3.15394141e-02, -1.14117246e-02,\n",
            "       -3.11315767e-02,  8.14023055e-03, -9.06838663e-03, -2.02794224e-02,\n",
            "        0.00000000e+00,  0.00000000e+00, -2.39601396e-02, -1.26866009e-02,\n",
            "       -1.06620812e-03, -3.83646518e-04, -1.57383438e-02, -2.78401636e-02],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[-3.24691124e-02,  1.77112296e-02,  9.02989227e-03, ...,\n",
            "         4.24986181e-04, -8.12930334e-03,  7.07758591e-03],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
            "       [ 1.11520465e-03,  3.62406310e-04, -1.21904202e-02, ...,\n",
            "         4.37320676e-03, -2.37305346e-03,  3.72260436e-03],\n",
            "       ...,\n",
            "       [ 2.17381275e-05,  1.30466915e-05,  3.15775069e-05, ...,\n",
            "         1.30569724e-05,  1.45481554e-05,  1.34650745e-05],\n",
            "       [-6.88684266e-03, -8.97116400e-03,  8.14178120e-03, ...,\n",
            "         5.68682142e-03, -6.27411623e-03,  3.94125702e-03],\n",
            "       [ 4.19380842e-03, -2.23300289e-02, -6.87212450e-05, ...,\n",
            "        -3.04938131e-03,  1.13925734e-03,  2.41478905e-03]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.00642473, -0.03205917,  0.0033537 ,  0.01042769, -0.00235959,\n",
            "        0.02539741,  0.01092728, -0.00233083, -0.0015981 , -0.00533365],\n",
            "      dtype=float32)>]\n",
            "[ 1.00000000e+03 -1.45302005e-02 -1.22481257e-01 ... -2.33083125e-03\n",
            " -1.59809599e-03 -5.33365412e-03]\n",
            "1000.0022009650044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZjbQBHOldN"
      },
      "source": [
        "Step5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta3 = 1\n",
        "\n",
        "weights_updated = ordinary_weights\n",
        "for i in range(1):\n",
        "\n",
        "  # 重みをw + (step4で決めた)vに設定する　　ここから\n",
        "  current_weights = []\n",
        "  for layer_weights, v in zip(weights_updated, v_updated):\n",
        "    current_layer_weight = tf.add(layer_weights, v)\n",
        "    current_weights.append(current_layer_weight)\n",
        "  model.set_weights(current_weights)\n",
        "  print(current_weights) \n",
        "  # 計算できている．\n",
        "  # 重みをw + (step4で決めた)vに設定する　　ここまで\n",
        "\n",
        "  # # gradientの計算　　ここから\n",
        "  # with tf.GradientTape() as tape:\n",
        "  #   loss = calculate_loss(adversarial_ds)\n",
        "  #   print(loss)\n",
        "  # gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  # # print(gradients) \n",
        "  # # 計算できているが，値が大きい．\n",
        "  # # gradientの計算　　ここまで\n",
        "\n",
        "  # # 勾配降下の実行　　ここから\n",
        "  # w_hat = []\n",
        "  # for wu, g in zip(weights_updated, gradients):\n",
        "  #   g_med = tf.multiply(eta3, g)\n",
        "  #   wu = tf.subtract(wu, g_med)\n",
        "  #   w_hat.append(wu)\n",
        "  # weights_updated = w_hat\n",
        "  # # 勾配降下の実行　　ここまで"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0bd9iyoK9EB",
        "outputId": "6ce54a7c-87ea-4a06-d3f8-6770b8acd0be"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(3, 3, 1, 32), dtype=float32, numpy=\n",
            "array([[[[-0.06457131,  0.0141384 ,  0.11912435, -0.08343159,\n",
            "          -0.12913011, -0.11486347, -0.02464951,  0.08808835,\n",
            "           0.0271644 , -0.08384793,  0.04860897,  0.03815352,\n",
            "           0.11945156, -0.09783938,  0.11319239,  0.05088645,\n",
            "           0.10941786,  0.13202386,  0.04035462, -0.02954747,\n",
            "           0.03910792,  0.05765489, -0.01069733, -0.01057309,\n",
            "          -0.03284337,  0.0394861 ,  0.05831145,  0.14012417,\n",
            "           0.09381586, -0.13298553,  0.0034723 ,  0.00124479]],\n",
            "\n",
            "        [[-0.03784123,  0.06509151, -0.0017809 ,  0.02778978,\n",
            "          -0.04812502,  0.09269726,  0.09885757, -0.04602231,\n",
            "           0.10491604, -0.02076299,  0.02373398, -0.0725281 ,\n",
            "          -0.14195873, -0.00500001, -0.01156732, -0.07484698,\n",
            "           0.12654208,  0.01383367, -0.06407446, -0.06768628,\n",
            "           0.02472196,  0.03314514, -0.10152464, -0.04755697,\n",
            "          -0.1400764 , -0.13122144,  0.10128731, -0.06543281,\n",
            "           0.1004184 ,  0.06769913,  0.0042711 ,  0.13878998]],\n",
            "\n",
            "        [[ 0.00249325,  0.0926401 , -0.07452568,  0.10240156,\n",
            "          -0.01169507,  0.14103533, -0.00465627, -0.00847069,\n",
            "           0.07789414, -0.10300816, -0.06175172, -0.0702439 ,\n",
            "          -0.03712854,  0.03173723, -0.00192843, -0.11266866,\n",
            "          -0.08277897,  0.12351219,  0.09898406, -0.11630821,\n",
            "          -0.08304244, -0.13125856, -0.0916218 , -0.04776502,\n",
            "           0.076756  , -0.12406851,  0.04166687,  0.11068825,\n",
            "           0.00246242,  0.02879073,  0.02232148, -0.00498744]]],\n",
            "\n",
            "\n",
            "       [[[ 0.01413587,  0.04053391,  0.11693963,  0.07763669,\n",
            "           0.01760622,  0.02461697,  0.1373249 ,  0.09886964,\n",
            "          -0.08532902, -0.07657658,  0.1388729 , -0.03187591,\n",
            "           0.09455413,  0.0387915 ,  0.00270711, -0.0605023 ,\n",
            "           0.04873251, -0.08715474,  0.02341938,  0.13280341,\n",
            "           0.06793857,  0.11601181, -0.00702415,  0.10262156,\n",
            "          -0.06449783, -0.03997395, -0.03138154, -0.0172633 ,\n",
            "           0.05392868, -0.10439123, -0.12527022, -0.01980435]],\n",
            "\n",
            "        [[ 0.10754593,  0.03946463, -0.12654613,  0.03637361,\n",
            "           0.06752814,  0.02912652, -0.06654936,  0.1418968 ,\n",
            "          -0.0009328 , -0.06897229, -0.04888117,  0.00943743,\n",
            "           0.05692843,  0.12309711, -0.13583606,  0.08612825,\n",
            "           0.02833213,  0.05893038, -0.12540755,  0.01349951,\n",
            "           0.02432039, -0.05613396,  0.03460836, -0.0050013 ,\n",
            "           0.06604163,  0.06446063,  0.0483041 , -0.06260007,\n",
            "           0.00797552, -0.04364924,  0.04923481, -0.08918778]],\n",
            "\n",
            "        [[-0.11460029,  0.06687342,  0.01672276,  0.04898369,\n",
            "           0.09428616, -0.08522749,  0.11427734, -0.10071447,\n",
            "          -0.10120165,  0.05772101,  0.11492758, -0.11443376,\n",
            "          -0.10428596,  0.02365293,  0.05006533,  0.04052749,\n",
            "           0.0046461 ,  0.01828844,  0.1109575 , -0.10795207,\n",
            "          -0.09931985, -0.10906319,  0.05429955, -0.07248634,\n",
            "           0.02966986, -0.09660602, -0.0650841 , -0.13805485,\n",
            "           0.02173337, -0.05847362, -0.07089175, -0.12772709]]],\n",
            "\n",
            "\n",
            "       [[[ 0.08943938,  0.10285776, -0.12938993,  0.05390751,\n",
            "           0.06973597, -0.00377942, -0.12405884, -0.00608692,\n",
            "          -0.11856397,  0.02771942, -0.10724589,  0.13240686,\n",
            "          -0.00188611, -0.00731157,  0.00651808,  0.02386953,\n",
            "          -0.02450145,  0.11043312,  0.0502874 ,  0.1199432 ,\n",
            "           0.04508699, -0.00113458,  0.00675628,  0.09150404,\n",
            "          -0.11868094, -0.00244542,  0.09199607, -0.09763982,\n",
            "           0.06395162, -0.0173701 , -0.00400869, -0.08605388]],\n",
            "\n",
            "        [[-0.11644854,  0.00854813,  0.07109316,  0.08477474,\n",
            "           0.03209878, -0.10976862,  0.09536144, -0.1398245 ,\n",
            "           0.054237  , -0.02301257, -0.02326548, -0.0823097 ,\n",
            "           0.08428923, -0.11879129, -0.11865866, -0.12546249,\n",
            "           0.02236803,  0.01677924,  0.09758331,  0.04857541,\n",
            "           0.09017554,  0.02142484,  0.10447933, -0.08273625,\n",
            "          -0.07557754, -0.07705481, -0.01805647,  0.03284527,\n",
            "          -0.07166054,  0.10926485,  0.02249132, -0.12957533]],\n",
            "\n",
            "        [[ 0.08012684,  0.06350876,  0.13304918,  0.09512055,\n",
            "          -0.11326057,  0.02113989,  0.00453118,  0.07296088,\n",
            "           0.0279854 ,  0.08787356,  0.10869916,  0.00743805,\n",
            "          -0.07154775, -0.06889171,  0.05658158, -0.09832107,\n",
            "           0.08675712,  0.07465325, -0.09175318,  0.10335691,\n",
            "           0.10805395,  0.11448894,  0.02288024, -0.01378157,\n",
            "          -0.07371192,  0.05791868, -0.05556344, -0.10467036,\n",
            "           0.10393387,  0.0462749 , -0.05239249, -0.11451734]]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-1.7793955e-03, -2.4137995e-03, -2.3622904e-03, -1.9001137e-03,\n",
            "       -3.2314777e-03, -3.1797555e-03, -1.8021478e-03, -1.4398913e-03,\n",
            "       -3.0144162e-03, -5.2722311e-04, -3.2154177e-03, -7.0122717e-04,\n",
            "       -3.1888601e-03, -9.6337672e-04, -3.1776952e-03, -1.9316484e-03,\n",
            "       -1.5588615e-03, -2.2702361e-03, -1.9467766e-03, -7.9498085e-04,\n",
            "       -1.9051044e-03, -1.8027424e-03, -3.4748374e-03, -4.4506218e-04,\n",
            "        5.4119533e-04, -1.3025661e-03, -2.2806290e-03,  2.4004676e-04,\n",
            "       -2.1040405e-03, -4.2722543e-04,  7.7273231e-05,  3.8787990e-04],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(21632, 128), dtype=float32, numpy=\n",
            "array([[-0.00538754, -0.00709194,  0.01219551, ..., -0.00421053,\n",
            "         0.00022396,  0.00338484],\n",
            "       [ 0.00859327, -0.00962707,  0.00123041, ..., -0.01238552,\n",
            "         0.00254974, -0.01116787],\n",
            "       [ 0.00046796, -0.00653827,  0.01487007, ...,  0.00166023,\n",
            "        -0.01099515,  0.01456743],\n",
            "       ...,\n",
            "       [ 0.00171562, -0.01261113,  0.00202259, ...,  0.00314826,\n",
            "        -0.00248561, -0.00098681],\n",
            "       [ 0.00577454,  0.00388715,  0.01350684, ..., -0.00040986,\n",
            "         0.00881106,  0.01250382],\n",
            "       [ 0.01144696, -0.00230081,  0.00577763, ...,  0.00703628,\n",
            "         0.00923539, -0.00811136]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
            "array([0.01031706, 0.00779723, 0.01137701, 0.01033117, 0.010101  ,\n",
            "       0.01130313, 0.00921641, 0.00968658, 0.00963312, 0.00822471,\n",
            "       0.01249209, 0.00769674, 0.00770788, 0.01237682, 0.01128863,\n",
            "       0.01152887, 0.00811927, 0.01214853, 0.00772262, 0.00769702,\n",
            "       0.01237737, 0.00799113, 0.01022069, 0.01284555, 0.01138698,\n",
            "       0.01264762, 0.00769699, 0.00952369, 0.00935166, 0.00984413,\n",
            "       0.01214785, 0.01218087, 0.00895253, 0.00769717, 0.00922368,\n",
            "       0.00900175, 0.01141322, 0.00819759, 0.00927861, 0.00992009,\n",
            "       0.01188405, 0.01271321, 0.00769726, 0.01259189, 0.01185225,\n",
            "       0.00872693, 0.00986452, 0.01014094, 0.01254246, 0.01213319,\n",
            "       0.01023374, 0.01045319, 0.00769824, 0.00792769, 0.01121624,\n",
            "       0.01095568, 0.01216898, 0.01229523, 0.0076981 , 0.00773169,\n",
            "       0.01183926, 0.0126234 , 0.00809439, 0.01019603, 0.00759182,\n",
            "       0.01286193, 0.01195573, 0.00987023, 0.01120754, 0.00931139,\n",
            "       0.01025758, 0.01204569, 0.01227155, 0.00991277, 0.01238774,\n",
            "       0.00982363, 0.00769904, 0.00905493, 0.012269  , 0.01000198,\n",
            "       0.01239763, 0.01007108, 0.01007608, 0.0076966 , 0.0102216 ,\n",
            "       0.01265603, 0.00979072, 0.01264168, 0.00909249, 0.00938161,\n",
            "       0.01022189, 0.00781098, 0.0124102 , 0.01271851, 0.00820113,\n",
            "       0.00920148, 0.00959863, 0.00773542, 0.00769749, 0.01026467,\n",
            "       0.01236915, 0.00729172, 0.00997613, 0.01163021, 0.01257544,\n",
            "       0.00863981, 0.01005547, 0.00785118, 0.00984805, 0.007699  ,\n",
            "       0.00987948, 0.01015002, 0.00773118, 0.00783453, 0.01233545,\n",
            "       0.00998281, 0.01015406, 0.0112679 , 0.0116312 , 0.00988356,\n",
            "       0.00769763, 0.00769889, 0.01212065, 0.01241774, 0.01265226,\n",
            "       0.01018096, 0.0119896 , 0.01017097], dtype=float32)>, <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
            "array([[ 1.26924366e-01, -1.66518584e-01, -9.88225043e-02, ...,\n",
            "         1.01544693e-01,  1.87248334e-01,  2.35893577e-03],\n",
            "       [ 1.78193778e-01,  3.83755118e-02, -1.60906017e-01, ...,\n",
            "         2.38251761e-02, -1.06024370e-01,  1.67569473e-01],\n",
            "       [ 9.60395411e-02,  1.35334972e-02,  1.71027094e-01, ...,\n",
            "        -1.23790145e-01,  9.13658440e-02,  1.45806998e-01],\n",
            "       ...,\n",
            "       [-9.17827711e-05,  2.41618268e-02, -9.98446643e-02, ...,\n",
            "        -1.37621611e-01, -5.09845316e-02,  4.06360254e-02],\n",
            "       [ 4.46952581e-02,  5.72552532e-02, -1.82293370e-01, ...,\n",
            "         5.27302502e-03,  1.42402247e-01, -1.15513645e-01],\n",
            "       [-4.96549197e-02,  1.91277906e-01,  8.50643963e-02, ...,\n",
            "         1.03061832e-01,  1.89909920e-01,  6.82744607e-02]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([0.00123116, 0.00665209, 0.00415582, 0.00705201, 0.00259373,\n",
            "       0.00362801, 0.0058617 , 0.00360565, 0.00380719, 0.00124606],\n",
            "      dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MclZYfOldN"
      },
      "source": [
        "再テストの実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jAmhPk_tOldN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740dea50-0a47-4ada-c770-7f6556cf0f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Test Loss: 1.5340921878814697, Test Accuracy: 77.61000061035156\n",
            "Epoch 2, Test Loss: 1.5340921878814697, Test Accuracy: 77.61000061035156\n",
            "Epoch 3, Test Loss: 1.5340921878814697, Test Accuracy: 77.61000061035156\n",
            "Epoch 4, Test Loss: 1.5340921878814697, Test Accuracy: 77.61000061035156\n",
            "Epoch 5, Test Loss: 1.5340921878814697, Test Accuracy: 77.61000061035156\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "    \n",
        "    print(\n",
        "        f'Epoch {epoch + 1}, '\n",
        "        f'Test Loss: {test_loss.result()}, '\n",
        "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQmyQyMYKM4P"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('pythonenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d1685d247089585e01bacc0e11595c4779ea690fa157e920ca16120e3c1da301"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}